{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ColabPreprocess  --START\n",
        "置換<br>\n",
        "\n",
        "/kaggle/input/            <br>\n",
        "/content/"
      ],
      "metadata": {
        "id": "uIY3gyjVDW16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "9D2OX6U0CaH6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! apt update\n",
        "! apt install gcsfuse"
      ],
      "metadata": {
        "outputId": "01ec070e-e241-45bf-cc58-cebec0c526eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qpeTkECaH7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0  91689      0 --:--:-- --:--:-- --:--:-- 91689\n",
            "OK\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:3 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,004 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,079 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [81.0 kB]\n",
            "Get:8 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [2,356 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,636 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease [24.3 kB]\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [39.5 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,604 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,229 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal/main amd64 Packages [44.1 kB]\n",
            "Fetched 8,104 kB in 5s (1,764 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "31 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 14.0 MB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 1.0.0 [14.0 MB]\n",
            "Fetched 14.0 MB in 0s (70.4 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_1.0.0_amd64.deb ...\n",
            "Unpacking gcsfuse (1.0.0) ...\n",
            "Setting up gcsfuse (1.0.0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5f_lFB9TCaH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kaggle get_gcspath\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "print(KaggleDatasets().get_gcs_path())"
      ],
      "metadata": {
        "id": "1GmDR8Lh1fku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3Q0v8LEtnE",
        "outputId": "08a66819-e9c0-4300-cac0-5e244b4c0e21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p asl-fingerspelling\n",
        "! gcsfuse  --implicit-dirs --lmiit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-1e4efec750c765afae26f4a9a1c1a2d995c7d320da64d01393f09fbf asl-fingerspelling"
      ],
      "metadata": {
        "id": "olczO1_pC2TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22d1978-ea56-422c-a84f-e9c78af2e6c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0703 03:26:05.715659 2023/07/03 03:26:05.715626 Start gcsfuse/1.0.0 (Go version go1.20.4) for app \"\" using mount point: /content/asl-fingerspelling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p aslfr-parquets-to-tfrecords-cleaned\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-a5db0f6cebe53c0b6c0786d89bbd5dfff0ce1facd9345f7f1ae044b7 aslfr-parquets-to-tfrecords-cleaned"
      ],
      "metadata": {
        "id": "fP7uO-XSJTlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esy-KMuR8ivw",
        "outputId": "f692c241-1e4a-4bfb-cf72-39fc6f477496"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8L77lmNJEQYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --END  ColabPreprocess"
      ],
      "metadata": {
        "id": "ZDYAPQiVEATw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. I used two transformer layer in the encoder instead of four.\n",
        "2. I used four attention heads instead of two.\n",
        "3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n",
        "2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n",
        "3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n",
        "4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n",
        "5. I added positional embedding to the encoder. This, too, had a significant impact.\n"
      ],
      "metadata": {
        "id": "ls6jZUmODp5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import Levenshtein as lev\n",
        "import os\n",
        "import gc\n",
        "import glob"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:39.647352Z",
          "iopub.execute_input": "2023-06-26T03:43:39.647946Z",
          "iopub.status.idle": "2023-06-26T03:43:39.654535Z",
          "shell.execute_reply.started": "2023-06-26T03:43:39.647910Z",
          "shell.execute_reply": "2023-06-26T03:43:39.653364Z"
        },
        "trusted": true,
        "id": "hJnLDjLzDp53",
        "outputId": "45d901bb-1d7f-40ad-9e98-755e8a98946b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ab2382fd46ae>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mLevenshtein\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Levenshtein'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "B3hcEfbDDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
        "display(df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:34.921833Z",
          "iopub.execute_input": "2023-06-21T12:27:34.922562Z",
          "iopub.status.idle": "2023-06-21T12:27:35.134638Z",
          "shell.execute_reply.started": "2023-06-21T12:27:34.922525Z",
          "shell.execute_reply": "2023-06-21T12:27:35.133695Z"
        },
        "id": "0Ni7noahDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_landmarks = pd.read_parquet('/content/asl-fingerspelling/train_landmarks/1019715464.parquet')\n",
        "keys = train_landmarks.keys()[1:]\n",
        "train_landmarks.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:35.136172Z",
          "iopub.execute_input": "2023-06-21T12:27:35.136526Z",
          "iopub.status.idle": "2023-06-21T12:27:52.128059Z",
          "shell.execute_reply.started": "2023-06-21T12:27:35.136494Z",
          "shell.execute_reply": "2023-06-21T12:27:52.122672Z"
        },
        "id": "F1hbBsMFDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFRecord"
      ],
      "metadata": {
        "id": "t_Zq2IIvDp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.129279Z",
          "iopub.status.idle": "2023-06-21T12:27:52.130399Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.130158Z",
          "shell.execute_reply": "2023-06-21T12:27:52.13018Z"
        },
        "id": "jycbHpy_Dp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
        "\n",
        "counter = 0\n",
        "for file_id in tqdm(df.file_id.unique()):\n",
        "    \n",
        "    print(counter)\n",
        "    counter+=1\n",
        "    \n",
        "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
        "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
        "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
        "    seq_refs = df.loc[df.file_id == file_id]\n",
        "    seqs = load_relevant_data_subset(pqfile)\n",
        "    seqs_numpy = seqs.to_numpy()\n",
        "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
        "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
        "            frames = seqs_numpy[seqs.index == seq_id]\n",
        "            \n",
        "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
        "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
        "            no_nan = max(r_nonan, l_nonan)\n",
        "            \n",
        "            if 2*len(phrase)<no_nan:\n",
        "                features = {SEL_COLS[i]: tf.train.Feature(\n",
        "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n",
        "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
        "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
        "                file_writer.write(record_bytes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.131662Z",
          "iopub.status.idle": "2023-06-21T12:27:52.132528Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.132225Z",
          "shell.execute_reply": "2023-06-21T12:27:52.132253Z"
        },
        "id": "Hmzq1uMZDp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "anVm5CKGDp57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs)."
      ],
      "metadata": {
        "id": "NaASHGkwDp57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = 'P'\n",
        "start_token = 'S'\n",
        "end_token = 'E'\n",
        "pad_token_idx = 59\n",
        "start_token_idx = 60\n",
        "end_token_idx = 61"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:50.038588Z",
          "iopub.execute_input": "2023-06-26T03:43:50.039294Z",
          "iopub.status.idle": "2023-06-26T03:43:50.043979Z",
          "shell.execute_reply.started": "2023-06-26T03:43:50.039260Z",
          "shell.execute_reply": "2023-06-26T03:43:50.043067Z"
        },
        "trusted": true,
        "id": "zGEhbPRUDp58"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    char_to_num = json.load(f)\n",
        "\n",
        "\n",
        "char_to_num[pad_token] = pad_token_idx\n",
        "char_to_num[start_token] = start_token_idx\n",
        "char_to_num[end_token] = end_token_idx\n",
        "\n",
        "num_to_char = {j:i for i,j in char_to_num.items()}\n",
        "\n",
        "\n",
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "\n",
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print(RPOSE_IDX)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:51.279454Z",
          "iopub.execute_input": "2023-06-26T03:43:51.279841Z",
          "iopub.status.idle": "2023-06-26T03:43:51.388163Z",
          "shell.execute_reply.started": "2023-06-26T03:43:51.279809Z",
          "shell.execute_reply": "2023-06-26T03:43:51.387128Z"
        },
        "trusted": true,
        "id": "SdTNf47NDp58",
        "outputId": "33c5e632-3e92-460e-d4a7-8d3eba66075a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 48, 49, 50, 51, 99, 100, 101, 102, 103, 151, 152, 153, 154, 155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{0: ' ', 1: '!', 2: '#', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: '+', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '=', 28: '?', 29: '@', 30: '[', 31: '_', 32: 'a', 33: 'b', 34: 'c', 35: 'd', 36: 'e', 37: 'f', 38: 'g', 39: 'h', 40: 'i', 41: 'j', 42: 'k', 43: 'l', 44: 'm', 45: 'n', 46: 'o', 47: 'p', 48: 'q', 49: 'r', 50: 's', 51: 't', 52: 'u', 53: 'v', 54: 'w', 55: 'x', 56: 'y', 57: 'z', 58: '~', 59: 'P', 60: 'S', 61: 'E'}\n",
        "add Codeadd Markdown"
      ],
      "metadata": {
        "id": "7l2otrH4Dp59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_pad(x):\n",
        "    if tf.shape(x)[0] < FRAME_LEN:\n",
        "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
        "        print(x)\n",
        "    else:\n",
        "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
        "    return x\n",
        "\n",
        "def translate_landmarks(landmarks, max_translation):\n",
        "    translation = tf.random.uniform(shape=tf.shape(landmarks), minval=-max_translation, maxval=max_translation)\n",
        "    translated_landmarks = landmarks + translation\n",
        "    return translated_landmarks\n",
        "\n",
        "# def scale_landmarks(landmarks, min_scale, max_scale):\n",
        "#     scale_factor = tf.random.uniform(shape=tf.shape(landmarks), minval=min_scale, maxval=max_scale)\n",
        "#     scaled_landmarks = landmarks * scale_factor\n",
        "#     return scaled_landmarks\n",
        "\n",
        "#Frame feture　preprocess\n",
        "def compute_second_derivative(frames):\n",
        "    second_derivatives = []\n",
        "    for i in range(len(frames) - 1):\n",
        "        frame1 = frames[i]\n",
        "        frame2 = frames[i+1]\n",
        "\n",
        "        derivatives = tf.reduce_mean(tf.abs(frame2 - 2*frame1 + tf.roll(frame2, shift=1, axis=0)), axis=0)\n",
        "        second_derivatives.append(derivatives)\n",
        "\n",
        "    return tf.stack(second_derivatives)\n",
        "\n",
        "def extract_feature_vectors(frames):\n",
        "    feature_vectors = []\n",
        "    for frame_pair in frames:\n",
        "        second_derivatives = compute_second_derivative(frame_pair)\n",
        "        feature_vector = tf.concat([tf.reduce_mean(second_derivatives), tf.math.reduce_std(second_derivatives)], axis=0)\n",
        "        feature_vectors.append(feature_vector)\n",
        "\n",
        "    return tf.stack(feature_vectors)\n",
        "\n",
        "\n",
        "\n",
        "def pre_process(x):\n",
        "\n",
        "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
        "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
        "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
        "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
        "\n",
        "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
        "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
        "\n",
        "    rnans = tf.math.count_nonzero(rnan_idx)\n",
        "    lnans = tf.math.count_nonzero(lnan_idx)\n",
        "\n",
        "    # For dominant hand\n",
        "    if rnans > lnans:\n",
        "        hand = lhand\n",
        "        pose = lpose\n",
        "\n",
        "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
        "\n",
        "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
        "    else:\n",
        "        hand = rhand\n",
        "        pose = rpose\n",
        "\n",
        "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
        "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
        "    hand = (hand - mean) / std\n",
        "\n",
        "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    x = tf.concat([hand, pose], axis=1)\n",
        "    x = resize_pad(x)\n",
        "\n",
        "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:56.251215Z",
          "iopub.execute_input": "2023-06-26T03:43:56.251603Z",
          "iopub.status.idle": "2023-06-26T03:43:56.275318Z",
          "shell.execute_reply.started": "2023-06-26T03:43:56.251574Z",
          "shell.execute_reply": "2023-06-26T03:43:56.274277Z"
        },
        "trusted": true,
        "id": "Qk5pTdDzDp5-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=list(char_to_num.keys()),\n",
        "        values=list(char_to_num.values()),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name=\"class_weight\"\n",
        ")\n",
        "\n",
        "def preprocess_fn(landmarks, phrase):\n",
        "\n",
        "    phrase = start_token + phrase + end_token\n",
        "    phrase = tf.strings.bytes_split(phrase)\n",
        "    phrase = table.lookup(phrase)\n",
        "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
        "                    constant_values = pad_token_idx)\n",
        "\n",
        "    # landmarksを前処理する\n",
        "    translated_landmarks = translate_landmarks(landmarks, max_translation=10)\n",
        "    #scaled_landmarks = scale_landmarks(landmarks, min_scale=0.8, max_scale=1.2)\n",
        "\n",
        "    # 前処理済みのlandmarksを結合する\n",
        "    #combined_landmarks = tf.concat([landmarks, translated_landmarks, scaled_landmarks], axis=1)\n",
        "    combined_landmarks = tf.concat([landmarks, translated_landmarks], axis=1)\n",
        "    return pre_process(combined_landmarks), phrase\n",
        "\n",
        "def preprocess_frame(landmarks, phrase):\n",
        "    # landmarks_dfをフレームごとに分割し、フレームごとのデータをリストに追加\n",
        "    for frame_idx in range(len(landmarks_df) - FRAME_LEN + 1):\n",
        "        frame = landmarks_df[frame_idx : frame_idx + FRAME_LEN]\n",
        "        frames.append(frame)\n",
        "\n",
        "    # フレームごとに特徴ベクトルを抽出\n",
        "    feature_vectors = extract_feature_vectors(frames)\n",
        "    return pre_process(combined_landmarks), phrase\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n",
        "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "    phrase = features[\"phrase\"]\n",
        "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n",
        "    landmarks = tf.transpose(landmarks)\n",
        "\n",
        "    return landmarks, phrase\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:57.838702Z",
          "iopub.execute_input": "2023-06-26T03:43:57.839078Z",
          "iopub.status.idle": "2023-06-26T03:43:59.156543Z",
          "shell.execute_reply.started": "2023-06-26T03:43:57.839049Z",
          "shell.execute_reply": "2023-06-26T03:43:59.155472Z"
        },
        "trusted": true,
        "id": "GK-wOj8CDp5_",
        "outputId": "50b77fb5-9da1-4c3d-c2e1-7937b39cf6b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inpdir = \"/content/aslfr-parquets-to-tfrecords-cleaned\"\n",
        "tffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n",
        "\n",
        "batch_size = 32\n",
        "val_len = int(0.05 * len(tffiles))\n",
        "\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "iHkk4dcB0fce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model"
      ],
      "metadata": {
        "id": "PufJODDjDp5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:e865f0c6-0e14-4387-9779-537f8b3d065d.png)\n",
        "![image.png](attachment:39ec8854-9e5f-4617-aa6a-69098b605134.png)\n",
        "![image.png](attachment:8b28cc87-2b4a-467f-a818-44b7e1f8dc8f.png)\n",
        "![image.png](attachment:243f34f9-3f88-4452-aac7-ee1ec0a3d065.png)"
      ],
      "metadata": {
        "id": "35kTT5MRDp5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I implemented proper positional embeddings for both the encoder and the decoder."
      ],
      "metadata": {
        "id": "su-6MWcSDp6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_hid=64, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.mlp = tf.keras.Sequential()\n",
        "        for _ in range(num_layers):\n",
        "            self.mlp.add(tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu))\n",
        "        self.mlp.add(tf.keras.layers.Dense(num_hid))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.mlp(inputs)\n",
        "\n",
        "\n",
        "class TokenEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64, mlp_num_layers=2):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = self.positional_encoding(maxlen - 1, num_hid)\n",
        "        self.mlp_block = MLPBlock(num_hid, num_layers=mlp_num_layers)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x) * tf.math.sqrt(tf.cast(self.num_hid, tf.float32))\n",
        "        x = x + self.pos_emb[:maxlen, :]\n",
        "        x = self.mlp_block(x)\n",
        "        return x\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depth = num_hid // 2\n",
        "        angles = positions / tf.pow(10000, tf.range(0, depth, 1, dtype=tf.float32) / num_hid)  # depthのインクリメントを修正\n",
        "        pos_encoding = tf.concat([tf.sin(angles), tf.cos(angles)], axis=-1)\n",
        "        return pos_encoding\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:00.656849Z",
          "iopub.execute_input": "2023-06-26T03:44:00.659000Z",
          "iopub.status.idle": "2023-06-26T03:44:00.672227Z",
          "shell.execute_reply.started": "2023-06-26T03:44:00.658953Z",
          "shell.execute_reply": "2023-06-26T03:44:00.671099Z"
        },
        "trusted": true,
        "id": "9QJUkdQeDp6A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "        '''\n",
        "        self.pos_emb = tf.math.divide(\n",
        "            self.positional_encoding(maxlen-1, num_hid),\n",
        "            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n",
        "        '''\n",
        "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        '''\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "        '''\n",
        "        return x + self.pos_emb[:maxlen, :]\n",
        "    \n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T01:27:59.514789Z",
          "iopub.execute_input": "2023-06-22T01:27:59.517058Z",
          "iopub.status.idle": "2023-06-22T01:27:59.530952Z",
          "shell.execute_reply.started": "2023-06-22T01:27:59.517017Z",
          "shell.execute_reply": "2023-06-22T01:27:59.529987Z"
        },
        "id": "0K45t4ttDp6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkEmbedding(tf.keras.Model):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super(LandmarkEmbedding, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu1 = tf.keras.layers.LeakyReLU()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu2 = tf.keras.layers.LeakyReLU()\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu3 = tf.keras.layers.LeakyReLU()\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu4 = tf.keras.layers.LeakyReLU()\n",
        "        self.dropout4 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
        "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
        "        self.maxlen = maxlen\n",
        "        self.num_hid = num_hid\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.leaky_relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.leaky_relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.leaky_relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.leaky_relu4(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb\n",
        "\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
        "        return pos_encoding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:02.337798Z",
          "iopub.execute_input": "2023-06-26T03:44:02.338456Z",
          "iopub.status.idle": "2023-06-26T03:44:02.358498Z",
          "shell.execute_reply.started": "2023-06-26T03:44:02.338424Z",
          "shell.execute_reply": "2023-06-26T03:44:02.357547Z"
        },
        "trusted": true,
        "id": "yhso_UunDp6A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:04.520721Z",
          "iopub.execute_input": "2023-06-26T03:44:04.521113Z",
          "iopub.status.idle": "2023-06-26T03:44:04.530882Z",
          "shell.execute_reply.started": "2023-06-26T03:44:04.521080Z",
          "shell.execute_reply": "2023-06-26T03:44:04.529251Z"
        },
        "trusted": true,
        "id": "N8Lugl97Dp6B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# TFRecordファイルのパス\n",
        "tfrecord_file = \"/kaggle/working/tfds/128822441.tfrecord\"\n",
        "\n",
        "# TFRecordデータセットの作成\n",
        "dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
        "print(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:07.559213Z",
          "iopub.execute_input": "2023-06-26T03:44:07.560180Z",
          "iopub.status.idle": "2023-06-26T03:44:07.577877Z",
          "shell.execute_reply.started": "2023-06-26T03:44:07.560136Z",
          "shell.execute_reply": "2023-06-26T03:44:07.576727Z"
        },
        "trusted": true,
        "id": "PryRJHouDp6B",
        "outputId": "0390ab49-6fd3-4fb3-b4bc-7742b696638a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I added the training flag to the TransformerDecoder's Dropout layers."
      ],
      "metadata": {
        "id": "6Ul8pZtNDp6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target, training):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:08.748287Z",
          "iopub.execute_input": "2023-06-26T03:44:08.748649Z",
          "iopub.status.idle": "2023-06-26T03:44:08.764270Z",
          "shell.execute_reply.started": "2023-06-26T03:44:08.748619Z",
          "shell.execute_reply": "2023-06-26T03:44:08.762681Z"
        },
        "trusted": true,
        "id": "lbmu0lqMDp6C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I made the passing of the training flag explicit."
      ],
      "metadata": {
        "id": "IxjuUK90Dp6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target, training):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source, training)\n",
        "        y = self.decode(x, target, training)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source, training = False)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input, training = False)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = logits[:, -1][..., tf.newaxis]\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:11.821637Z",
          "iopub.execute_input": "2023-06-26T03:44:11.822020Z",
          "iopub.status.idle": "2023-06-26T03:44:11.845701Z",
          "shell.execute_reply.started": "2023-06-26T03:44:11.821989Z",
          "shell.execute_reply": "2023-06-26T03:44:11.844544Z"
        },
        "trusted": true,
        "id": "FMzXwlaNDp6D"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解率を計算するためのメトリクスを作成\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# 学習ループ内で正解率を更新するコールバックを定義\n",
        "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_acc = train_accuracy.result()\n",
        "        val_acc = val_accuracy.result()\n",
        "        print(f\"Epoch {epoch+1}: Train Accuracy = {train_acc}, Validation Accuracy = {val_acc}\")\n",
        "        # 正解率をリセット\n",
        "        train_accuracy.reset_states()\n",
        "        val_accuracy.reset_states()\n",
        "# val_lossが連続3回マイナスになった場合に学習を停止するコールバック\n",
        "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=3):\n",
        "        super(EarlyStoppingCallback, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.min_val_loss = float('inf')\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        if val_loss < self.min_val_loss:\n",
        "            self.min_val_loss = val_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stopped due to early stopping.\")\n",
        "\n",
        "batch = next(iter(val_dataset))\n",
        "idx_to_char = list(char_to_num.keys())\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=4,\n",
        "    num_feed_forward=400,\n",
        "    source_maxlen = FRAME_LEN,\n",
        "    target_maxlen=64,\n",
        "    num_layers_enc=2,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=62,\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "accuracy_callback = AccuracyCallback()\n",
        "optimizer = keras.optimizers.Adam(0.0001)\n",
        "\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_accuracy])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:45:35.856212Z",
          "iopub.execute_input": "2023-06-26T03:45:35.856580Z",
          "iopub.status.idle": "2023-06-26T03:45:36.221753Z",
          "shell.execute_reply.started": "2023-06-26T03:45:35.856550Z",
          "shell.execute_reply": "2023-06-26T03:45:36.220648Z"
        },
        "trusted": true,
        "id": "qZRLTg89Dp6D"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# EarlyStoppingCallbackをコールバックリストに追加して学習を行う\n",
        "history = model.fit(train_dataset, verbose=2, validation_data=val_dataset, epochs=100,\n",
        "                    callbacks=[AccuracyCallback(), EarlyStoppingCallback()])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:45:40.633802Z",
          "iopub.execute_input": "2023-06-26T03:45:40.634201Z",
          "iopub.status.idle": "2023-06-26T04:23:16.771818Z",
          "shell.execute_reply.started": "2023-06-26T03:45:40.634167Z",
          "shell.execute_reply": "2023-06-26T04:23:16.769586Z"
        },
        "trusted": true,
        "id": "rLPhxPFzDp6E",
        "outputId": "82654bca-1090-4f4b-fae5-70872dcfb29e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 528s - loss: 0.7910 - val_loss: 0.6529 - 528s/epoch - 347ms/step\n",
            "Epoch 2/100\n",
            "Epoch 2: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.5748 - val_loss: 0.5366 - 138s/epoch - 91ms/step\n",
            "Epoch 3/100\n",
            "Epoch 3: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 139s - loss: 0.5127 - val_loss: 0.5065 - 139s/epoch - 91ms/step\n",
            "Epoch 4/100\n",
            "Epoch 4: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 139s - loss: 0.4853 - val_loss: 0.4826 - 139s/epoch - 91ms/step\n",
            "Epoch 5/100\n",
            "Epoch 5: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 140s - loss: 0.4673 - val_loss: 0.4727 - 140s/epoch - 92ms/step\n",
            "Epoch 6/100\n",
            "Epoch 6: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 141s - loss: 0.4537 - val_loss: 0.4630 - 141s/epoch - 93ms/step\n",
            "Epoch 7/100\n",
            "Epoch 7: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.4427 - val_loss: 0.4557 - 138s/epoch - 91ms/step\n",
            "Epoch 8/100\n",
            "Epoch 8: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 144s - loss: 0.4343 - val_loss: 0.4513 - 144s/epoch - 95ms/step\n",
            "Epoch 9/100\n",
            "Epoch 9: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 137s - loss: 0.4267 - val_loss: 0.4487 - 137s/epoch - 90ms/step\n",
            "Epoch 10/100\n",
            "Epoch 10: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 143s - loss: 0.4198 - val_loss: 0.4431 - 143s/epoch - 94ms/step\n",
            "Epoch 11/100\n",
            "Epoch 11: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 137s - loss: 0.4139 - val_loss: 0.4405 - 137s/epoch - 90ms/step\n",
            "Epoch 12/100\n",
            "Epoch 12: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.4083 - val_loss: 0.4426 - 138s/epoch - 91ms/step\n",
            "Epoch 13/100\n",
            "Epoch 13: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.4032 - val_loss: 0.4363 - 138s/epoch - 91ms/step\n",
            "Epoch 14/100\n",
            "Epoch 14: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.3982 - val_loss: 0.4377 - 138s/epoch - 91ms/step\n",
            "Epoch 15/100\n",
            "Epoch 15: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.3941 - val_loss: 0.4318 - 138s/epoch - 91ms/step\n",
            "Epoch 16/100\n",
            "Epoch 16: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 139s - loss: 0.3898 - val_loss: 0.4332 - 139s/epoch - 92ms/step\n",
            "Epoch 17/100\n",
            "Epoch 17: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 138s - loss: 0.3856 - val_loss: 0.4325 - 138s/epoch - 91ms/step\n",
            "Epoch 18/100\n",
            "Epoch 18: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "Training stopped due to early stopping.\n",
            "1520/1520 - 138s - loss: 0.3818 - val_loss: 0.4343 - 138s/epoch - 91ms/step\n",
            "CPU times: user 1h 10min 30s, sys: 3min 42s, total: 1h 14min 13s\n",
            "Wall time: 49min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:22.467839Z",
          "iopub.execute_input": "2023-06-26T04:23:22.468542Z",
          "iopub.status.idle": "2023-06-26T04:23:22.523050Z",
          "shell.execute_reply.started": "2023-06-26T04:23:22.468503Z",
          "shell.execute_reply": "2023-06-26T04:23:22.522121Z"
        },
        "trusted": true,
        "id": "m0PK7-zbDp6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:25.874327Z",
          "iopub.execute_input": "2023-06-26T04:23:25.874717Z",
          "iopub.status.idle": "2023-06-26T04:23:26.232494Z",
          "shell.execute_reply.started": "2023-06-26T04:23:25.874667Z",
          "shell.execute_reply": "2023-06-26T04:23:26.231586Z"
        },
        "trusted": true,
        "id": "BHA4qBuLDp6E",
        "outputId": "7e3b12bb-9444-4a63-81e5-a7fc5eef8d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2b72f2a470>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "SywRcwtGDp6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [batch for batch in val_dataset]\n",
        "\n",
        "preds_list = []\n",
        "ground_truth_list = []\n",
        "\n",
        "for batch in batches[:1]:\n",
        "    source = batch[0]\n",
        "    target = batch[1].numpy()\n",
        "    bs = tf.shape(source)[0]\n",
        "    preds = model.generate(source, start_token_idx)\n",
        "    preds = preds.numpy()\n",
        "\n",
        "    for i in range(bs):\n",
        "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
        "        ground_truth_list.append(target_text.replace('P', ''))\n",
        "        prediction = \"\"\n",
        "        for idx in preds[i, :]:\n",
        "            prediction += idx_to_char[idx]\n",
        "            if idx == end_token_idx:\n",
        "                break\n",
        "        preds_list.append(prediction)\n",
        "\n",
        "for i in range(10):\n",
        "    print(ground_truth_list[i])\n",
        "    print(preds_list[i])\n",
        "    print('\\n~~~\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:33.831503Z",
          "iopub.execute_input": "2023-06-26T04:23:33.832760Z",
          "iopub.status.idle": "2023-06-26T04:23:40.926369Z",
          "shell.execute_reply.started": "2023-06-26T04:23:33.832713Z",
          "shell.execute_reply": "2023-06-26T04:23:40.925390Z"
        },
        "trusted": true,
        "id": "CTn5dZ8ADp6F",
        "outputId": "64771ae5-a0ca-40fe-f804-e31a958fe8eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 creekhouseE\n",
            "S3 crekhouseE\n",
            "\n",
            "~~~\n",
            "\n",
            "Sscales/kuhaylahE\n",
            "Sscales chauhaylaE\n",
            "\n",
            "~~~\n",
            "\n",
            "S1383 william lanierE\n",
            "S1386 william lanierE\n",
            "\n",
            "~~~\n",
            "\n",
            "S988 franklin laneE\n",
            "S988 funkland laneE\n",
            "\n",
            "~~~\n",
            "\n",
            "S6920 northeast 661st roadE\n",
            "S6920 northeast 66tst roadE\n",
            "\n",
            "~~~\n",
            "\n",
            "Swww.freem.ne.jpE\n",
            "Swww.freem.meE\n",
            "\n",
            "~~~\n",
            "\n",
            "Shttps://jsi.is/hukuokaE\n",
            "Shttps://jsi.itis/hturokaE\n",
            "\n",
            "~~~\n",
            "\n",
            "S239613 stolze streetE\n",
            "S23961 tolzolz street roadE\n",
            "\n",
            "~~~\n",
            "\n",
            "S271097 bayshore boulevardE\n",
            "S271097 bay doreboulevardE\n",
            "\n",
            "~~~\n",
            "\n",
            "Sfederico pearsonE\n",
            "S9 dericon aroonE\n",
            "\n",
            "~~~\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
        "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
        "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n",
        "            for i in range(len(preds_list_processed))]\n",
        "N = [len(phrase) for phrase in ground_truth_processed]\n",
        "\n",
        "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:45.163446Z",
          "iopub.execute_input": "2023-06-26T04:23:45.163846Z",
          "iopub.status.idle": "2023-06-26T04:23:45.171850Z",
          "shell.execute_reply.started": "2023-06-26T04:23:45.163812Z",
          "shell.execute_reply": "2023-06-26T04:23:45.170820Z"
        },
        "trusted": true,
        "id": "naN88UcIDp6F",
        "outputId": "683a56eb-1347-4fae-853c-0da9d2ef3947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.7667238421955404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLiteModel"
      ],
      "metadata": {
        "id": "ucgKzMf4Dp6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " class TFLiteModel(tf.keras.Model):\n",
        "    def __init__(self, model):\n",
        "        super(TFLiteModel, self).__init__()\n",
        "        self.target_start_token_idx = start_token_idx\n",
        "        self.target_end_token_idx = end_token_idx\n",
        "        # Load the feature generation and main models\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n",
        "    def __call__(self, inputs, training=False):\n",
        "        # Preprocess Data\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = x[None]\n",
        "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n",
        "        x = x[0]\n",
        "        x = pre_process(x)\n",
        "        x = x[None]\n",
        "        x = self.model.generate(x, self.target_start_token_idx)\n",
        "        x = x[0]\n",
        "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
        "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
        "        x = x[1:idx]\n",
        "        x = tf.one_hot(x, 59)\n",
        "        return {'outputs': x}\n",
        "\n",
        "tflitemodel_base = TFLiteModel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:47.474886Z",
          "iopub.execute_input": "2023-06-26T04:23:47.476016Z",
          "iopub.status.idle": "2023-06-26T04:23:47.488141Z",
          "shell.execute_reply.started": "2023-06-26T04:23:47.475971Z",
          "shell.execute_reply": "2023-06-26T04:23:47.487131Z"
        },
        "trusted": true,
        "id": "tEcGTaJ2Dp6G",
        "outputId": "ff248e67-a6fb-4332-c5ef-8f6f1126e015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2c99857cd405>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtflitemodel_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFLiteModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:50.183480Z",
          "iopub.execute_input": "2023-06-26T04:23:50.184185Z",
          "iopub.status.idle": "2023-06-26T04:23:50.376400Z",
          "shell.execute_reply.started": "2023-06-26T04:23:50.184149Z",
          "shell.execute_reply": "2023-06-26T04:23:50.375374Z"
        },
        "trusted": true,
        "id": "yC-8CLlHDp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
        "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = keras_model_converter.convert()\n",
        "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "infargs = {\"selected_columns\" : SEL_COLS}\n",
        "\n",
        "with open('inference_args.json', \"w\") as json_file:\n",
        "    json.dump(infargs, json_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:53.080752Z",
          "iopub.execute_input": "2023-06-26T04:23:53.081962Z",
          "iopub.status.idle": "2023-06-26T04:25:04.842986Z",
          "shell.execute_reply.started": "2023-06-26T04:23:53.081917Z",
          "shell.execute_reply": "2023-06-26T04:25:04.841993Z"
        },
        "trusted": true,
        "id": "0PxmgsFQDp6G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "ae9d9e83-7dc1-45d4-b8a8-2bf41870cded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"cond_2/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 93). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-139d7c4a996e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkeras_model_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLITE_BUILTINS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#, tf.lite.OpsSet.SELECT_TF_OPS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_model_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/model.tflite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/model.tflite'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip submission.zip  './model.tflite' './inference_args.json'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:25:07.995108Z",
          "iopub.execute_input": "2023-06-26T04:25:07.995950Z",
          "iopub.status.idle": "2023-06-26T04:25:10.415570Z",
          "shell.execute_reply.started": "2023-06-26T04:25:07.995914Z",
          "shell.execute_reply": "2023-06-26T04:25:10.414236Z"
        },
        "trusted": true,
        "id": "S4U791C_Dp6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "output = prediction_fn(inputs=batch[0][0])\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print(prediction_str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:25:14.037030Z",
          "iopub.execute_input": "2023-06-26T04:25:14.037455Z",
          "iopub.status.idle": "2023-06-26T04:25:14.458201Z",
          "shell.execute_reply.started": "2023-06-26T04:25:14.037420Z",
          "shell.execute_reply": "2023-06-26T04:25:14.457173Z"
        },
        "trusted": true,
        "id": "YpI1MlRqDp6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KxaL1qFDp6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}