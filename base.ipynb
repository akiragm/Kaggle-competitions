{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ColabPreprocess  --START\n",
        "置換<br>\n",
        "\n",
        "/kaggle/input/  <br>\n",
        "/content/"
      ],
      "metadata": {
        "id": "uIY3gyjVDW16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "9D2OX6U0CaH6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! apt update\n",
        "! apt install gcsfuse"
      ],
      "metadata": {
        "outputId": "18407b6a-1ad8-4a99-dc58-810147bc8eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qpeTkECaH7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0  73861      0 --:--:-- --:--:-- --:--:-- 73861\n",
            "OK\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:8 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,004 B]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,070 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,866 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,369 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,347 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,081 kB]\n",
            "Get:14 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [2,356 B]\n",
            "Err:15 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "  Could not connect to ppa.launchpad.net:80 (185.125.190.52), connection timed out [IP: 185.125.190.52 80]\n",
            "Err:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "  Unable to connect to ppa.launchpad.net:http: [IP: 185.125.190.52 80]\n",
            "Err:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "  Unable to connect to ppa.launchpad.net:http: [IP: 185.125.190.52 80]\n",
            "Err:18 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "  Unable to connect to ppa.launchpad.net:http: [IP: 185.125.190.52 80]\n",
            "Fetched 10.1 MB in 30s (332 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "15 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mFailed to fetch http://ppa.launchpad.net/cran/libgit2/ubuntu/dists/focal/InRelease  Could not connect to ppa.launchpad.net:80 (185.125.190.52), connection timed out [IP: 185.125.190.52 80]\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mFailed to fetch http://ppa.launchpad.net/deadsnakes/ppa/ubuntu/dists/focal/InRelease  Unable to connect to ppa.launchpad.net:http: [IP: 185.125.190.52 80]\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mFailed to fetch http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu/dists/focal/InRelease  Unable to connect to ppa.launchpad.net:http: [IP: 185.125.190.52 80]\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mFailed to fetch http://ppa.launchpad.net/ubuntugis/ppa/ubuntu/dists/focal/InRelease  Unable to connect to ppa.launchpad.net:http: [IP: 185.125.190.52 80]\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mSome index files failed to download. They have been ignored, or old ones used instead.\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 14.0 MB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 1.0.0 [14.0 MB]\n",
            "Fetched 14.0 MB in 1s (27.6 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 123105 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_1.0.0_amd64.deb ...\n",
            "Unpacking gcsfuse (1.0.0) ...\n",
            "Setting up gcsfuse (1.0.0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5f_lFB9TCaH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kaggle get_gcspath\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "print(KaggleDatasets().get_gcs_path())"
      ],
      "metadata": {
        "id": "1GmDR8Lh1fku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3Q0v8LEtnE",
        "outputId": "a860b38b-94f2-490a-f1fc-eea66d643685"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p asl-fingerspelling\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-7a1de6f6fb09cdad50ebab8364ce5c9e2937606d5437de561aab1448 asl-fingerspelling"
      ],
      "metadata": {
        "id": "olczO1_pC2TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f098309c-d088-475c-869c-c45fc06b6250"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0712 02:13:18.466226 2023/07/12 02:13:18.466162 Start gcsfuse/1.0.0 (Go version go1.20.4) for app \"\" using mount point: /content/asl-fingerspelling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p aslfr-parquets-to-tfrecords-cleaned\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-6720764106d040caa24754175e3c58fcbf8d829fba1b2c2d59149b30 aslfr-parquets-to-tfrecords-cleaned"
      ],
      "metadata": {
        "outputId": "c078897e-5d2b-436f-d6a9-4efab3a2ccf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2KWdEtVCaH9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0712 02:13:21.136178 2023/07/12 02:13:21.136134 Start gcsfuse/1.0.0 (Go version go1.20.4) for app \"\" using mount point: /content/aslfr-parquets-to-tfrecords-cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esy-KMuR8ivw",
        "outputId": "a54b7684-d243-4771-ea4e-e465ee9ddcfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8L77lmNJEQYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --END  ColabPreprocess"
      ],
      "metadata": {
        "id": "ZDYAPQiVEATw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. I used two transformer layer in the encoder instead of four.\n",
        "2. I used four attention heads instead of two.\n",
        "3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n",
        "2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n",
        "3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n",
        "4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n",
        "5. I added positional embedding to the encoder. This, too, had a significant impact.\n"
      ],
      "metadata": {
        "id": "ZDWdHG-n3D4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import Levenshtein as lev\n",
        "import os\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:06.160562Z",
          "iopub.execute_input": "2023-07-12T00:41:06.160885Z",
          "iopub.status.idle": "2023-07-12T00:41:15.771270Z",
          "shell.execute_reply.started": "2023-07-12T00:41:06.160858Z",
          "shell.execute_reply": "2023-07-12T00:41:15.770254Z"
        },
        "trusted": true,
        "id": "7RmQuWvj3D4f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "4ZCG_2Ml3D4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "0973wX8O3D4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_landmarks = pd.read_parquet('/content/asl-fingerspelling/train_landmarks/1019715464.parquet')\n",
        "keys = train_landmarks.keys()[1:]\n",
        "train_landmarks.head()"
      ],
      "metadata": {
        "id": "mV5fnqEi3D4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFRecord"
      ],
      "metadata": {
        "id": "wTZS8Qxe3D4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "77XX9Lel3D4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))"
      ],
      "metadata": {
        "id": "n-vOTOB73D4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
        "\n",
        "counter = 0\n",
        "for file_id in tqdm(df.file_id.unique()):\n",
        "    \n",
        "    print(counter)\n",
        "    counter+=1\n",
        "    \n",
        "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
        "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
        "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
        "    seq_refs = df.loc[df.file_id == file_id]\n",
        "    seqs = load_relevant_data_subset(pqfile)\n",
        "    seqs_numpy = seqs.to_numpy()\n",
        "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
        "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
        "            frames = seqs_numpy[seqs.index == seq_id]\n",
        "            \n",
        "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
        "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
        "            no_nan = max(r_nonan, l_nonan)\n",
        "            \n",
        "            if 2*len(phrase)<no_nan:\n",
        "                features = {SEL_COLS[i]: tf.train.Feature(\n",
        "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n",
        "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
        "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
        "                file_writer.write(record_bytes)"
      ],
      "metadata": {
        "id": "ShX-eGAV3D4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "6aC8op943D4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs)."
      ],
      "metadata": {
        "id": "V1yIVyUZ3D4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = 'P'\n",
        "start_token = 'S'\n",
        "end_token = 'E'\n",
        "pad_token_idx = 59\n",
        "start_token_idx = 60\n",
        "end_token_idx = 61"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:15.776677Z",
          "iopub.execute_input": "2023-07-12T00:41:15.779291Z",
          "iopub.status.idle": "2023-07-12T00:41:15.789291Z",
          "shell.execute_reply.started": "2023-07-12T00:41:15.779257Z",
          "shell.execute_reply": "2023-07-12T00:41:15.784660Z"
        },
        "trusted": true,
        "id": "Z2NX_XA43D4w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    char_to_num = json.load(f)\n",
        "\n",
        "\n",
        "char_to_num[pad_token] = pad_token_idx\n",
        "char_to_num[start_token] = start_token_idx\n",
        "char_to_num[end_token] = end_token_idx\n",
        "\n",
        "num_to_char = {j:i for i,j in char_to_num.items()}\n",
        "\n",
        "\n",
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "\n",
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print(RPOSE_IDX)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:15.790672Z",
          "iopub.execute_input": "2023-07-12T00:41:15.791217Z",
          "iopub.status.idle": "2023-07-12T00:41:16.008386Z",
          "shell.execute_reply.started": "2023-07-12T00:41:15.791187Z",
          "shell.execute_reply": "2023-07-12T00:41:16.007456Z"
        },
        "trusted": true,
        "id": "vIrIgs3S3D4x",
        "outputId": "0a14f688-1324-4d24-933b-0cd3393c5ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 48, 49, 50, 51, 99, 100, 101, 102, 103, 151, 152, 153, 154, 155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_pad(x):\n",
        "    if tf.shape(x)[0] < FRAME_LEN:\n",
        "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
        "        print(x)\n",
        "    else:\n",
        "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
        "    return x\n",
        "\n",
        "def translate_landmarks(landmarks, max_translation):\n",
        "    translation = tf.random.uniform(shape=(1,), minval=-max_translation, maxval=max_translation)\n",
        "    translated_landmarks = landmarks + translation\n",
        "    return translated_landmarks\n",
        "\n",
        "def scale_landmarks(landmarks, min_scale, max_scale):\n",
        "    scale_factor = tf.random.uniform(shape=(1,), minval=min_scale, maxval=max_scale)\n",
        "    scaled_landmarks = landmarks * scale_factor\n",
        "    return scaled_landmarks\n",
        "\n",
        "def pre_process(x):\n",
        "\n",
        "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
        "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
        "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
        "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
        "\n",
        "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
        "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
        "\n",
        "    rnans = tf.math.count_nonzero(rnan_idx)\n",
        "    lnans = tf.math.count_nonzero(lnan_idx)\n",
        "\n",
        "    # For dominant hand\n",
        "    if rnans > lnans:\n",
        "        hand = lhand\n",
        "        pose = lpose\n",
        "\n",
        "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
        "\n",
        "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
        "    else:\n",
        "        hand = rhand\n",
        "        pose = rpose\n",
        "\n",
        "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
        "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
        "    hand = (hand - mean) / std\n",
        "\n",
        "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    x = tf.concat([hand, pose], axis=1)\n",
        "    x = resize_pad(x)\n",
        "\n",
        "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:16.013623Z",
          "iopub.execute_input": "2023-07-12T00:41:16.016021Z",
          "iopub.status.idle": "2023-07-12T00:41:16.044860Z",
          "shell.execute_reply.started": "2023-07-12T00:41:16.015984Z",
          "shell.execute_reply": "2023-07-12T00:41:16.043734Z"
        },
        "trusted": true,
        "id": "CwsIEjSx3D4y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=list(char_to_num.keys()),\n",
        "        values=list(char_to_num.values()),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name=\"class_weight\"\n",
        ")\n",
        "\n",
        "def preprocess_fn(landmarks, phrase):\n",
        "    phrase = start_token + phrase + end_token\n",
        "    phrase = tf.strings.bytes_split(phrase)\n",
        "    phrase = table.lookup(phrase)\n",
        "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
        "                    constant_values = pad_token_idx)\n",
        "\n",
        "    # landmarksを前処理する\n",
        "    if tf.random.uniform(()) < 0.5:  # Random chance to perform translation\n",
        "        landmarks = translate_landmarks(landmarks, max_translation=10)\n",
        "    if tf.random.uniform(()) < 0.5:  # Random chance to perform scaling\n",
        "        landmarks = scale_landmarks(landmarks, min_scale=0.8, max_scale=1.2)\n",
        "\n",
        "    return pre_process(landmarks), phrase\n",
        "\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n",
        "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "    phrase = features[\"phrase\"]\n",
        "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n",
        "    landmarks = tf.transpose(landmarks)\n",
        "\n",
        "    return landmarks, phrase\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:16.046274Z",
          "iopub.execute_input": "2023-07-12T00:41:16.046794Z",
          "iopub.status.idle": "2023-07-12T00:41:21.367621Z",
          "shell.execute_reply.started": "2023-07-12T00:41:16.046762Z",
          "shell.execute_reply": "2023-07-12T00:41:21.366623Z"
        },
        "trusted": true,
        "id": "4qLrqdoW3D4z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inpdir = \"/content/aslfr-parquets-to-tfrecords-cleaned\"\n",
        "tffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n",
        "\n",
        "batch_size = 32\n",
        "val_len = int(0.05 * len(tffiles))\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "Tf0xDk_O8zfc",
        "outputId": "885596e8-155d-47d9-ae36-9b1de76bd1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"cond_3/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
            "Tensor(\"cond_3/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model"
      ],
      "metadata": {
        "id": "XrwFS5h03D41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.369610Z",
          "iopub.execute_input": "2023-07-12T00:41:21.369989Z",
          "iopub.status.idle": "2023-07-12T00:41:21.385138Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.369955Z",
          "shell.execute_reply": "2023-07-12T00:41:21.384105Z"
        },
        "trusted": true,
        "id": "RYHzcYzp3D41",
        "outputId": "a06565e3-6f48-4691-fc99-76f69a889df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "SEL_COLS size:156\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I implemented proper positional embeddings for both the encoder and the decoder."
      ],
      "metadata": {
        "id": "u9Erb4iq3D42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_hid=64, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.mlp = tf.keras.Sequential()\n",
        "        for _ in range(num_layers):\n",
        "            self.mlp.add(tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu))\n",
        "        self.mlp.add(tf.keras.layers.Dense(num_hid))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.mlp(inputs)\n",
        "\n",
        "\n",
        "class TokenEmbedding(keras.layers.Layer):\n",
        "    def __init__(self, num_vocab=61, maxlen=50, num_hid=256, mlp_num_layers=5):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = self.positional_encoding(maxlen - 1, num_hid)\n",
        "        self.mlp_block = MLPBlock(num_hid, num_layers=mlp_num_layers)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x) * tf.math.sqrt(tf.cast(self.num_hid, tf.float32))\n",
        "        x = x + self.pos_emb[:maxlen, :]\n",
        "        x = self.mlp_block(x)\n",
        "        return x\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depth = num_hid // 2\n",
        "        angles = positions / tf.pow(10000, tf.range(0, depth, 1, dtype=tf.float32) / num_hid)  # depthのインクリメントを修正\n",
        "        pos_encoding = tf.concat([tf.sin(angles), tf.cos(angles)], axis=-1)\n",
        "        return pos_encoding\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.386830Z",
          "iopub.execute_input": "2023-07-12T00:41:21.387238Z",
          "iopub.status.idle": "2023-07-12T00:41:21.406429Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.387208Z",
          "shell.execute_reply": "2023-07-12T00:41:21.405537Z"
        },
        "trusted": true,
        "id": "0HslbkR83D43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "        '''\n",
        "        self.pos_emb = tf.math.divide(\n",
        "            self.positional_encoding(maxlen-1, num_hid),\n",
        "            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n",
        "        '''\n",
        "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        '''\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "        '''\n",
        "        return x + self.pos_emb[:maxlen, :]\n",
        "    \n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zh4liqdb3D44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkEmbedding(tf.keras.Model):\n",
        "    def __init__(self, num_hid=256, maxlen=100):\n",
        "        super(LandmarkEmbedding, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu1 = tf.keras.layers.LeakyReLU()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu2 = tf.keras.layers.LeakyReLU()\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu3 = tf.keras.layers.LeakyReLU()\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        self.leaky_relu4 = tf.keras.layers.LeakyReLU()\n",
        "        self.dropout4 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
        "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
        "        self.maxlen = maxlen\n",
        "        self.num_hid = num_hid\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.leaky_relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.leaky_relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.leaky_relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.leaky_relu4(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb\n",
        "\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
        "        return pos_encoding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.407904Z",
          "iopub.execute_input": "2023-07-12T00:41:21.408335Z",
          "iopub.status.idle": "2023-07-12T00:41:21.426903Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.408305Z",
          "shell.execute_reply": "2023-07-12T00:41:21.425895Z"
        },
        "trusted": true,
        "id": "hhEzMMAN3D45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.428424Z",
          "iopub.execute_input": "2023-07-12T00:41:21.428823Z",
          "iopub.status.idle": "2023-07-12T00:41:21.440879Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.428794Z",
          "shell.execute_reply": "2023-07-12T00:41:21.439946Z"
        },
        "trusted": true,
        "id": "Fhr9HWVb3D46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I added the training flag to the TransformerDecoder's Dropout layers."
      ],
      "metadata": {
        "id": "6cbOcrFK3D47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target, training):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.442406Z",
          "iopub.execute_input": "2023-07-12T00:41:21.442727Z",
          "iopub.status.idle": "2023-07-12T00:41:21.458169Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.442698Z",
          "shell.execute_reply": "2023-07-12T00:41:21.457097Z"
        },
        "trusted": true,
        "id": "Y35bT4wb3D48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I made the passing of the training flag explicit."
      ],
      "metadata": {
        "id": "McbjptyD3D49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target, training):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source, training)\n",
        "        y = self.decode(x, target, training)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source, training = False)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input, training = False)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = logits[:, -1][..., tf.newaxis]\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.463811Z",
          "iopub.execute_input": "2023-07-12T00:41:21.464083Z",
          "iopub.status.idle": "2023-07-12T00:41:21.486855Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.464055Z",
          "shell.execute_reply": "2023-07-12T00:41:21.484527Z"
        },
        "trusted": true,
        "id": "1LDSYoCh3D49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解率を計算するためのメトリクスを作成\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# 学習ループ内で正解率を更新するコールバックを定義\n",
        "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_acc = train_accuracy.result()\n",
        "        val_acc = val_accuracy.result()\n",
        "        print(f\"Epoch {epoch+1}: Train Accuracy = {train_acc}, Validation Accuracy = {val_acc}\")\n",
        "        # 正解率をリセット\n",
        "        train_accuracy.reset_states()\n",
        "        val_accuracy.reset_states()\n",
        "# val_lossが3回マイナスになった場合に学習を停止するコールバック\n",
        "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=7):\n",
        "        super(EarlyStoppingCallback, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.min_val_loss = float('inf')\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        if val_loss < self.min_val_loss:\n",
        "            self.min_val_loss = val_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stopped due to early stopping.\")\n",
        "\n",
        "batch = next(iter(val_dataset))\n",
        "idx_to_char = list(char_to_num.keys())\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=256,\n",
        "    num_head=4,\n",
        "    num_feed_forward=400,\n",
        "    source_maxlen = FRAME_LEN,\n",
        "    target_maxlen=64,\n",
        "    num_layers_enc=3,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=62,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "accuracy_callback = AccuracyCallback()\n",
        "optimizer = keras.optimizers.Adam(0.0001)\n",
        "\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_accuracy])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:21.488296Z",
          "iopub.execute_input": "2023-07-12T00:41:21.488800Z",
          "iopub.status.idle": "2023-07-12T00:41:23.888490Z",
          "shell.execute_reply.started": "2023-07-12T00:41:21.488770Z",
          "shell.execute_reply": "2023-07-12T00:41:23.887517Z"
        },
        "trusted": true,
        "id": "RoQoEAwf3D4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modelアーキテクト\n",
        "#tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:23.892255Z",
          "iopub.execute_input": "2023-07-12T00:41:23.892542Z",
          "iopub.status.idle": "2023-07-12T00:41:23.899228Z",
          "shell.execute_reply.started": "2023-07-12T00:41:23.892518Z",
          "shell.execute_reply": "2023-07-12T00:41:23.898312Z"
        },
        "trusted": true,
        "id": "0IUChNM23D4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ##Optuna\n",
        "# pip install optuna"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:23.902440Z",
          "iopub.execute_input": "2023-07-12T00:41:23.904644Z",
          "iopub.status.idle": "2023-07-12T00:41:23.911381Z",
          "shell.execute_reply.started": "2023-07-12T00:41:23.904620Z",
          "shell.execute_reply": "2023-07-12T00:41:23.910457Z"
        },
        "trusted": true,
        "id": "yflrYw4v3D5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# EarlyStoppingCallbackをコールバックリストに追加して学習を行う\n",
        "history = model.fit(train_dataset, verbose=2, validation_data=val_dataset, epochs=100,\n",
        "                    callbacks=[AccuracyCallback(), EarlyStoppingCallback()])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T00:41:23.912787Z",
          "iopub.execute_input": "2023-07-12T00:41:23.913388Z",
          "iopub.status.idle": "2023-07-12T02:00:38.349217Z",
          "shell.execute_reply.started": "2023-07-12T00:41:23.913358Z",
          "shell.execute_reply": "2023-07-12T02:00:38.348008Z"
        },
        "trusted": true,
        "id": "7FvvtVwc3D5A",
        "outputId": "dbfdc8d4-6f7e-480d-e503-af2f207cd5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\nEpoch 1: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 226s - loss: 0.8062 - val_loss: 0.6568 - 226s/epoch - 149ms/step\nEpoch 2/100\nEpoch 2: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 185s - loss: 0.5753 - val_loss: 0.5375 - 185s/epoch - 122ms/step\nEpoch 3/100\nEpoch 3: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 179s - loss: 0.5128 - val_loss: 0.5079 - 179s/epoch - 118ms/step\nEpoch 4/100\nEpoch 4: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 170s - loss: 0.4818 - val_loss: 0.4809 - 170s/epoch - 112ms/step\nEpoch 5/100\nEpoch 5: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 193s - loss: 0.4618 - val_loss: 0.4682 - 193s/epoch - 127ms/step\nEpoch 6/100\nEpoch 6: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 181s - loss: 0.4476 - val_loss: 0.4582 - 181s/epoch - 119ms/step\nEpoch 7/100\nEpoch 7: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 208s - loss: 0.4355 - val_loss: 0.4521 - 208s/epoch - 137ms/step\nEpoch 8/100\nEpoch 8: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 193s - loss: 0.4262 - val_loss: 0.4473 - 193s/epoch - 127ms/step\nEpoch 9/100\nEpoch 9: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 202s - loss: 0.4175 - val_loss: 0.4444 - 202s/epoch - 133ms/step\nEpoch 10/100\nEpoch 10: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 208s - loss: 0.4098 - val_loss: 0.4390 - 208s/epoch - 137ms/step\nEpoch 11/100\nEpoch 11: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 203s - loss: 0.4035 - val_loss: 0.4376 - 203s/epoch - 134ms/step\nEpoch 12/100\nEpoch 12: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 206s - loss: 0.3971 - val_loss: 0.4325 - 206s/epoch - 136ms/step\nEpoch 13/100\nEpoch 13: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 202s - loss: 0.3913 - val_loss: 0.4325 - 202s/epoch - 133ms/step\nEpoch 14/100\nEpoch 14: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 187s - loss: 0.3860 - val_loss: 0.4286 - 187s/epoch - 123ms/step\nEpoch 15/100\nEpoch 15: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 191s - loss: 0.3809 - val_loss: 0.4299 - 191s/epoch - 126ms/step\nEpoch 16/100\nEpoch 16: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 198s - loss: 0.3757 - val_loss: 0.4282 - 198s/epoch - 130ms/step\nEpoch 17/100\nEpoch 17: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 192s - loss: 0.3711 - val_loss: 0.4268 - 192s/epoch - 127ms/step\nEpoch 18/100\nEpoch 18: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 192s - loss: 0.3668 - val_loss: 0.4287 - 192s/epoch - 126ms/step\nEpoch 19/100\nEpoch 19: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 198s - loss: 0.3626 - val_loss: 0.4294 - 198s/epoch - 130ms/step\nEpoch 20/100\nEpoch 20: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 202s - loss: 0.3583 - val_loss: 0.4310 - 202s/epoch - 133ms/step\nEpoch 21/100\nEpoch 21: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 203s - loss: 0.3541 - val_loss: 0.4296 - 203s/epoch - 133ms/step\nEpoch 22/100\nEpoch 22: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 202s - loss: 0.3503 - val_loss: 0.4332 - 202s/epoch - 133ms/step\nEpoch 23/100\nEpoch 23: Train Accuracy = 0.0, Validation Accuracy = 0.0\n1520/1520 - 191s - loss: 0.3464 - val_loss: 0.4331 - 191s/epoch - 126ms/step\nEpoch 24/100\nEpoch 24: Train Accuracy = 0.0, Validation Accuracy = 0.0\nTraining stopped due to early stopping.\n1520/1520 - 194s - loss: 0.3425 - val_loss: 0.4337 - 194s/epoch - 127ms/step\nCPU times: user 1h 41min 49s, sys: 5min 28s, total: 1h 47min 17s\nWall time: 1h 19min 14s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:00:38.352608Z",
          "iopub.execute_input": "2023-07-12T02:00:38.353545Z",
          "iopub.status.idle": "2023-07-12T02:00:38.404769Z",
          "shell.execute_reply.started": "2023-07-12T02:00:38.353507Z",
          "shell.execute_reply": "2023-07-12T02:00:38.403914Z"
        },
        "trusted": true,
        "id": "aT4MU6D43D5B",
        "outputId": "e5575cd8-e58a-4a4b-84a2-03158c3e3381"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"transformer\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n landmark_embedding (Landmar  (None, 128, 256)         2387456   \n kEmbedding)                                                     \n                                                                 \n token_embedding (TokenEmbed  multiple                 410624    \n ding)                                                           \n                                                                 \n sequential_4 (Sequential)   (None, 128, 256)          6162608   \n                                                                 \n transformer_decoder (Transf  multiple                 2310800   \n ormerDecoder)                                                   \n                                                                 \n dense_14 (Dense)            multiple                  15934     \n                                                                 \n=================================================================\nTotal params: 8,899,968\nTrainable params: 8,897,918\nNon-trainable params: 2,050\n_________________________________________________________________\nNone\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:07.225773Z",
          "iopub.execute_input": "2023-07-12T02:03:07.226704Z",
          "iopub.status.idle": "2023-07-12T02:03:07.475786Z",
          "shell.execute_reply.started": "2023-07-12T02:03:07.226669Z",
          "shell.execute_reply": "2023-07-12T02:03:07.474682Z"
        },
        "trusted": true,
        "id": "Dmc_Vs_f3D5B",
        "outputId": "5f77c6b0-016f-48f9-aa0b-1b5116365bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7a60bddf6680>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "8Fxn_TUt3D5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [batch for batch in val_dataset]\n",
        "\n",
        "preds_list = []\n",
        "ground_truth_list = []\n",
        "\n",
        "for batch in batches[:1]:\n",
        "    source = batch[0]\n",
        "    target = batch[1].numpy()\n",
        "    bs = tf.shape(source)[0]\n",
        "    preds = model.generate(source, start_token_idx)\n",
        "    preds = preds.numpy()\n",
        "\n",
        "    for i in range(bs):\n",
        "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
        "        ground_truth_list.append(target_text.replace('P', ''))\n",
        "        prediction = \"\"\n",
        "        for idx in preds[i, :]:\n",
        "            prediction += idx_to_char[idx]\n",
        "            if idx == end_token_idx:\n",
        "                break\n",
        "        preds_list.append(prediction)\n",
        "\n",
        "for i in range(10):\n",
        "    print(ground_truth_list[i])\n",
        "    print(preds_list[i])\n",
        "    print('\\n~~~\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:10.399504Z",
          "iopub.execute_input": "2023-07-12T02:03:10.400090Z",
          "iopub.status.idle": "2023-07-12T02:03:20.072171Z",
          "shell.execute_reply.started": "2023-07-12T02:03:10.400051Z",
          "shell.execute_reply": "2023-07-12T02:03:20.070989Z"
        },
        "trusted": true,
        "id": "2XcqFl4p3D5D",
        "outputId": "a902365d-dda4-4f1d-d79e-8d291f8e0657"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "S3 creekhouseE\nS3 creek horseE\n\n~~~\n\nSscales/kuhaylahE\nSscales couthaylaE\n\n~~~\n\nS1383 william lanierE\nS1386 william lanierE\n\n~~~\n\nS988 franklin laneE\nS988 furt 110E\n\n~~~\n\nS6920 northeast 661st roadE\nS6920 northeast 61st roadE\n\n~~~\n\nSwww.freem.ne.jpE\nSwww.freem.jpE\n\n~~~\n\nShttps://jsi.is/hukuokaE\nShttps://jsssi.is/hkuruokaE\n\n~~~\n\nS239613 stolze streetE\nS239611 st 33sthearetE\n\n~~~\n\nS271097 bayshore boulevardE\nS271097 bay tore boulevarE\n\n~~~\n\nSfederico pearsonE\nSfederico pearonE\n\n~~~\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
        "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
        "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n",
        "            for i in range(len(preds_list_processed))]\n",
        "N = [len(phrase) for phrase in ground_truth_processed]\n",
        "\n",
        "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:42.912843Z",
          "iopub.execute_input": "2023-07-12T02:03:42.913268Z",
          "iopub.status.idle": "2023-07-12T02:03:42.922640Z",
          "shell.execute_reply.started": "2023-07-12T02:03:42.913237Z",
          "shell.execute_reply": "2023-07-12T02:03:42.921677Z"
        },
        "trusted": true,
        "id": "F8EMyPau3D5E",
        "outputId": "7a556d6f-3eb3-4c34-be4a-6a3ddb0f6a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Validation score: 0.7770154373927959\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Levenstein Distance Train"
      ],
      "metadata": {
        "id": "3PwS5F3j3D5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Levenstein Distances\n",
        "def get_ld_train():\n",
        "    N = 100 if IS_INTERACTIVE else 1000\n",
        "    LD_TRAIN = []\n",
        "    for idx, (frames, phrase_true) in enumerate(zip(tqdm(X_train, total=N), y_train)):\n",
        "        # Predict Phrase and Convert to String\n",
        "        phrase_pred = predict_phrase(frames).numpy()\n",
        "        phrase_pred = outputs2phrase(phrase_pred)\n",
        "        # True Phrase Ordinal to String\n",
        "        phrase_true = outputs2phrase(phrase_true)\n",
        "        # Add Levenstein Distance\n",
        "        LD_TRAIN.append({\n",
        "            'phrase_true': phrase_true,\n",
        "            'phrase_pred': phrase_pred,\n",
        "            'levenshtein_distance': levenshtein(phrase_pred, phrase_true),\n",
        "        })\n",
        "        # Take subset in interactive mode\n",
        "        if idx == N:\n",
        "            break\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    LD_TRAIN_DF = pd.DataFrame(LD_TRAIN)\n",
        "\n",
        "    return LD_TRAIN_DF"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:46.780302Z",
          "iopub.execute_input": "2023-07-12T02:03:46.780675Z",
          "iopub.status.idle": "2023-07-12T02:03:46.791825Z",
          "shell.execute_reply.started": "2023-07-12T02:03:46.780648Z",
          "shell.execute_reply": "2023-07-12T02:03:46.790708Z"
        },
        "trusted": true,
        "id": "C289LerY3D5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLiteModel"
      ],
      "metadata": {
        "id": "yXPYfSur3D5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " class TFLiteModel(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        super(TFLiteModel, self).__init__()\n",
        "        self.target_start_token_idx = start_token_idx\n",
        "        self.target_end_token_idx = end_token_idx\n",
        "        # Load the feature generation and main models\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n",
        "    def __call__(self, inputs, training=False):\n",
        "        # Preprocess Data\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = x[None]\n",
        "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n",
        "        x = x[0]\n",
        "        x = pre_process(x)\n",
        "        x = x[None]\n",
        "        x = self.model.generate(x, self.target_start_token_idx)\n",
        "        x = x[0]\n",
        "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
        "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
        "        x = x[1:idx]\n",
        "        x = tf.one_hot(x, 59)\n",
        "        return {'outputs': x}\n",
        "\n",
        "tflitemodel_base = TFLiteModel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:49.807869Z",
          "iopub.execute_input": "2023-07-12T02:03:49.808254Z",
          "iopub.status.idle": "2023-07-12T02:03:49.820509Z",
          "shell.execute_reply.started": "2023-07-12T02:03:49.808225Z",
          "shell.execute_reply": "2023-07-12T02:03:49.819309Z"
        },
        "trusted": true,
        "id": "q62jNFIt3D5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:53.220612Z",
          "iopub.execute_input": "2023-07-12T02:03:53.221533Z",
          "iopub.status.idle": "2023-07-12T02:03:53.451831Z",
          "shell.execute_reply.started": "2023-07-12T02:03:53.221500Z",
          "shell.execute_reply": "2023-07-12T02:03:53.450449Z"
        },
        "trusted": true,
        "id": "n7LiyIW43D5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 重みの読み込み\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "# モデルの形状を表示\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:03:55.632143Z",
          "iopub.execute_input": "2023-07-12T02:03:55.632793Z",
          "iopub.status.idle": "2023-07-12T02:03:55.844587Z",
          "shell.execute_reply.started": "2023-07-12T02:03:55.632733Z",
          "shell.execute_reply": "2023-07-12T02:03:55.843616Z"
        },
        "trusted": true,
        "id": "mmIvipm83D5s",
        "outputId": "551af2fe-b8ff-4c1c-c5d3-fd59b53129a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"transformer\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n landmark_embedding (Landmar  (None, 128, 256)         2387456   \n kEmbedding)                                                     \n                                                                 \n token_embedding (TokenEmbed  multiple                 410624    \n ding)                                                           \n                                                                 \n sequential_4 (Sequential)   (None, 128, 256)          6162608   \n                                                                 \n transformer_decoder (Transf  multiple                 2310800   \n ormerDecoder)                                                   \n                                                                 \n dense_14 (Dense)            multiple                  15934     \n                                                                 \n=================================================================\nTotal params: 8,899,968\nTrainable params: 8,897,918\nNon-trainable params: 2,050\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
        "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = keras_model_converter.convert()\n",
        "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "infargs = {\"selected_columns\" : SEL_COLS}\n",
        "\n",
        "with open('inference_args.json', \"w\") as json_file:\n",
        "    json.dump(infargs, json_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:04:00.461919Z",
          "iopub.execute_input": "2023-07-12T02:04:00.462297Z",
          "iopub.status.idle": "2023-07-12T02:05:28.260310Z",
          "shell.execute_reply.started": "2023-07-12T02:04:00.462270Z",
          "shell.execute_reply": "2023-07-12T02:05:28.259193Z"
        },
        "trusted": true,
        "id": "MygKEnwt3D5t",
        "outputId": "70e17996-ced5-4a09-c532-bb28ddc1718f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Tensor(\"cond_2/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip submission.zip  './model.tflite' './inference_args.json'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:05:34.260100Z",
          "iopub.execute_input": "2023-07-12T02:05:34.260870Z",
          "iopub.status.idle": "2023-07-12T02:05:37.507028Z",
          "shell.execute_reply.started": "2023-07-12T02:05:34.260832Z",
          "shell.execute_reply": "2023-07-12T02:05:37.505759Z"
        },
        "trusted": true,
        "id": "P02lJRDR3D5u",
        "outputId": "ccc74bc4-c180-42ae-f07c-bbe9ce0ce045"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "updating: model.tflite (deflated 14%)\nupdating: inference_args.json (deflated 85%)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "output = prediction_fn(inputs=batch[0][0])\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print(prediction_str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T02:05:41.221259Z",
          "iopub.execute_input": "2023-07-12T02:05:41.221654Z",
          "iopub.status.idle": "2023-07-12T02:05:41.759109Z",
          "shell.execute_reply.started": "2023-07-12T02:05:41.221623Z",
          "shell.execute_reply": "2023-07-12T02:05:41.757359Z"
        },
        "trusted": true,
        "id": "eKivsj_33D5v",
        "outputId": "97aadf82-3a01-4a6d-9e0e-18f16157502b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/8111/\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}