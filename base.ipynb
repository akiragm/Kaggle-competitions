{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ColabPreprocess  --START\n置換<br>\n\n/kaggle/input/  <br>\n/content/","metadata":{"id":"uIY3gyjVDW16"}},{"cell_type":"code","source":"from google.colab import auth\nauth.authenticate_user()","metadata":{"id":"9D2OX6U0CaH6","execution":{"iopub.status.busy":"2023-07-12T04:36:13.649306Z","iopub.execute_input":"2023-07-12T04:36:13.650437Z","iopub.status.idle":"2023-07-12T04:36:13.712949Z","shell.execute_reply.started":"2023-07-12T04:36:13.650398Z","shell.execute_reply":"2023-07-12T04:36:13.710359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n! apt update\n! apt install gcsfuse","metadata":{"outputId":"18407b6a-1ad8-4a99-dc58-810147bc8eb5","id":"A6qpeTkECaH7","execution":{"iopub.status.busy":"2023-07-12T04:36:13.713659Z","iopub.status.idle":"2023-07-12T04:36:13.714018Z","shell.execute_reply.started":"2023-07-12T04:36:13.713848Z","shell.execute_reply":"2023-07-12T04:36:13.713864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#kaggle get_gcspath\nfrom kaggle_datasets import KaggleDatasets\nprint(KaggleDatasets().get_gcs_path())","metadata":{"id":"1GmDR8Lh1fku"}},{"cell_type":"code","source":"!pip install kaggle","metadata":{"id":"Pj3Q0v8LEtnE","outputId":"a860b38b-94f2-490a-f1fc-eea66d643685","execution":{"iopub.status.busy":"2023-07-12T04:36:13.715861Z","iopub.status.idle":"2023-07-12T04:36:13.718693Z","shell.execute_reply.started":"2023-07-12T04:36:13.718427Z","shell.execute_reply":"2023-07-12T04:36:13.718451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir -p asl-fingerspelling\n! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-7a1de6f6fb09cdad50ebab8364ce5c9e2937606d5437de561aab1448 asl-fingerspelling","metadata":{"id":"olczO1_pC2TX","outputId":"f098309c-d088-475c-869c-c45fc06b6250","execution":{"iopub.status.busy":"2023-07-12T04:36:13.720334Z","iopub.status.idle":"2023-07-12T04:36:13.720814Z","shell.execute_reply.started":"2023-07-12T04:36:13.720563Z","shell.execute_reply":"2023-07-12T04:36:13.720585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir -p aslfr-parquets-to-tfrecords-cleaned\n! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-6720764106d040caa24754175e3c58fcbf8d829fba1b2c2d59149b30 aslfr-parquets-to-tfrecords-cleaned","metadata":{"outputId":"c078897e-5d2b-436f-d6a9-4efab3a2ccf6","id":"K2KWdEtVCaH9","execution":{"iopub.status.busy":"2023-07-12T04:36:13.722528Z","iopub.status.idle":"2023-07-12T04:36:13.723001Z","shell.execute_reply.started":"2023-07-12T04:36:13.722761Z","shell.execute_reply":"2023-07-12T04:36:13.722783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install Levenshtein","metadata":{"id":"Esy-KMuR8ivw","outputId":"a54b7684-d243-4771-ea4e-e465ee9ddcfd","execution":{"iopub.status.busy":"2023-07-12T04:36:13.724923Z","iopub.status.idle":"2023-07-12T04:36:13.725413Z","shell.execute_reply.started":"2023-07-12T04:36:13.725150Z","shell.execute_reply":"2023-07-12T04:36:13.725173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"8L77lmNJEQYQ"}},{"cell_type":"markdown","source":"# --END  ColabPreprocess","metadata":{"id":"ZDYAPQiVEATw"}},{"cell_type":"markdown","source":"\n\n1. I used two transformer layer in the encoder instead of four.\n2. I used four attention heads instead of two.\n3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n5. I added positional embedding to the encoder. This, too, had a significant impact.\n","metadata":{"id":"ZDWdHG-n3D4U"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.metrics import Accuracy\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nimport json\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport Levenshtein as lev\nimport os\nimport gc","metadata":{"id":"7RmQuWvj3D4f","execution":{"iopub.status.busy":"2023-07-12T23:21:34.044861Z","iopub.execute_input":"2023-07-12T23:21:34.045273Z","iopub.status.idle":"2023-07-12T23:21:42.779173Z","shell.execute_reply.started":"2023-07-12T23:21:34.045239Z","shell.execute_reply":"2023-07-12T23:21:42.778206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{"id":"4ZCG_2Ml3D4k"}},{"cell_type":"markdown","source":"inpdir = \"/kaggle/input/asl-fingerspelling\"\ndf = pd.read_csv(f'{inpdir}/train.csv')\ndf[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\ndisplay(df.head())","metadata":{"id":"0973wX8O3D4m"}},{"cell_type":"markdown","source":"train_landmarks = pd.read_parquet('/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet')\nkeys = train_landmarks.keys()[1:]\ntrain_landmarks.head()","metadata":{"id":"mV5fnqEi3D4n"}},{"cell_type":"markdown","source":"# TFRecord","metadata":{"id":"wTZS8Qxe3D4p"}},{"cell_type":"markdown","source":"","metadata":{"id":"77XX9Lel3D4q"}},{"cell_type":"markdown","source":"LPOSE = [13, 15, 17, 19, 21]\nRPOSE = [14, 16, 18, 20, 22]\nPOSE = LPOSE + RPOSE\n\nRHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\nLHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\nPOSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n\nX = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\nY = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\nZ = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n\nSEL_COLS = X + Y + Z\nFRAME_LEN = 128\n\nX_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\nY_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\nZ_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n\nRHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\nLHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\nRPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\nLPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n\nprint('SEL_COLS size:' + str(len(SEL_COLS)))","metadata":{"id":"n-vOTOB73D4r"}},{"cell_type":"markdown","source":"def load_relevant_data_subset(pq_path):\n    return pd.read_parquet(pq_path, columns=SEL_COLS)\n\ncounter = 0\nfor file_id in tqdm(df.file_id.unique()):\n    \n    print(counter)\n    counter+=1\n    \n    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n    tffile = f\"tfds/{file_id}.tfrecord\"\n    seq_refs = df.loc[df.file_id == file_id]\n    seqs = load_relevant_data_subset(pqfile)\n    seqs_numpy = seqs.to_numpy()\n    with tf.io.TFRecordWriter(tffile) as file_writer:\n        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n            frames = seqs_numpy[seqs.index == seq_id]\n            \n            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n            no_nan = max(r_nonan, l_nonan)\n            \n            if 2*len(phrase)<no_nan:\n                features = {SEL_COLS[i]: tf.train.Feature(\n                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n                file_writer.write(record_bytes)","metadata":{"id":"ShX-eGAV3D4s"}},{"cell_type":"markdown","source":"# Data loading","metadata":{"id":"6aC8op943D4u"}},{"cell_type":"markdown","source":"#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs).","metadata":{"id":"V1yIVyUZ3D4v"}},{"cell_type":"code","source":"pad_token = 'P'\nstart_token = 'S'\nend_token = 'E'\npad_token_idx = 59\nstart_token_idx = 60\nend_token_idx = 61","metadata":{"id":"Z2NX_XA43D4w","execution":{"iopub.status.busy":"2023-07-12T23:22:00.042398Z","iopub.execute_input":"2023-07-12T23:22:00.043169Z","iopub.status.idle":"2023-07-12T23:22:00.048274Z","shell.execute_reply.started":"2023-07-12T23:22:00.043130Z","shell.execute_reply":"2023-07-12T23:22:00.047100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n    char_to_num = json.load(f)\n\n\nchar_to_num[pad_token] = pad_token_idx\nchar_to_num[start_token] = start_token_idx\nchar_to_num[end_token] = end_token_idx\n\nnum_to_char = {j:i for i,j in char_to_num.items()}\n\n\ninpdir = \"/kaggle/input/asl-fingerspelling\"\ndf = pd.read_csv(f'{inpdir}/train.csv')\n\nLPOSE = [13, 15, 17, 19, 21]\nRPOSE = [14, 16, 18, 20, 22]\nPOSE = LPOSE + RPOSE\n\nRHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\nLHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\nPOSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n\nX = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\nY = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\nZ = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n\nSEL_COLS = X + Y + Z\nFRAME_LEN = 128\n\nX_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\nY_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\nZ_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n\nRHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\nLHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\nRPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\nLPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n\nprint(RPOSE_IDX)","metadata":{"id":"vIrIgs3S3D4x","outputId":"0a14f688-1324-4d24-933b-0cd3393c5ad3","execution":{"iopub.status.busy":"2023-07-12T23:22:00.054909Z","iopub.execute_input":"2023-07-12T23:22:00.055257Z","iopub.status.idle":"2023-07-12T23:22:00.222460Z","shell.execute_reply.started":"2023-07-12T23:22:00.055231Z","shell.execute_reply":"2023-07-12T23:22:00.221364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_pad(x):\n    if tf.shape(x)[0] < FRAME_LEN:\n        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n        print(x)\n    else:\n        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n    return x\n\ndef translate_landmarks(landmarks, max_translation):\n    translation = tf.random.uniform(shape=(1,), minval=-max_translation, maxval=max_translation)\n    translated_landmarks = landmarks + translation\n    return translated_landmarks\n\ndef scale_landmarks(landmarks, min_scale, max_scale):\n    scale_factor = tf.random.uniform(shape=(1,), minval=min_scale, maxval=max_scale)\n    scaled_landmarks = landmarks * scale_factor\n    return scaled_landmarks\n\ndef add_noise(landmarks, noise_level):\n    noise = tf.random.normal(shape=tf.shape(landmarks), mean=0., stddev=noise_level)\n    landmarks = landmarks + noise\n    return landmarks\n\ndef pre_process(x):\n\n    rhand = tf.gather(x, RHAND_IDX, axis=1)\n    lhand = tf.gather(x, LHAND_IDX, axis=1)\n    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n\n    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n\n    rnans = tf.math.count_nonzero(rnan_idx)\n    lnans = tf.math.count_nonzero(lnan_idx)\n\n    # For dominant hand\n    if rnans > lnans:\n        hand = lhand\n        pose = lpose\n\n        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n\n        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n    else:\n        hand = rhand\n        pose = rpose\n\n    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n\n    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n    hand = (hand - mean) / std\n\n    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n\n    x = tf.concat([hand, pose], axis=1)\n    x = resize_pad(x)\n\n    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n    return x","metadata":{"id":"CwsIEjSx3D4y","execution":{"iopub.status.busy":"2023-07-12T23:22:00.225201Z","iopub.execute_input":"2023-07-12T23:22:00.225568Z","iopub.status.idle":"2023-07-12T23:22:00.248546Z","shell.execute_reply.started":"2023-07-12T23:22:00.225532Z","shell.execute_reply":"2023-07-12T23:22:00.247364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table = tf.lookup.StaticHashTable(\n    initializer=tf.lookup.KeyValueTensorInitializer(\n        keys=list(char_to_num.keys()),\n        values=list(char_to_num.values()),\n    ),\n    default_value=tf.constant(-1),\n    name=\"class_weight\"\n)\n\ndef preprocess_fn(landmarks, phrase):\n    phrase = start_token + phrase + end_token\n    phrase = tf.strings.bytes_split(phrase)\n    phrase = table.lookup(phrase)\n    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n                    constant_values = pad_token_idx)\n\n    # landmarksを前処理する\n    if tf.random.uniform(()) < 0.5:  # Random chance to perform translation\n        landmarks = translate_landmarks(landmarks, max_translation=10)\n    if tf.random.uniform(()) < 0.5:  # Random chance to perform scaling\n        landmarks = scale_landmarks(landmarks, min_scale=0.8, max_scale=1.2)\n    if tf.random.uniform(()) < 0.5:  # Random chance to add noise\n        landmarks = add_noise(landmarks, noise_level=0.05)\n\n    return pre_process(landmarks), phrase\n\n\ndef decode_fn(record_bytes):\n    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n    features = tf.io.parse_single_example(record_bytes, schema)\n    phrase = features[\"phrase\"]\n    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n    landmarks = tf.transpose(landmarks)\n\n    return landmarks, phrase\n","metadata":{"id":"4qLrqdoW3D4z","execution":{"iopub.status.busy":"2023-07-12T23:22:00.251660Z","iopub.execute_input":"2023-07-12T23:22:00.251935Z","iopub.status.idle":"2023-07-12T23:22:03.447967Z","shell.execute_reply.started":"2023-07-12T23:22:00.251902Z","shell.execute_reply":"2023-07-12T23:22:03.446970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inpdir = \"/kaggle/input/aslfr-parquets-to-tfrecords-cleaned\"\ntffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n\nbatch_size = 32\nval_len = int(0.05 * len(tffiles))\n\ntrain_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n","metadata":{"id":"Tf0xDk_O8zfc","outputId":"885596e8-155d-47d9-ae36-9b1de76bd1f8","execution":{"iopub.status.busy":"2023-07-12T23:22:03.451072Z","iopub.execute_input":"2023-07-12T23:22:03.451794Z","iopub.status.idle":"2023-07-12T23:22:05.544264Z","shell.execute_reply.started":"2023-07-12T23:22:03.451757Z","shell.execute_reply":"2023-07-12T23:22:05.543133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The model","metadata":{"id":"XrwFS5h03D41"}},{"cell_type":"code","source":"LPOSE = [13, 15, 17, 19, 21]\nRPOSE = [14, 16, 18, 20, 22]\n\nPOSE = LPOSE + RPOSE\n\nRHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\nLHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\nPOSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n\nX = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\nY = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\nZ = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n\nSEL_COLS = X + Y + Z\nFRAME_LEN = 128\n\nX_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\nY_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\nZ_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n\nRHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\nLHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\nRPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\nLPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n\nprint('SEL_COLS size:' + str(len(SEL_COLS)))","metadata":{"id":"RYHzcYzp3D41","outputId":"a06565e3-6f48-4691-fc99-76f69a889df6","execution":{"iopub.status.busy":"2023-07-12T23:22:05.545830Z","iopub.execute_input":"2023-07-12T23:22:05.546460Z","iopub.status.idle":"2023-07-12T23:22:05.562900Z","shell.execute_reply.started":"2023-07-12T23:22:05.546422Z","shell.execute_reply":"2023-07-12T23:22:05.561823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here I implemented proper positional embeddings for both the encoder and the decoder.","metadata":{"id":"u9Erb4iq3D42"}},{"cell_type":"code","source":"class MLPBlock(tf.keras.layers.Layer):\n    def __init__(self, num_hid=64, num_layers=5):\n        super().__init__()\n        self.mlp = tf.keras.Sequential()\n        for _ in range(num_layers):\n            self.mlp.add(tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu))\n        self.mlp.add(tf.keras.layers.Dense(num_hid))\n\n    def call(self, inputs):\n        return self.mlp(inputs)\n\n\nclass TokenEmbedding(keras.layers.Layer):\n    def __init__(self, num_vocab=61, maxlen=50, num_hid=256, mlp_num_layers=5):\n        super().__init__()\n        self.num_hid = num_hid\n        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n        self.pos_emb = self.positional_encoding(maxlen - 1, num_hid)\n        self.mlp_block = MLPBlock(num_hid, num_layers=mlp_num_layers)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        x = self.emb(x) * tf.math.sqrt(tf.cast(self.num_hid, tf.float32))\n        x = x + self.pos_emb[:maxlen, :]\n        x = self.mlp_block(x)\n        return x\n\n    def positional_encoding(self, maxlen, num_hid):\n        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n        depth = num_hid // 2\n        angles = positions / tf.pow(10000, tf.range(0, depth, 1, dtype=tf.float32) / num_hid)  # depthのインクリメントを修正\n        pos_encoding = tf.concat([tf.sin(angles), tf.cos(angles)], axis=-1)\n        return pos_encoding\n\n","metadata":{"id":"0HslbkR83D43","execution":{"iopub.status.busy":"2023-07-12T23:22:05.564555Z","iopub.execute_input":"2023-07-12T23:22:05.565159Z","iopub.status.idle":"2023-07-12T23:22:05.578971Z","shell.execute_reply.started":"2023-07-12T23:22:05.565115Z","shell.execute_reply":"2023-07-12T23:22:05.577976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"class TokenEmbedding(layers.Layer):\n    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n        super().__init__()\n        self.num_hid = num_hid\n        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n        '''\n        self.pos_emb = tf.math.divide(\n            self.positional_encoding(maxlen-1, num_hid),\n            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n        '''\n        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        x = self.emb(x)\n        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n        '''\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        return x + positions\n        '''\n        return x + self.pos_emb[:maxlen, :]\n    \n    def positional_encoding(self, maxlen, num_hid):\n        depth = num_hid/2\n        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n        angle_rads = tf.linalg.matmul(positions, angle_rates)\n        pos_encoding = tf.concat(\n          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n          axis=-1)\n        return pos_encoding\n\n\n","metadata":{"id":"Zh4liqdb3D44"}},{"cell_type":"code","source":"class LandmarkEmbedding(tf.keras.Model):\n    def __init__(self, num_hid=256, maxlen=100):\n        super(LandmarkEmbedding, self).__init__()\n        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.leaky_relu1 = tf.keras.layers.LeakyReLU()\n\n        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.leaky_relu2 = tf.keras.layers.LeakyReLU()\n        self.dropout2 = tf.keras.layers.Dropout(0.2)\n\n        self.conv3 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.leaky_relu3 = tf.keras.layers.LeakyReLU()\n        self.dropout3 = tf.keras.layers.Dropout(0.2)\n\n        self.conv4 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n        self.bn4 = tf.keras.layers.BatchNormalization()\n        self.leaky_relu4 = tf.keras.layers.LeakyReLU()\n        self.dropout4 = tf.keras.layers.Dropout(0.2)\n\n        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n        self.maxlen = maxlen\n        self.num_hid = num_hid\n\n    def call(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.leaky_relu1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.leaky_relu2(x)\n        x = self.dropout2(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.leaky_relu3(x)\n        x = self.dropout3(x)\n        x = self.conv4(x)\n        x = self.bn4(x)\n        x = self.leaky_relu4(x)\n        x = self.dropout4(x)\n        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n        x = x + self.pos_emb\n\n        return self.sigmoid(x)\n\n    def positional_encoding(self, maxlen, num_hid):\n        depth = num_hid/2\n        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n        depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n        angle_rads = tf.linalg.matmul(positions, angle_rates)\n        pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n        return pos_encoding\n","metadata":{"id":"hhEzMMAN3D45","execution":{"iopub.status.busy":"2023-07-12T23:22:05.580372Z","iopub.execute_input":"2023-07-12T23:22:05.580712Z","iopub.status.idle":"2023-07-12T23:22:05.599629Z","shell.execute_reply.started":"2023-07-12T23:22:05.580678Z","shell.execute_reply":"2023-07-12T23:22:05.598568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"id":"Fhr9HWVb3D46","execution":{"iopub.status.busy":"2023-07-12T23:22:05.601020Z","iopub.execute_input":"2023-07-12T23:22:05.601598Z","iopub.status.idle":"2023-07-12T23:22:05.614449Z","shell.execute_reply.started":"2023-07-12T23:22:05.601565Z","shell.execute_reply":"2023-07-12T23:22:05.613752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here I added the training flag to the TransformerDecoder's Dropout layers.","metadata":{"id":"6cbOcrFK3D47"}},{"cell_type":"code","source":"class TransformerDecoder(keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n        super().__init__()\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.self_att = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.self_dropout = layers.Dropout(0.5)\n        self.enc_dropout = layers.Dropout(0.1)\n        self.ffn_dropout = layers.Dropout(0.1)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n\n    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n        \"\"\"Masks the upper half of the dot product matrix in self attention.\n\n        This prevents flow of information from future tokens to current token.\n        1's in the lower triangle, counting from the lower right corner.\n        \"\"\"\n        i = tf.range(n_dest)[:, None]\n        j = tf.range(n_src)\n        m = i >= j - n_src + n_dest\n        mask = tf.cast(m, dtype)\n        mask = tf.reshape(mask, [1, n_dest, n_src])\n        mult = tf.concat(\n            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n        )\n        return tf.tile(mask, mult)\n\n    def call(self, enc_out, target, training):\n        input_shape = tf.shape(target)\n        batch_size = input_shape[0]\n        seq_len = input_shape[1]\n        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n        target_att = self.self_att(target, target, attention_mask=causal_mask)\n        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n        enc_out = self.enc_att(target_norm, enc_out)\n        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n        ffn_out = self.ffn(enc_out_norm)\n        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n        return ffn_out_norm","metadata":{"id":"Y35bT4wb3D48","execution":{"iopub.status.busy":"2023-07-12T23:22:05.617463Z","iopub.execute_input":"2023-07-12T23:22:05.618061Z","iopub.status.idle":"2023-07-12T23:22:05.632649Z","shell.execute_reply.started":"2023-07-12T23:22:05.618027Z","shell.execute_reply":"2023-07-12T23:22:05.631779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here I made the passing of the training flag explicit.","metadata":{"id":"McbjptyD3D49"}},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n    def __init__(\n        self,\n        num_hid=64,\n        num_head=2,\n        num_feed_forward=128,\n        source_maxlen=100,\n        target_maxlen=100,\n        num_layers_enc=4,\n        num_layers_dec=1,\n        num_classes=60,\n    ):\n        super().__init__()\n        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n        self.num_layers_enc = num_layers_enc\n        self.num_layers_dec = num_layers_dec\n        self.target_maxlen = target_maxlen\n        self.num_classes = num_classes\n        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n        self.dec_input = TokenEmbedding(\n            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n        )\n\n        self.encoder = keras.Sequential(\n            [self.enc_input]\n            + [\n                TransformerEncoder(num_hid, num_head, num_feed_forward)\n                for _ in range(num_layers_enc)\n            ]\n        )\n\n        for i in range(num_layers_dec):\n            setattr(\n                self,\n                f\"dec_layer_{i}\",\n                TransformerDecoder(num_hid, num_head, num_feed_forward),\n            )\n\n        self.classifier = layers.Dense(num_classes)\n\n    def decode(self, enc_out, target, training):\n        y = self.dec_input(target)\n        for i in range(self.num_layers_dec):\n            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n        return y\n\n    def call(self, inputs, training):\n        source = inputs[0]\n        target = inputs[1]\n        x = self.encoder(source, training)\n        y = self.decode(x, target, training)\n        return self.classifier(y)\n\n    @property\n    def metrics(self):\n        return [self.loss_metric]\n\n    def train_step(self, batch):\n        \"\"\"Processes one batch inside model.fit().\"\"\"\n        source = batch[0]\n        target = batch[1]\n\n        input_shape = tf.shape(target)\n        batch_size = input_shape[0]\n\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        with tf.GradientTape() as tape:\n            preds = self([source, dec_input])\n            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def test_step(self, batch):\n        source = batch[0]\n        target = batch[1]\n\n        input_shape = tf.shape(target)\n        batch_size = input_shape[0]\n\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        preds = self([source, dec_input])\n        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def generate(self, source, target_start_token_idx):\n        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n        bs = tf.shape(source)[0]\n        enc = self.encoder(source, training = False)\n        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n        dec_logits = []\n        for i in range(self.target_maxlen - 1):\n            dec_out = self.decode(enc, dec_input, training = False)\n            logits = self.classifier(dec_out)\n            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n            last_logit = logits[:, -1][..., tf.newaxis]\n            dec_logits.append(last_logit)\n            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n        return dec_input","metadata":{"id":"1LDSYoCh3D49","execution":{"iopub.status.busy":"2023-07-12T23:22:05.638018Z","iopub.execute_input":"2023-07-12T23:22:05.638297Z","iopub.status.idle":"2023-07-12T23:22:05.661755Z","shell.execute_reply.started":"2023-07-12T23:22:05.638273Z","shell.execute_reply":"2023-07-12T23:22:05.660837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 正解率を計算するためのメトリクスを作成\ntrain_accuracy = tf.keras.metrics.CategoricalAccuracy()\nval_accuracy = tf.keras.metrics.CategoricalAccuracy()\n\n# 学習ループ内で正解率を更新するコールバックを定義\nclass AccuracyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        train_acc = train_accuracy.result()\n        val_acc = val_accuracy.result()\n        print(f\"Epoch {epoch+1}: Train Accuracy = {train_acc}, Validation Accuracy = {val_acc}\")\n        # 正解率をリセット\n        train_accuracy.reset_states()\n        val_accuracy.reset_states()\n# val_lossが3回マイナスになった場合に学習を停止するコールバック\nclass EarlyStoppingCallback(tf.keras.callbacks.Callback):\n    def __init__(self, patience=7):\n        super(EarlyStoppingCallback, self).__init__()\n        self.patience = patience\n        self.min_val_loss = float('inf')\n        self.wait = 0\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_loss = logs.get('val_loss')\n        if val_loss < self.min_val_loss:\n            self.min_val_loss = val_loss\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.model.stop_training = True\n                print(\"Training stopped due to early stopping.\")\n\nbatch = next(iter(val_dataset))\nidx_to_char = list(char_to_num.keys())\n\nmodel = Transformer(\n    num_hid=256,\n    num_head=4,\n    num_feed_forward=400,\n    source_maxlen = FRAME_LEN,\n    target_maxlen=64,\n    num_layers_enc=2,\n    num_layers_dec=1,\n    num_classes=62,\n)\n\n\n\nloss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\naccuracy_callback = AccuracyCallback()\noptimizer = keras.optimizers.Adam(0.0001)\n\n\n# モデルのコンパイル\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_accuracy])","metadata":{"id":"RoQoEAwf3D4-","execution":{"iopub.status.busy":"2023-07-12T23:22:05.663380Z","iopub.execute_input":"2023-07-12T23:22:05.663871Z","iopub.status.idle":"2023-07-12T23:22:08.195202Z","shell.execute_reply.started":"2023-07-12T23:22:05.663821Z","shell.execute_reply":"2023-07-12T23:22:08.194119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#modelアーキテクト\n#tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)\n","metadata":{"id":"0IUChNM23D4_","execution":{"iopub.status.busy":"2023-07-12T23:22:08.196624Z","iopub.execute_input":"2023-07-12T23:22:08.196949Z","iopub.status.idle":"2023-07-12T23:22:08.202491Z","shell.execute_reply.started":"2023-07-12T23:22:08.196916Z","shell.execute_reply":"2023-07-12T23:22:08.201446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ##Optuna\n# pip install optuna","metadata":{"id":"yflrYw4v3D5A","execution":{"iopub.status.busy":"2023-07-12T23:22:08.204313Z","iopub.execute_input":"2023-07-12T23:22:08.204640Z","iopub.status.idle":"2023-07-12T23:22:08.217039Z","shell.execute_reply.started":"2023-07-12T23:22:08.204609Z","shell.execute_reply":"2023-07-12T23:22:08.216098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# EarlyStoppingCallbackをコールバックリストに追加して学習を行う\nhistory = model.fit(train_dataset, verbose=2, validation_data=val_dataset, epochs=100,\n                    callbacks=[AccuracyCallback(), EarlyStoppingCallback()])\n","metadata":{"id":"7FvvtVwc3D5A","outputId":"dbfdc8d4-6f7e-480d-e503-af2f207cd5d9","execution":{"iopub.status.busy":"2023-07-12T23:22:08.218573Z","iopub.execute_input":"2023-07-12T23:22:08.218901Z","iopub.status.idle":"2023-07-13T02:06:55.284850Z","shell.execute_reply.started":"2023-07-12T23:22:08.218870Z","shell.execute_reply":"2023-07-13T02:06:55.281844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.summary())","metadata":{"id":"aT4MU6D43D5B","outputId":"e5575cd8-e58a-4a4b-84a2-03158c3e3381","execution":{"iopub.status.busy":"2023-07-13T02:08:47.061918Z","iopub.execute_input":"2023-07-13T02:08:47.062562Z","iopub.status.idle":"2023-07-13T02:08:47.104334Z","shell.execute_reply.started":"2023-07-13T02:08:47.062525Z","shell.execute_reply":"2023-07-13T02:08:47.103334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","metadata":{"id":"Dmc_Vs_f3D5B","outputId":"5f77c6b0-016f-48f9-aa0b-1b5116365bd7","execution":{"iopub.status.busy":"2023-07-13T02:06:55.346845Z","iopub.execute_input":"2023-07-13T02:06:55.347787Z","iopub.status.idle":"2023-07-13T02:07:15.096031Z","shell.execute_reply.started":"2023-07-13T02:06:55.347752Z","shell.execute_reply":"2023-07-13T02:07:15.095109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{"id":"8Fxn_TUt3D5D"}},{"cell_type":"code","source":"pip install termcolor","metadata":{"execution":{"iopub.status.busy":"2023-07-13T03:14:21.645569Z","iopub.execute_input":"2023-07-13T03:14:21.646032Z","iopub.status.idle":"2023-07-13T03:14:35.366990Z","shell.execute_reply.started":"2023-07-13T03:14:21.645999Z","shell.execute_reply":"2023-07-13T03:14:35.365559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nbatches = [batch for batch in val_dataset]\n\npreds_list = []\nground_truth_list = []\n\nfor batch in batches[:1]:\n    source = batch[0]\n    target = batch[1].numpy()\n    bs = tf.shape(source)[0]\n    preds = model.generate(source, start_token_idx)\n    preds = preds.numpy()\n\n    for i in range(bs):\n        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n        ground_truth_list.append(target_text.replace('P', ''))\n        prediction = \"\"\n        for idx in preds[i, :]:\n            prediction += idx_to_char[idx]\n            if idx == end_token_idx:\n                break\n        preds_list.append(prediction)\n\ndata = {'Ground Truth': ground_truth_list, 'Prediction': preds_list}\ndf = pd.DataFrame(data)\n\ncorrect_predictions = (df['Ground Truth'] == df['Prediction']).sum()\ncorrect_words_list = [truth for truth, pred in zip(ground_truth_list, preds_list) if truth == pred]\n\ntotal_predictions = len(df)\naccuracy = correct_predictions / total_predictions\n\nprint(\"Ground Truth vs. Prediction:\")\nprint(df)\nprint(\"\\nAccuracy: {:.2%}\".format(accuracy))\n\nprint(\"\\nCorrect Predictions:\")\nfor word in correct_words_list:\n    print(word)\n\nword_counts = Counter(correct_words_list)\n\nprint(\"\\nCorrect Word Counts:\")\nfor word, count in word_counts.items():\n    print(f\"'{word}': {count} times\")\n","metadata":{"id":"2XcqFl4p3D5D","outputId":"a902365d-dda4-4f1d-d79e-8d291f8e0657","execution":{"iopub.status.busy":"2023-07-13T03:22:18.411368Z","iopub.execute_input":"2023-07-13T03:22:18.412087Z","iopub.status.idle":"2023-07-13T03:22:24.597036Z","shell.execute_reply.started":"2023-07-13T03:22:18.412030Z","shell.execute_reply":"2023-07-13T03:22:24.596040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\npreds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\nlev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n            for i in range(len(preds_list_processed))]\nN = [len(phrase) for phrase in ground_truth_processed]\n\nprint('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))","metadata":{"id":"F8EMyPau3D5E","outputId":"7a556d6f-3eb3-4c34-be4a-6a3ddb0f6a43","execution":{"iopub.status.busy":"2023-07-13T03:37:13.876707Z","iopub.execute_input":"2023-07-13T03:37:13.877216Z","iopub.status.idle":"2023-07-13T03:37:13.886659Z","shell.execute_reply.started":"2023-07-13T03:37:13.877180Z","shell.execute_reply":"2023-07-13T03:37:13.885695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Levenstein Distance Train","metadata":{"id":"3PwS5F3j3D5F"}},{"cell_type":"code","source":"# Compute Levenstein Distances\ndef get_ld_train():\n    N = 100 if IS_INTERACTIVE else 1000\n    LD_TRAIN = []\n    for idx, (frames, phrase_true) in enumerate(zip(tqdm(X_train, total=N), y_train)):\n        # Predict Phrase and Convert to String\n        phrase_pred = predict_phrase(frames).numpy()\n        phrase_pred = outputs2phrase(phrase_pred)\n        # True Phrase Ordinal to String\n        phrase_true = outputs2phrase(phrase_true)\n        # Add Levenstein Distance\n        LD_TRAIN.append({\n            'phrase_true': phrase_true,\n            'phrase_pred': phrase_pred,\n            'levenshtein_distance': levenshtein(phrase_pred, phrase_true),\n        })\n        # Take subset in interactive mode\n        if idx == N:\n            break\n\n    # Convert to DataFrame\n    LD_TRAIN_DF = pd.DataFrame(LD_TRAIN)\n\n    return LD_TRAIN_DF","metadata":{"id":"C289LerY3D5F","execution":{"iopub.status.busy":"2023-07-13T02:36:01.752510Z","iopub.execute_input":"2023-07-13T02:36:01.752882Z","iopub.status.idle":"2023-07-13T02:36:01.760394Z","shell.execute_reply.started":"2023-07-13T02:36:01.752852Z","shell.execute_reply":"2023-07-13T02:36:01.759128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TFLiteModel","metadata":{"id":"yXPYfSur3D5G"}},{"cell_type":"code","source":" class TFLiteModel(tf.Module):\n    def __init__(self, model):\n        super(TFLiteModel, self).__init__()\n        self.target_start_token_idx = start_token_idx\n        self.target_end_token_idx = end_token_idx\n        # Load the feature generation and main models\n        self.model = model\n\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n    def __call__(self, inputs, training=False):\n        # Preprocess Data\n        x = tf.cast(inputs, tf.float32)\n        x = x[None]\n        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n        x = x[0]\n        x = pre_process(x)\n        x = x[None]\n        x = self.model.generate(x, self.target_start_token_idx)\n        x = x[0]\n        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n        x = x[1:idx]\n        x = tf.one_hot(x, 59)\n        return {'outputs': x}\n\ntflitemodel_base = TFLiteModel(model)","metadata":{"id":"q62jNFIt3D5G","execution":{"iopub.status.busy":"2023-07-13T02:36:15.782093Z","iopub.execute_input":"2023-07-13T02:36:15.782817Z","iopub.status.idle":"2023-07-13T02:36:15.794153Z","shell.execute_reply.started":"2023-07-13T02:36:15.782782Z","shell.execute_reply":"2023-07-13T02:36:15.793230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#モデル保存\n#model.save_weights(\"model.h5\")\nmodel.save('model_and_weight.h5')","metadata":{"id":"n7LiyIW43D5r","execution":{"iopub.status.busy":"2023-07-13T02:36:23.059989Z","iopub.execute_input":"2023-07-13T02:36:23.060702Z","iopub.status.idle":"2023-07-13T02:36:23.246584Z","shell.execute_reply.started":"2023-07-13T02:36:23.060667Z","shell.execute_reply":"2023-07-13T02:36:23.245518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 重みの読み込み\nmodel.load_weights('model.h5')\n\n# モデルの形状を表示\nmodel.summary()","metadata":{"id":"mmIvipm83D5s","outputId":"551af2fe-b8ff-4c1c-c5d3-fd59b53129a2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\nkeras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\ntflite_model = keras_model_converter.convert()\nwith open('/kaggle/working/model.tflite', 'wb') as f:\n    f.write(tflite_model)\n\ninfargs = {\"selected_columns\" : SEL_COLS}\n\nwith open('inference_args.json', \"w\") as json_file:\n    json.dump(infargs, json_file)","metadata":{"id":"MygKEnwt3D5t","outputId":"70e17996-ced5-4a09-c532-bb28ddc1718f","execution":{"iopub.status.busy":"2023-07-13T02:36:32.543995Z","iopub.execute_input":"2023-07-13T02:36:32.544707Z","iopub.status.idle":"2023-07-13T02:37:55.209538Z","shell.execute_reply.started":"2023-07-13T02:36:32.544671Z","shell.execute_reply":"2023-07-13T02:37:55.208436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip submission.zip  './model.tflite' './inference_args.json'","metadata":{"id":"P02lJRDR3D5u","outputId":"ccc74bc4-c180-42ae-f07c-bbe9ce0ce045","execution":{"iopub.status.busy":"2023-07-13T02:37:55.211407Z","iopub.execute_input":"2023-07-13T02:37:55.211765Z","iopub.status.idle":"2023-07-13T02:37:58.316412Z","shell.execute_reply.started":"2023-07-13T02:37:55.211723Z","shell.execute_reply":"2023-07-13T02:37:58.315211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(\"model.tflite\")\n\nREQUIRED_SIGNATURE = \"serving_default\"\nREQUIRED_OUTPUT = \"outputs\"\n\nwith open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n    character_map = json.load(f)\nrev_character_map = {j:i for i,j in character_map.items()}\n\nfound_signatures = list(interpreter.get_signature_list().keys())\n\nif REQUIRED_SIGNATURE not in found_signatures:\n    raise KernelEvalException('Required input signature not found.')\n\nprediction_fn = interpreter.get_signature_runner(\"serving_default\")\noutput = prediction_fn(inputs=batch[0][0])\nprediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\nprint(prediction_str)","metadata":{"id":"eKivsj_33D5v","outputId":"97aadf82-3a01-4a6d-9e0e-18f16157502b","execution":{"iopub.status.busy":"2023-07-13T02:38:08.864827Z","iopub.execute_input":"2023-07-13T02:38:08.865248Z","iopub.status.idle":"2023-07-13T02:38:09.419235Z","shell.execute_reply.started":"2023-07-13T02:38:08.865210Z","shell.execute_reply":"2023-07-13T02:38:09.418145Z"},"trusted":true},"execution_count":null,"outputs":[]}]}