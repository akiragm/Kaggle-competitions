{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ColabPreprocess  --START\n",
        "置換<br>\n",
        "\n",
        "/kaggle/input/            <br>\n",
        "/content/"
      ],
      "metadata": {
        "id": "uIY3gyjVDW16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "9D2OX6U0CaH6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! apt update\n",
        "! apt install gcsfuse"
      ],
      "metadata": {
        "outputId": "ddda77aa-44da-4a9b-ec1c-1b66bd47b8c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qpeTkECaH7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0   129k      0 --:--:-- --:--:-- --:--:--  129k\n",
            "OK\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:5 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,004 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:7 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [2,286 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,360 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,299 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Fetched 5,054 kB in 3s (1,799 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "13 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 14.0 MB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 0.42.5 [14.0 MB]\n",
            "Fetched 14.0 MB in 0s (112 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.42.5_amd64.deb ...\n",
            "Unpacking gcsfuse (0.42.5) ...\n",
            "Setting up gcsfuse (0.42.5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5f_lFB9TCaH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kaggle get_gcspath\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "print(KaggleDatasets().get_gcs_path())"
      ],
      "metadata": {
        "id": "1GmDR8Lh1fku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3Q0v8LEtnE",
        "outputId": "a5251539-5c26-40d1-da10-2a92d56e68c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p asl-fingerspelling\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-060e8f96f45da8817e298f5151de7d204c3aa2ebfe6436b68e8d87e2 asl-fingerspelling"
      ],
      "metadata": {
        "id": "olczO1_pC2TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29236b8-d24f-41be-bb14-d06b7f76936c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0626 11:50:43.994690 2023/06/26 11:50:43.994666 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /content/asl-fingerspelling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p aslfr-parquets-to-tfrecords-cleaned\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-1865224784ea3c877e01e6064beb4b6fd74d08462427498e98ddc3df aslfr-parquets-to-tfrecords-cleaned"
      ],
      "metadata": {
        "outputId": "7d861d53-8a13-414b-f959-67b1ef3baced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2KWdEtVCaH9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0626 11:50:44.812019 2023/06/26 11:50:44.811995 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /content/aslfr-parquets-to-tfrecords-cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esy-KMuR8ivw",
        "outputId": "d70aa2ee-d3db-4444-bbd3-efc6efb78fc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8L77lmNJEQYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --END  ColabPreprocess"
      ],
      "metadata": {
        "id": "ZDYAPQiVEATw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. I used two transformer layer in the encoder instead of four.\n",
        "2. I used four attention heads instead of two.\n",
        "3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n",
        "2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n",
        "3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n",
        "4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n",
        "5. I added positional embedding to the encoder. This, too, had a significant impact.\n"
      ],
      "metadata": {
        "id": "ls6jZUmODp5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import Levenshtein as lev\n",
        "import os\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:39.647352Z",
          "iopub.execute_input": "2023-06-26T03:43:39.647946Z",
          "iopub.status.idle": "2023-06-26T03:43:39.654535Z",
          "shell.execute_reply.started": "2023-06-26T03:43:39.647910Z",
          "shell.execute_reply": "2023-06-26T03:43:39.653364Z"
        },
        "trusted": true,
        "id": "hJnLDjLzDp53"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "B3hcEfbDDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
        "display(df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:34.921833Z",
          "iopub.execute_input": "2023-06-21T12:27:34.922562Z",
          "iopub.status.idle": "2023-06-21T12:27:35.134638Z",
          "shell.execute_reply.started": "2023-06-21T12:27:34.922525Z",
          "shell.execute_reply": "2023-06-21T12:27:35.133695Z"
        },
        "id": "0Ni7noahDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_landmarks = pd.read_parquet('/content/asl-fingerspelling/train_landmarks/1019715464.parquet')\n",
        "keys = train_landmarks.keys()[1:]\n",
        "train_landmarks.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:35.136172Z",
          "iopub.execute_input": "2023-06-21T12:27:35.136526Z",
          "iopub.status.idle": "2023-06-21T12:27:52.128059Z",
          "shell.execute_reply.started": "2023-06-21T12:27:35.136494Z",
          "shell.execute_reply": "2023-06-21T12:27:52.122672Z"
        },
        "id": "F1hbBsMFDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFRecord"
      ],
      "metadata": {
        "id": "t_Zq2IIvDp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.129279Z",
          "iopub.status.idle": "2023-06-21T12:27:52.130399Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.130158Z",
          "shell.execute_reply": "2023-06-21T12:27:52.13018Z"
        },
        "id": "jycbHpy_Dp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
        "\n",
        "counter = 0\n",
        "for file_id in tqdm(df.file_id.unique()):\n",
        "    \n",
        "    print(counter)\n",
        "    counter+=1\n",
        "    \n",
        "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
        "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
        "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
        "    seq_refs = df.loc[df.file_id == file_id]\n",
        "    seqs = load_relevant_data_subset(pqfile)\n",
        "    seqs_numpy = seqs.to_numpy()\n",
        "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
        "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
        "            frames = seqs_numpy[seqs.index == seq_id]\n",
        "            \n",
        "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
        "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
        "            no_nan = max(r_nonan, l_nonan)\n",
        "            \n",
        "            if 2*len(phrase)<no_nan:\n",
        "                features = {SEL_COLS[i]: tf.train.Feature(\n",
        "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n",
        "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
        "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
        "                file_writer.write(record_bytes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.131662Z",
          "iopub.status.idle": "2023-06-21T12:27:52.132528Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.132225Z",
          "shell.execute_reply": "2023-06-21T12:27:52.132253Z"
        },
        "id": "Hmzq1uMZDp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "anVm5CKGDp57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs)."
      ],
      "metadata": {
        "id": "NaASHGkwDp57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = 'P'\n",
        "start_token = 'S'\n",
        "end_token = 'E'\n",
        "pad_token_idx = 59\n",
        "start_token_idx = 60\n",
        "end_token_idx = 61"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:50.038588Z",
          "iopub.execute_input": "2023-06-26T03:43:50.039294Z",
          "iopub.status.idle": "2023-06-26T03:43:50.043979Z",
          "shell.execute_reply.started": "2023-06-26T03:43:50.039260Z",
          "shell.execute_reply": "2023-06-26T03:43:50.043067Z"
        },
        "trusted": true,
        "id": "zGEhbPRUDp58"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    char_to_num = json.load(f)\n",
        "\n",
        "\n",
        "char_to_num[pad_token] = pad_token_idx\n",
        "char_to_num[start_token] = start_token_idx\n",
        "char_to_num[end_token] = end_token_idx\n",
        "\n",
        "num_to_char = {j:i for i,j in char_to_num.items()}\n",
        "\n",
        "\n",
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "\n",
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print(RPOSE_IDX)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:51.279454Z",
          "iopub.execute_input": "2023-06-26T03:43:51.279841Z",
          "iopub.status.idle": "2023-06-26T03:43:51.388163Z",
          "shell.execute_reply.started": "2023-06-26T03:43:51.279809Z",
          "shell.execute_reply": "2023-06-26T03:43:51.387128Z"
        },
        "trusted": true,
        "id": "SdTNf47NDp58",
        "outputId": "a51230b5-0649-4a1f-ffb7-41e9793b69a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 48, 49, 50, 51, 99, 100, 101, 102, 103, 151, 152, 153, 154, 155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{0: ' ', 1: '!', 2: '#', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: '+', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '=', 28: '?', 29: '@', 30: '[', 31: '_', 32: 'a', 33: 'b', 34: 'c', 35: 'd', 36: 'e', 37: 'f', 38: 'g', 39: 'h', 40: 'i', 41: 'j', 42: 'k', 43: 'l', 44: 'm', 45: 'n', 46: 'o', 47: 'p', 48: 'q', 49: 'r', 50: 's', 51: 't', 52: 'u', 53: 'v', 54: 'w', 55: 'x', 56: 'y', 57: 'z', 58: '~', 59: 'P', 60: 'S', 61: 'E'}\n",
        "add Codeadd Markdown"
      ],
      "metadata": {
        "id": "7l2otrH4Dp59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_pad(x):\n",
        "    if tf.shape(x)[0] < FRAME_LEN:\n",
        "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
        "        print(x)\n",
        "    else:\n",
        "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
        "    return x\n",
        "\n",
        "def translate_landmarks(landmarks, max_translation):\n",
        "    translation = tf.random.uniform(shape=tf.shape(landmarks), minval=-max_translation, maxval=max_translation)\n",
        "    translated_landmarks = landmarks + translation\n",
        "    return translated_landmarks\n",
        "\n",
        "def scale_landmarks(landmarks, min_scale, max_scale):\n",
        "    scale_factor = tf.random.uniform(shape=tf.shape(landmarks), minval=min_scale, maxval=max_scale)\n",
        "    scaled_landmarks = landmarks * scale_factor\n",
        "    return scaled_landmarks\n",
        "\n",
        "def pre_process(x):\n",
        "\n",
        "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
        "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
        "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
        "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
        "\n",
        "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
        "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
        "\n",
        "    rnans = tf.math.count_nonzero(rnan_idx)\n",
        "    lnans = tf.math.count_nonzero(lnan_idx)\n",
        "\n",
        "    # For dominant hand\n",
        "    if rnans > lnans:\n",
        "        hand = lhand\n",
        "        pose = lpose\n",
        "\n",
        "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
        "\n",
        "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
        "    else:\n",
        "        hand = rhand\n",
        "        pose = rpose\n",
        "\n",
        "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
        "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
        "    hand = (hand - mean) / std\n",
        "\n",
        "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    x = tf.concat([hand, pose], axis=1)\n",
        "    x = resize_pad(x)\n",
        "\n",
        "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:56.251215Z",
          "iopub.execute_input": "2023-06-26T03:43:56.251603Z",
          "iopub.status.idle": "2023-06-26T03:43:56.275318Z",
          "shell.execute_reply.started": "2023-06-26T03:43:56.251574Z",
          "shell.execute_reply": "2023-06-26T03:43:56.274277Z"
        },
        "trusted": true,
        "id": "Qk5pTdDzDp5-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=list(char_to_num.keys()),\n",
        "        values=list(char_to_num.values()),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name=\"class_weight\"\n",
        ")\n",
        "\n",
        "def preprocess_fn(landmarks, phrase):\n",
        "    phrase = start_token + phrase + end_token\n",
        "    phrase = tf.strings.bytes_split(phrase)\n",
        "    phrase = table.lookup(phrase)\n",
        "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
        "                    constant_values = pad_token_idx)\n",
        "\n",
        "    # landmarksを前処理する\n",
        "    translated_landmarks = translate_landmarks(landmarks, max_translation=10)\n",
        "    scaled_landmarks = scale_landmarks(landmarks, min_scale=0.8, max_scale=1.2)\n",
        "\n",
        "    # 前処理済みのlandmarksを結合する\n",
        "    combined_landmarks = tf.concat([landmarks, translated_landmarks, scaled_landmarks], axis=1)\n",
        "\n",
        "    return pre_process(combined_landmarks), phrase\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n",
        "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "    phrase = features[\"phrase\"]\n",
        "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n",
        "    landmarks = tf.transpose(landmarks)\n",
        "\n",
        "    return landmarks, phrase\n",
        "\n",
        "inpdir = \"/content/aslfr-parquets-to-tfrecords-cleaned\"\n",
        "tffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n",
        "\n",
        "batch_size = 32\n",
        "val_len = int(0.05 * len(tffiles))\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:57.838702Z",
          "iopub.execute_input": "2023-06-26T03:43:57.839078Z",
          "iopub.status.idle": "2023-06-26T03:43:59.156543Z",
          "shell.execute_reply.started": "2023-06-26T03:43:57.839049Z",
          "shell.execute_reply": "2023-06-26T03:43:59.155472Z"
        },
        "trusted": true,
        "id": "GK-wOj8CDp5_",
        "outputId": "98308b33-cf87-4cf0-8d20-d96dc63e27e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model"
      ],
      "metadata": {
        "id": "PufJODDjDp5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:e865f0c6-0e14-4387-9779-537f8b3d065d.png)\n",
        "![image.png](attachment:39ec8854-9e5f-4617-aa6a-69098b605134.png)\n",
        "![image.png](attachment:8b28cc87-2b4a-467f-a818-44b7e1f8dc8f.png)\n",
        "![image.png](attachment:243f34f9-3f88-4452-aac7-ee1ec0a3d065.png)"
      ],
      "metadata": {
        "id": "35kTT5MRDp5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I implemented proper positional embeddings for both the encoder and the decoder."
      ],
      "metadata": {
        "id": "su-6MWcSDp6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(layers.Layer):\n",
        "    def __init__(self, num_hid=64, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.mlp = tf.keras.Sequential()\n",
        "        for _ in range(num_layers):\n",
        "            self.mlp.add(tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu))\n",
        "        self.mlp.add(tf.keras.layers.Dense(num_hid))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.mlp(inputs)\n",
        "\n",
        "\n",
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64, mlp_num_layers=2):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = self.positional_encoding(maxlen - 1, num_hid)\n",
        "        self.mlp_block = MLPBlock(num_hid, num_layers=mlp_num_layers)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x) * tf.math.sqrt(tf.cast(self.num_hid, tf.float32))\n",
        "        x = x + self.pos_emb[:maxlen, :]\n",
        "        x = self.mlp_block(x)\n",
        "        return x\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depth = num_hid // 2\n",
        "        angles = positions / tf.pow(10000, tf.range(0, depth, 1, dtype=tf.float32) / num_hid)  # depthのインクリメントを修正\n",
        "        pos_encoding = tf.concat([tf.sin(angles), tf.cos(angles)], axis=-1)\n",
        "        return pos_encoding\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:00.656849Z",
          "iopub.execute_input": "2023-06-26T03:44:00.659000Z",
          "iopub.status.idle": "2023-06-26T03:44:00.672227Z",
          "shell.execute_reply.started": "2023-06-26T03:44:00.658953Z",
          "shell.execute_reply": "2023-06-26T03:44:00.671099Z"
        },
        "trusted": true,
        "id": "9QJUkdQeDp6A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "        '''\n",
        "        self.pos_emb = tf.math.divide(\n",
        "            self.positional_encoding(maxlen-1, num_hid),\n",
        "            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n",
        "        '''\n",
        "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        '''\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "        '''\n",
        "        return x + self.pos_emb[:maxlen, :]\n",
        "    \n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T01:27:59.514789Z",
          "iopub.execute_input": "2023-06-22T01:27:59.517058Z",
          "iopub.status.idle": "2023-06-22T01:27:59.530952Z",
          "shell.execute_reply.started": "2023-06-22T01:27:59.517017Z",
          "shell.execute_reply": "2023-06-22T01:27:59.529987Z"
        },
        "id": "0K45t4ttDp6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super(LandmarkEmbedding, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu1 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu2 = tf.keras.layers.ReLU()\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu3 = tf.keras.layers.ReLU()\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu4 = tf.keras.layers.ReLU()\n",
        "        self.dropout4 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv5 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu5 = tf.keras.layers.ReLU()\n",
        "        self.dropout5 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv6 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn6 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu6 = tf.keras.layers.ReLU()\n",
        "        self.dropout6 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv7 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn7 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu7 = tf.keras.layers.ReLU()\n",
        "        self.dropout7 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
        "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
        "        self.maxlen = maxlen\n",
        "        self.num_hid = num_hid\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.dropout5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = self.relu6(x)\n",
        "        x = self.dropout6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.bn7(x)\n",
        "        x = self.relu7(x)\n",
        "        x = self.dropout7(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.bn8(x)\n",
        "        x = self.relu8(x)\n",
        "        x = self.dropout8(x)\n",
        "\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb\n",
        "\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
        "        return pos_encoding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:02.337798Z",
          "iopub.execute_input": "2023-06-26T03:44:02.338456Z",
          "iopub.status.idle": "2023-06-26T03:44:02.358498Z",
          "shell.execute_reply.started": "2023-06-26T03:44:02.338424Z",
          "shell.execute_reply": "2023-06-26T03:44:02.357547Z"
        },
        "trusted": true,
        "id": "yhso_UunDp6A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:04.520721Z",
          "iopub.execute_input": "2023-06-26T03:44:04.521113Z",
          "iopub.status.idle": "2023-06-26T03:44:04.530882Z",
          "shell.execute_reply.started": "2023-06-26T03:44:04.521080Z",
          "shell.execute_reply": "2023-06-26T03:44:04.529251Z"
        },
        "trusted": true,
        "id": "N8Lugl97Dp6B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# TFRecordファイルのパス\n",
        "tfrecord_file = \"/kaggle/working/tfds/128822441.tfrecord\"\n",
        "\n",
        "# TFRecordデータセットの作成\n",
        "dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
        "print(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:07.559213Z",
          "iopub.execute_input": "2023-06-26T03:44:07.560180Z",
          "iopub.status.idle": "2023-06-26T03:44:07.577877Z",
          "shell.execute_reply.started": "2023-06-26T03:44:07.560136Z",
          "shell.execute_reply": "2023-06-26T03:44:07.576727Z"
        },
        "trusted": true,
        "id": "PryRJHouDp6B",
        "outputId": "2bfc5b78-e933-43a9-caae-009fdab30d46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I added the training flag to the TransformerDecoder's Dropout layers."
      ],
      "metadata": {
        "id": "6Ul8pZtNDp6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target, training):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:08.748287Z",
          "iopub.execute_input": "2023-06-26T03:44:08.748649Z",
          "iopub.status.idle": "2023-06-26T03:44:08.764270Z",
          "shell.execute_reply.started": "2023-06-26T03:44:08.748619Z",
          "shell.execute_reply": "2023-06-26T03:44:08.762681Z"
        },
        "trusted": true,
        "id": "lbmu0lqMDp6C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I made the passing of the training flag explicit."
      ],
      "metadata": {
        "id": "IxjuUK90Dp6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target, training):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source, training)\n",
        "        y = self.decode(x, target, training)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source, training = False)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input, training = False)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = logits[:, -1][..., tf.newaxis]\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:11.821637Z",
          "iopub.execute_input": "2023-06-26T03:44:11.822020Z",
          "iopub.status.idle": "2023-06-26T03:44:11.845701Z",
          "shell.execute_reply.started": "2023-06-26T03:44:11.821989Z",
          "shell.execute_reply": "2023-06-26T03:44:11.844544Z"
        },
        "trusted": true,
        "id": "FMzXwlaNDp6D"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解率を計算するためのメトリクスを作成\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# 学習ループ内で正解率を更新するコールバックを定義\n",
        "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_acc = train_accuracy.result()\n",
        "        val_acc = val_accuracy.result()\n",
        "        print(f\"Epoch {epoch+1}: Train Accuracy = {train_acc}, Validation Accuracy = {val_acc}\")\n",
        "        # 正解率をリセット\n",
        "        train_accuracy.reset_states()\n",
        "        val_accuracy.reset_states()\n",
        "# val_lossが連続3回マイナスになった場合に学習を停止するコールバック\n",
        "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=3):\n",
        "        super(EarlyStoppingCallback, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.min_val_loss = float('inf')\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        if val_loss < self.min_val_loss:\n",
        "            self.min_val_loss = val_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stopped due to early stopping.\")\n",
        "\n",
        "batch = next(iter(val_dataset))\n",
        "idx_to_char = list(char_to_num.keys())\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=4,\n",
        "    num_feed_forward=400,\n",
        "    source_maxlen = FRAME_LEN,\n",
        "    target_maxlen=64,\n",
        "    num_layers_enc=2,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=62,\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "accuracy_callback = AccuracyCallback()\n",
        "optimizer = keras.optimizers.Adam(0.0001)\n",
        "\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_accuracy])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:45:35.856212Z",
          "iopub.execute_input": "2023-06-26T03:45:35.856580Z",
          "iopub.status.idle": "2023-06-26T03:45:36.221753Z",
          "shell.execute_reply.started": "2023-06-26T03:45:35.856550Z",
          "shell.execute_reply": "2023-06-26T03:45:36.220648Z"
        },
        "trusted": true,
        "id": "qZRLTg89Dp6D"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# EarlyStoppingCallbackをコールバックリストに追加して学習を行う\n",
        "history = model.fit(train_dataset, verbose=2, validation_data=val_dataset, epochs=100,\n",
        "                    callbacks=[AccuracyCallback(), EarlyStoppingCallback()])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:45:40.633802Z",
          "iopub.execute_input": "2023-06-26T03:45:40.634201Z",
          "iopub.status.idle": "2023-06-26T04:23:16.771818Z",
          "shell.execute_reply.started": "2023-06-26T03:45:40.634167Z",
          "shell.execute_reply": "2023-06-26T04:23:16.769586Z"
        },
        "trusted": true,
        "id": "rLPhxPFzDp6E",
        "outputId": "4f54d9bd-d960-4cd4-df37-71b7e985c9dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 268s - loss: 0.8390 - val_loss: 0.7434 - 268s/epoch - 177ms/step\n",
            "Epoch 2/100\n",
            "Epoch 2: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 97s - loss: 0.6446 - val_loss: 0.5727 - 97s/epoch - 64ms/step\n",
            "Epoch 3/100\n",
            "Epoch 3: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 95s - loss: 0.5385 - val_loss: 0.5203 - 95s/epoch - 62ms/step\n",
            "Epoch 4/100\n",
            "Epoch 4: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 95s - loss: 0.4968 - val_loss: 0.4917 - 95s/epoch - 63ms/step\n",
            "Epoch 5/100\n",
            "Epoch 5: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.4727 - val_loss: 0.4797 - 93s/epoch - 61ms/step\n",
            "Epoch 6/100\n",
            "Epoch 6: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 95s - loss: 0.4557 - val_loss: 0.4709 - 95s/epoch - 62ms/step\n",
            "Epoch 7/100\n",
            "Epoch 7: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.4428 - val_loss: 0.4596 - 93s/epoch - 61ms/step\n",
            "Epoch 8/100\n",
            "Epoch 8: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 95s - loss: 0.4319 - val_loss: 0.4559 - 95s/epoch - 63ms/step\n",
            "Epoch 9/100\n",
            "Epoch 9: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 94s - loss: 0.4224 - val_loss: 0.4523 - 94s/epoch - 62ms/step\n",
            "Epoch 10/100\n",
            "Epoch 10: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 95s - loss: 0.4139 - val_loss: 0.4488 - 95s/epoch - 62ms/step\n",
            "Epoch 11/100\n",
            "Epoch 11: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 94s - loss: 0.4063 - val_loss: 0.4498 - 94s/epoch - 62ms/step\n",
            "Epoch 12/100\n",
            "Epoch 12: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.3993 - val_loss: 0.4455 - 93s/epoch - 61ms/step\n",
            "Epoch 13/100\n",
            "Epoch 13: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.3926 - val_loss: 0.4442 - 93s/epoch - 61ms/step\n",
            "Epoch 14/100\n",
            "Epoch 14: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.3863 - val_loss: 0.4433 - 93s/epoch - 61ms/step\n",
            "Epoch 15/100\n",
            "Epoch 15: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.3808 - val_loss: 0.4411 - 93s/epoch - 61ms/step\n",
            "Epoch 16/100\n",
            "Epoch 16: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.3753 - val_loss: 0.4474 - 93s/epoch - 61ms/step\n",
            "Epoch 17/100\n",
            "Epoch 17: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 93s - loss: 0.3701 - val_loss: 0.4434 - 93s/epoch - 61ms/step\n",
            "Epoch 18/100\n",
            "Epoch 18: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "Training stopped due to early stopping.\n",
            "1520/1520 - 93s - loss: 0.3650 - val_loss: 0.4453 - 93s/epoch - 61ms/step\n",
            "CPU times: user 1h 10min 8s, sys: 7min 1s, total: 1h 17min 9s\n",
            "Wall time: 31min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:22.467839Z",
          "iopub.execute_input": "2023-06-26T04:23:22.468542Z",
          "iopub.status.idle": "2023-06-26T04:23:22.523050Z",
          "shell.execute_reply.started": "2023-06-26T04:23:22.468503Z",
          "shell.execute_reply": "2023-06-26T04:23:22.522121Z"
        },
        "trusted": true,
        "id": "m0PK7-zbDp6E",
        "outputId": "c83ca452-cb90-4667-bee8-359a0a1aec0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " landmark_embedding_1 (Landm  (None, 128, 200)         1495600   \n",
            " arkEmbedding)                                                   \n",
            "                                                                 \n",
            " token_embedding_1 (TokenEmb  multiple                 133000    \n",
            " edding)                                                         \n",
            "                                                                 \n",
            " sequential_8 (Sequential)   (None, 128, 200)          3103600   \n",
            "                                                                 \n",
            " transformer_decoder_1 (Tran  multiple                 1447000   \n",
            " sformerDecoder)                                                 \n",
            "                                                                 \n",
            " dense_19 (Dense)            multiple                  12462     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,696,064\n",
            "Trainable params: 4,694,462\n",
            "Non-trainable params: 1,602\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:25.874327Z",
          "iopub.execute_input": "2023-06-26T04:23:25.874717Z",
          "iopub.status.idle": "2023-06-26T04:23:26.232494Z",
          "shell.execute_reply.started": "2023-06-26T04:23:25.874667Z",
          "shell.execute_reply": "2023-06-26T04:23:26.231586Z"
        },
        "trusted": true,
        "id": "BHA4qBuLDp6E",
        "outputId": "0d7d7cd7-2ef2-4bdb-c589-ca4910526883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1441cfcc40>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "SywRcwtGDp6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [batch for batch in val_dataset]\n",
        "\n",
        "preds_list = []\n",
        "ground_truth_list = []\n",
        "\n",
        "for batch in batches[:1]:\n",
        "    source = batch[0]\n",
        "    target = batch[1].numpy()\n",
        "    bs = tf.shape(source)[0]\n",
        "    preds = model.generate(source, start_token_idx)\n",
        "    preds = preds.numpy()\n",
        "\n",
        "    for i in range(bs):\n",
        "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
        "        ground_truth_list.append(target_text.replace('P', ''))\n",
        "        prediction = \"\"\n",
        "        for idx in preds[i, :]:\n",
        "            prediction += idx_to_char[idx]\n",
        "            if idx == end_token_idx:\n",
        "                break\n",
        "        preds_list.append(prediction)\n",
        "\n",
        "for i in range(10):\n",
        "    print(ground_truth_list[i])\n",
        "    print(preds_list[i])\n",
        "    print('\\n~~~\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:33.831503Z",
          "iopub.execute_input": "2023-06-26T04:23:33.832760Z",
          "iopub.status.idle": "2023-06-26T04:23:40.926369Z",
          "shell.execute_reply.started": "2023-06-26T04:23:33.832713Z",
          "shell.execute_reply": "2023-06-26T04:23:40.925390Z"
        },
        "trusted": true,
        "id": "CTn5dZ8ADp6F",
        "outputId": "b13aa7aa-3ffd-4ab6-d3ab-dc03bc88ac80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 creekhouseE\n",
            "S33 crekhouseE\n",
            "\n",
            "~~~\n",
            "\n",
            "Sscales/kuhaylahE\n",
            "Ssalees.chapuhay.laE\n",
            "\n",
            "~~~\n",
            "\n",
            "S1383 william lanierE\n",
            "S138383 willis lanierE\n",
            "\n",
            "~~~\n",
            "\n",
            "S988 franklin laneE\n",
            "S9888 frankan laneE\n",
            "\n",
            "~~~\n",
            "\n",
            "S6920 northeast 661st roadE\n",
            "S6920 southeast 66tst roadE\n",
            "\n",
            "~~~\n",
            "\n",
            "Swww.freem.ne.jpE\n",
            "Swww.frem.mesiE\n",
            "\n",
            "~~~\n",
            "\n",
            "Shttps://jsi.is/hukuokaE\n",
            "Shttps://jsi.isis/htkurokaE\n",
            "\n",
            "~~~\n",
            "\n",
            "S239613 stolze streetE\n",
            "S23961 trost olzes streetE\n",
            "\n",
            "~~~\n",
            "\n",
            "S271097 bayshore boulevardE\n",
            "S271097 bay toreboulevardE\n",
            "\n",
            "~~~\n",
            "\n",
            "Sfederico pearsonE\n",
            "SfedericopearonE\n",
            "\n",
            "~~~\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
        "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
        "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n",
        "            for i in range(len(preds_list_processed))]\n",
        "N = [len(phrase) for phrase in ground_truth_processed]\n",
        "\n",
        "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:45.163446Z",
          "iopub.execute_input": "2023-06-26T04:23:45.163846Z",
          "iopub.status.idle": "2023-06-26T04:23:45.171850Z",
          "shell.execute_reply.started": "2023-06-26T04:23:45.163812Z",
          "shell.execute_reply": "2023-06-26T04:23:45.170820Z"
        },
        "trusted": true,
        "id": "naN88UcIDp6F",
        "outputId": "1eb324dd-8c5c-4717-e5a8-e575363d53d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.7924528301886793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLiteModel"
      ],
      "metadata": {
        "id": "ucgKzMf4Dp6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " class TFLiteModel(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        super(TFLiteModel, self).__init__()\n",
        "        self.target_start_token_idx = start_token_idx\n",
        "        self.target_end_token_idx = end_token_idx\n",
        "        # Load the feature generation and main models\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n",
        "    def __call__(self, inputs, training=False):\n",
        "        # Preprocess Data\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = x[None]\n",
        "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n",
        "        x = x[0]\n",
        "        x = pre_process(x)\n",
        "        x = x[None]\n",
        "        x = self.model.generate(x, self.target_start_token_idx)\n",
        "        x = x[0]\n",
        "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
        "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
        "        x = x[1:idx]\n",
        "        x = tf.one_hot(x, 59)\n",
        "        return {'outputs': x}\n",
        "\n",
        "tflitemodel_base = TFLiteModel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:47.474886Z",
          "iopub.execute_input": "2023-06-26T04:23:47.476016Z",
          "iopub.status.idle": "2023-06-26T04:23:47.488141Z",
          "shell.execute_reply.started": "2023-06-26T04:23:47.475971Z",
          "shell.execute_reply": "2023-06-26T04:23:47.487131Z"
        },
        "trusted": true,
        "id": "tEcGTaJ2Dp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:50.183480Z",
          "iopub.execute_input": "2023-06-26T04:23:50.184185Z",
          "iopub.status.idle": "2023-06-26T04:23:50.376400Z",
          "shell.execute_reply.started": "2023-06-26T04:23:50.184149Z",
          "shell.execute_reply": "2023-06-26T04:23:50.375374Z"
        },
        "trusted": true,
        "id": "yC-8CLlHDp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
        "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = keras_model_converter.convert()\n",
        "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "infargs = {\"selected_columns\" : SEL_COLS}\n",
        "\n",
        "with open('inference_args.json', \"w\") as json_file:\n",
        "    json.dump(infargs, json_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:53.080752Z",
          "iopub.execute_input": "2023-06-26T04:23:53.081962Z",
          "iopub.status.idle": "2023-06-26T04:25:04.842986Z",
          "shell.execute_reply.started": "2023-06-26T04:23:53.081917Z",
          "shell.execute_reply": "2023-06-26T04:25:04.841993Z"
        },
        "trusted": true,
        "id": "0PxmgsFQDp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip submission.zip  './model.tflite' './inference_args.json'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:25:07.995108Z",
          "iopub.execute_input": "2023-06-26T04:25:07.995950Z",
          "iopub.status.idle": "2023-06-26T04:25:10.415570Z",
          "shell.execute_reply.started": "2023-06-26T04:25:07.995914Z",
          "shell.execute_reply": "2023-06-26T04:25:10.414236Z"
        },
        "trusted": true,
        "id": "S4U791C_Dp6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "output = prediction_fn(inputs=batch[0][0])\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print(prediction_str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:25:14.037030Z",
          "iopub.execute_input": "2023-06-26T04:25:14.037455Z",
          "iopub.status.idle": "2023-06-26T04:25:14.458201Z",
          "shell.execute_reply.started": "2023-06-26T04:25:14.037420Z",
          "shell.execute_reply": "2023-06-26T04:25:14.457173Z"
        },
        "trusted": true,
        "id": "YpI1MlRqDp6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KxaL1qFDp6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}