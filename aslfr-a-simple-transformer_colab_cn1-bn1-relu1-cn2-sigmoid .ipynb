{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "jYLbD5m5uNeZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! apt update\n",
        "! apt install gcsfuse"
      ],
      "metadata": {
        "id": "MzMgHxLluNkW",
        "outputId": "ec262a1f-3c3c-4419-e3bb-b9aba4ad9add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0   123k      0 --:--:-- --:--:-- --:--:--  123k\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,004 B]\n",
            "Get:4 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [2,286 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,820 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,299 kB]\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,416 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,360 kB]\n",
            "Fetched 10.2 MB in 3s (3,354 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "14 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 14.0 MB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 0.42.5 [14.0 MB]\n",
            "Fetched 14.0 MB in 0s (90.0 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.42.5_amd64.deb ...\n",
            "Unpacking gcsfuse (0.42.5) ...\n",
            "Setting up gcsfuse (0.42.5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZKk_26ZJ1ohe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kaggle get_gcspath\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "print(KaggleDatasets().get_gcs_path())"
      ],
      "metadata": {
        "id": "1GmDR8Lh1fku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3Q0v8LEtnE",
        "outputId": "4aca07a4-fb16-4f20-e636-0198750833de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p asl-fingerspelling\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-060e8f96f45da8817e298f5151de7d204c3aa2ebfe6436b68e8d87e2 asl-fingerspelling"
      ],
      "metadata": {
        "id": "olczO1_pC2TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba28047c-7958-4b73-d837-5404da0465d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0623 15:19:11.467075 2023/06/23 15:19:11.467048 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /content/asl-fingerspelling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p aslfr-parquets-to-tfrecords-cleaned\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-1865224784ea3c877e01e6064beb4b6fd74d08462427498e98ddc3df aslfr-parquets-to-tfrecords-cleaned"
      ],
      "metadata": {
        "id": "0E092szmuNnt",
        "outputId": "64453dcd-421e-4f95-db0f-c552790f90f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0623 15:19:12.382257 2023/06/23 15:19:12.382234 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /content/aslfr-parquets-to-tfrecords-cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esy-KMuR8ivw",
        "outputId": "05ebc3e5-db27-413d-b378-479d654f340f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. I used two transformer layer in the encoder instead of four.\n",
        "2. I used four attention heads instead of two.\n",
        "3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n",
        "2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n",
        "3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n",
        "4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n",
        "5. I added positional embedding to the encoder. This, too, had a significant impact.\n"
      ],
      "metadata": {
        "id": "KxyePP2G62KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import Levenshtein as lev\n",
        "import os\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:09.967808Z",
          "iopub.execute_input": "2023-06-22T11:53:09.968211Z",
          "iopub.status.idle": "2023-06-22T11:53:51.864967Z",
          "shell.execute_reply.started": "2023-06-22T11:53:09.968178Z",
          "shell.execute_reply": "2023-06-22T11:53:51.860974Z"
        },
        "trusted": true,
        "id": "edCaEbLT62Kd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "EJS9gqiG62Kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "inpdir = \"/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
        "display(df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:34.921833Z",
          "iopub.execute_input": "2023-06-21T12:27:34.922562Z",
          "iopub.status.idle": "2023-06-21T12:27:35.134638Z",
          "shell.execute_reply.started": "2023-06-21T12:27:34.922525Z",
          "shell.execute_reply": "2023-06-21T12:27:35.133695Z"
        },
        "id": "mgQWpYc-62Kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_landmarks = pd.read_parquet('/content/asl-fingerspelling/train_landmarks/1019715464.parquet')\n",
        "keys = train_landmarks.keys()[1:]\n",
        "train_landmarks.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:35.136172Z",
          "iopub.execute_input": "2023-06-21T12:27:35.136526Z",
          "iopub.status.idle": "2023-06-21T12:27:52.128059Z",
          "shell.execute_reply.started": "2023-06-21T12:27:35.136494Z",
          "shell.execute_reply": "2023-06-21T12:27:52.122672Z"
        },
        "id": "ZMCUEE3F62Kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFRecord"
      ],
      "metadata": {
        "id": "wXKQoVL862Kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.129279Z",
          "iopub.status.idle": "2023-06-21T12:27:52.130399Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.130158Z",
          "shell.execute_reply": "2023-06-21T12:27:52.130180Z"
        },
        "id": "RbjwD4gu62Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
        "\n",
        "counter = 0\n",
        "for file_id in tqdm(df.file_id.unique()):\n",
        "    \n",
        "    print(counter)\n",
        "    counter+=1\n",
        "    \n",
        "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
        "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
        "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
        "    seq_refs = df.loc[df.file_id == file_id]\n",
        "    seqs = load_relevant_data_subset(pqfile)\n",
        "    seqs_numpy = seqs.to_numpy()\n",
        "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
        "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
        "            frames = seqs_numpy[seqs.index == seq_id]\n",
        "            \n",
        "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
        "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
        "            no_nan = max(r_nonan, l_nonan)\n",
        "            \n",
        "            if 2*len(phrase)<no_nan:\n",
        "                features = {SEL_COLS[i]: tf.train.Feature(\n",
        "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n",
        "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
        "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
        "                file_writer.write(record_bytes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.131662Z",
          "iopub.status.idle": "2023-06-21T12:27:52.132528Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.132225Z",
          "shell.execute_reply": "2023-06-21T12:27:52.132253Z"
        },
        "id": "bEBOrTIc62Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "vcPLBcuH62Ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs)."
      ],
      "metadata": {
        "id": "QFAzucE-62Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = 'P'\n",
        "start_token = 'S'\n",
        "end_token = 'E'\n",
        "pad_token_idx = 59\n",
        "start_token_idx = 60\n",
        "end_token_idx = 61"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.866119Z",
          "iopub.status.idle": "2023-06-22T11:53:51.866535Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.866331Z",
          "shell.execute_reply": "2023-06-22T11:53:51.866350Z"
        },
        "trusted": true,
        "id": "fYfUURTc62Kj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    char_to_num = json.load(f)\n",
        "\n",
        "char_to_num.update({pad_token: pad_token_idx, start_token: start_token_idx, end_token: end_token_idx})\n",
        "num_to_char = {j: i for i, j in char_to_num.items()}\n",
        "\n",
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f\"{inpdir}/train.csv\")\n",
        "\n",
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f\"x_right_hand_{i}\" for i in range(21)] + [f\"y_right_hand_{i}\" for i in range(21)] + [\n",
        "    f\"z_right_hand_{i}\" for i in range(21)\n",
        "]\n",
        "LHAND_LBLS = [f\"x_left_hand_{i}\" for i in range(21)] + [f\"y_left_hand_{i}\" for i in range(21)] + [\n",
        "    f\"z_left_hand_{i}\" for i in range(21)\n",
        "]\n",
        "POSE_LBLS = [f\"x_pose_{i}\" for i in POSE] + [f\"y_pose_{i}\" for i in POSE] + [f\"z_pose_{i}\" for i in POSE]\n",
        "\n",
        "SEL_COLS = RHAND_LBLS + LHAND_LBLS + POSE_LBLS\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS) if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS) if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS) if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS) if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS) if \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS) if \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS) if \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print(RPOSE_IDX)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.869024Z",
          "iopub.status.idle": "2023-06-22T11:53:51.869450Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.869243Z",
          "shell.execute_reply": "2023-06-22T11:53:51.869262Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GsPAlJn62Kk",
        "outputId": "3aeb5983-d2ba-4ea2-d94c-a7932046b00c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[131, 132, 133, 134, 135, 141, 142, 143, 144, 145, 151, 152, 153, 154, 155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{0: ' ', 1: '!', 2: '#', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: '+', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '=', 28: '?', 29: '@', 30: '[', 31: '_', 32: 'a', 33: 'b', 34: 'c', 35: 'd', 36: 'e', 37: 'f', 38: 'g', 39: 'h', 40: 'i', 41: 'j', 42: 'k', 43: 'l', 44: 'm', 45: 'n', 46: 'o', 47: 'p', 48: 'q', 49: 'r', 50: 's', 51: 't', 52: 'u', 53: 'v', 54: 'w', 55: 'x', 56: 'y', 57: 'z', 58: '~', 59: 'P', 60: 'S', 61: 'E'}\n",
        "add Codeadd Markdown"
      ],
      "metadata": {
        "id": "08Oj3uvq62Kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_pad(x):\n",
        "    if tf.shape(x)[0] < FRAME_LEN:\n",
        "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
        "        print(x)\n",
        "    else:\n",
        "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
        "    return x\n",
        "\n",
        "def pre_process(x):\n",
        "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
        "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
        "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
        "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
        "\n",
        "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
        "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
        "\n",
        "    rnans = tf.math.count_nonzero(rnan_idx)\n",
        "    lnans = tf.math.count_nonzero(lnan_idx)\n",
        "\n",
        "    # For dominant hand\n",
        "    if rnans > lnans:\n",
        "        hand = lhand\n",
        "        pose = lpose\n",
        "\n",
        "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
        "\n",
        "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
        "    else:\n",
        "        hand = rhand\n",
        "        pose = rpose\n",
        "\n",
        "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
        "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
        "    hand = (hand - mean) / std\n",
        "\n",
        "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    x = tf.concat([hand, pose], axis=1)\n",
        "    x = resize_pad(x)\n",
        "\n",
        "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.870826Z",
          "iopub.status.idle": "2023-06-22T11:53:51.871228Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.871029Z",
          "shell.execute_reply": "2023-06-22T11:53:51.871048Z"
        },
        "trusted": true,
        "id": "Gw3CZwIA62Kl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=list(char_to_num.keys()),\n",
        "        values=list(char_to_num.values()),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name=\"class_weight\"\n",
        ")\n",
        "\n",
        "def preprocess_fn(landmarks, phrase):\n",
        "    phrase = start_token + phrase + end_token\n",
        "    phrase = tf.strings.bytes_split(phrase)\n",
        "    phrase = table.lookup(phrase)\n",
        "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
        "                    constant_values = pad_token_idx)\n",
        "    return pre_process(landmarks), phrase\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n",
        "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "    phrase = features[\"phrase\"]\n",
        "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n",
        "    landmarks = tf.transpose(landmarks)\n",
        "\n",
        "    return landmarks, phrase\n",
        "\n",
        "inpdir = \"/content/aslfr-parquets-to-tfrecords-cleaned\"\n",
        "tffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n",
        "\n",
        "batch_size = 32\n",
        "val_len = int(0.05 * len(tffiles))\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.873256Z",
          "iopub.status.idle": "2023-06-22T11:53:51.873650Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.873454Z",
          "shell.execute_reply": "2023-06-22T11:53:51.873472Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SC25Kla62Km",
        "outputId": "44082786-005e-4464-f1ff-1539dabcf49c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model"
      ],
      "metadata": {
        "id": "zuB2eBst62Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j0W_0E3PAvGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:e865f0c6-0e14-4387-9779-537f8b3d065d.png)\n",
        "![image.png](attachment:39ec8854-9e5f-4617-aa6a-69098b605134.png)\n",
        "![image.png](attachment:8b28cc87-2b4a-467f-a818-44b7e1f8dc8f.png)\n",
        "![image.png](attachment:243f34f9-3f88-4452-aac7-ee1ec0a3d065.png)"
      ],
      "metadata": {
        "id": "vz53KKHV62Kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I implemented proper positional embeddings for both the encoder and the decoder."
      ],
      "metadata": {
        "id": "ccMm9mKh62Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(layers.Layer):\n",
        "    def __init__(self, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu),\n",
        "            tf.keras.layers.Dense(num_hid)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.mlp(inputs)\n",
        "\n",
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
        "        self.mlp_block = MLPBlock(num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb[:maxlen, :]\n",
        "        x = self.mlp_block(x)\n",
        "        return x\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid / 2\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype=tf.float32)[np.newaxis, :] / depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "            [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "            axis=-1)\n",
        "        return pos_encoding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.876803Z",
          "iopub.status.idle": "2023-06-22T11:53:51.877205Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.877002Z",
          "shell.execute_reply": "2023-06-22T11:53:51.877019Z"
        },
        "trusted": true,
        "id": "OlFG4Y3L62Kn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "        '''\n",
        "        self.pos_emb = tf.math.divide(\n",
        "            self.positional_encoding(maxlen-1, num_hid),\n",
        "            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n",
        "        '''\n",
        "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        '''\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "        '''\n",
        "        return x + self.pos_emb[:maxlen, :]\n",
        "    \n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T01:27:59.514789Z",
          "iopub.execute_input": "2023-06-22T01:27:59.517058Z",
          "iopub.status.idle": "2023-06-22T01:27:59.530952Z",
          "shell.execute_reply.started": "2023-06-22T01:27:59.517017Z",
          "shell.execute_reply": "2023-06-22T01:27:59.529987Z"
        },
        "id": "Nb7meuNX62Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu1 = tf.keras.layers.ReLU()\n",
        "        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\")\n",
        "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
        "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
        "        self.maxlen = maxlen\n",
        "        self.num_hid = num_hid\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid / 2\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype=tf.float32)[np.newaxis, :] / depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "            [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "            axis=-1)\n",
        "        return pos_encoding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.878408Z",
          "iopub.status.idle": "2023-06-22T11:53:51.878801Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.878591Z",
          "shell.execute_reply": "2023-06-22T11:53:51.878627Z"
        },
        "trusted": true,
        "id": "GDA7zwGH62Ko"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Old<br>\n",
        "class LandmarkEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv2 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv3 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
        "        self.maxlen = maxlen\n",
        "        self.num_hid = num_hid\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:29:09.513052Z",
          "iopub.execute_input": "2023-06-21T12:29:09.513538Z",
          "iopub.status.idle": "2023-06-21T12:29:09.528297Z",
          "shell.execute_reply.started": "2023-06-21T12:29:09.513507Z",
          "shell.execute_reply": "2023-06-21T12:29:09.527154Z"
        },
        "id": "XPA3CfIQ62Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.880202Z",
          "iopub.status.idle": "2023-06-22T11:53:51.880585Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.880388Z",
          "shell.execute_reply": "2023-06-22T11:53:51.880406Z"
        },
        "trusted": true,
        "id": "JehiEo1362Ko"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I added the training flag to the TransformerDecoder's Dropout layers."
      ],
      "metadata": {
        "id": "YMQHCZ3462Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target, training):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.882184Z",
          "iopub.status.idle": "2023-06-22T11:53:51.882530Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.882355Z",
          "shell.execute_reply": "2023-06-22T11:53:51.882371Z"
        },
        "trusted": true,
        "id": "p9LfuEp562Kp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I made the passing of the training flag explicit."
      ],
      "metadata": {
        "id": "arigUkCk62Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target, training):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source, training)\n",
        "        y = self.decode(x, target, training)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source, training = False)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input, training = False)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = logits[:, -1][..., tf.newaxis]\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.883756Z",
          "iopub.status.idle": "2023-06-22T11:53:51.884116Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.883940Z",
          "shell.execute_reply": "2023-06-22T11:53:51.883956Z"
        },
        "trusted": true,
        "id": "ynQ2v2gk62Kq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(val_dataset))\n",
        "idx_to_char = list(char_to_num.keys())\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=4,\n",
        "    num_feed_forward=400,\n",
        "    source_maxlen = FRAME_LEN,\n",
        "    target_maxlen=64,\n",
        "    num_layers_enc=2,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=62,\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(0.0001)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.885459Z",
          "iopub.status.idle": "2023-06-22T11:53:51.885802Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.885623Z",
          "shell.execute_reply": "2023-06-22T11:53:51.885639Z"
        },
        "trusted": true,
        "id": "81xX7XPN62Kq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model.fit(train_dataset, verbose = 2, validation_data=val_dataset, epochs=18)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.887052Z",
          "iopub.status.idle": "2023-06-22T11:53:51.887471Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.887266Z",
          "shell.execute_reply": "2023-06-22T11:53:51.887284Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4_yPrN62Kq",
        "outputId": "88328791-18ab-4e19-cc88-bd8500eb9f2f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "1520/1520 - 474s - loss: 0.7948 - val_loss: 0.6688 - 474s/epoch - 312ms/step\n",
            "Epoch 2/18\n",
            "1520/1520 - 73s - loss: 0.5909 - val_loss: 0.5454 - 73s/epoch - 48ms/step\n",
            "Epoch 3/18\n",
            "1520/1520 - 73s - loss: 0.5228 - val_loss: 0.5138 - 73s/epoch - 48ms/step\n",
            "Epoch 4/18\n",
            "1520/1520 - 73s - loss: 0.4934 - val_loss: 0.4968 - 73s/epoch - 48ms/step\n",
            "Epoch 5/18\n",
            "1520/1520 - 72s - loss: 0.4746 - val_loss: 0.4812 - 72s/epoch - 48ms/step\n",
            "Epoch 6/18\n",
            "1520/1520 - 72s - loss: 0.4612 - val_loss: 0.4717 - 72s/epoch - 48ms/step\n",
            "Epoch 7/18\n",
            "1520/1520 - 72s - loss: 0.4499 - val_loss: 0.4663 - 72s/epoch - 47ms/step\n",
            "Epoch 8/18\n",
            "1520/1520 - 72s - loss: 0.4406 - val_loss: 0.4601 - 72s/epoch - 47ms/step\n",
            "Epoch 9/18\n",
            "1520/1520 - 72s - loss: 0.4328 - val_loss: 0.4568 - 72s/epoch - 48ms/step\n",
            "Epoch 10/18\n",
            "1520/1520 - 73s - loss: 0.4257 - val_loss: 0.4564 - 73s/epoch - 48ms/step\n",
            "Epoch 11/18\n",
            "1520/1520 - 73s - loss: 0.4191 - val_loss: 0.4553 - 73s/epoch - 48ms/step\n",
            "Epoch 12/18\n",
            "1520/1520 - 76s - loss: 0.4130 - val_loss: 0.4524 - 76s/epoch - 50ms/step\n",
            "Epoch 13/18\n",
            "1520/1520 - 72s - loss: 0.4074 - val_loss: 0.4535 - 72s/epoch - 48ms/step\n",
            "Epoch 14/18\n",
            "1520/1520 - 72s - loss: 0.4020 - val_loss: 0.4522 - 72s/epoch - 47ms/step\n",
            "Epoch 15/18\n",
            "1520/1520 - 72s - loss: 0.3967 - val_loss: 0.4505 - 72s/epoch - 48ms/step\n",
            "Epoch 16/18\n",
            "1520/1520 - 72s - loss: 0.3920 - val_loss: 0.4523 - 72s/epoch - 48ms/step\n",
            "Epoch 17/18\n",
            "1520/1520 - 73s - loss: 0.3876 - val_loss: 0.4535 - 73s/epoch - 48ms/step\n",
            "Epoch 18/18\n",
            "1520/1520 - 72s - loss: 0.3831 - val_loss: 0.4508 - 72s/epoch - 48ms/step\n",
            "CPU times: user 58min 13s, sys: 6min 17s, total: 1h 4min 31s\n",
            "Wall time: 28min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.888442Z",
          "iopub.status.idle": "2023-06-22T11:53:51.888821Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.888629Z",
          "shell.execute_reply": "2023-06-22T11:53:51.888647Z"
        },
        "trusted": true,
        "id": "Fzs392FF62Kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1ecb88-895d-4b3f-c3c4-80ee796d4553"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " landmark_embedding (Landmar  (None, 128, 200)         612800    \n",
            " kEmbedding)                                                     \n",
            "                                                                 \n",
            " token_embedding (TokenEmbed  multiple                 92800     \n",
            " ding)                                                           \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 128, 200)          2220800   \n",
            "                                                                 \n",
            " transformer_decoder (Transf  multiple                 1447000   \n",
            " ormerDecoder)                                                   \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  12462     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,773,064\n",
            "Trainable params: 3,772,662\n",
            "Non-trainable params: 402\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.890084Z",
          "iopub.status.idle": "2023-06-22T11:53:51.890469Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.890276Z",
          "shell.execute_reply": "2023-06-22T11:53:51.890294Z"
        },
        "trusted": true,
        "id": "DICn3MxF62Kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "95999bcc-b8cc-4cf6-b43b-e479127ab4da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f00d0f41f90>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "il0EJrPK62Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [batch for batch in val_dataset]\n",
        "\n",
        "preds_list = []\n",
        "ground_truth_list = []\n",
        "\n",
        "for batch in batches[:1]:\n",
        "    source = batch[0]\n",
        "    target = batch[1].numpy()\n",
        "    bs = tf.shape(source)[0]\n",
        "    preds = model.generate(source, start_token_idx)\n",
        "    preds = preds.numpy()\n",
        "\n",
        "    for i in range(bs):\n",
        "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
        "        ground_truth_list.append(target_text.replace('P', ''))\n",
        "        prediction = \"\"\n",
        "        for idx in preds[i, :]:\n",
        "            prediction += idx_to_char[idx]\n",
        "            if idx == end_token_idx:\n",
        "                break\n",
        "        preds_list.append(prediction)\n",
        "\n",
        "for i in range(10):\n",
        "    print(ground_truth_list[i])\n",
        "    print(preds_list[i])\n",
        "    print('\\n~~~\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.891653Z",
          "iopub.status.idle": "2023-06-22T11:53:51.892172Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.891821Z",
          "shell.execute_reply": "2023-06-22T11:53:51.891838Z"
        },
        "trusted": true,
        "id": "irYDcnDk62Kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8a34fd-2c18-4e98-f446-bcfe6399de44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 creekhouseE\n",
            "S33 creekhorseE\n",
            "\n",
            "~~~\n",
            "\n",
            "Sscales/kuhaylahE\n",
            "Sscales/ces/hauhaE\n",
            "\n",
            "~~~\n",
            "\n",
            "S1383 william lanierE\n",
            "S1386 jalliam lanierE\n",
            "\n",
            "~~~\n",
            "\n",
            "S988 franklin laneE\n",
            "S988 funding laneE\n",
            "\n",
            "~~~\n",
            "\n",
            "S6920 northeast 661st roadE\n",
            "S6920 northeast 61st roadE\n",
            "\n",
            "~~~\n",
            "\n",
            "Swww.freem.ne.jpE\n",
            "Swww.frem.meE\n",
            "\n",
            "~~~\n",
            "\n",
            "Shttps://jsi.is/hukuokaE\n",
            "Shttps://i.itis/hkurokaE\n",
            "\n",
            "~~~\n",
            "\n",
            "S239613 stolze streetE\n",
            "S3961 33rst road southE\n",
            "\n",
            "~~~\n",
            "\n",
            "S271097 bayshore boulevardE\n",
            "S271097 bay horeboulevardE\n",
            "\n",
            "~~~\n",
            "\n",
            "Sfederico pearsonE\n",
            "S9 ederico aronE\n",
            "\n",
            "~~~\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
        "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
        "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n",
        "            for i in range(len(preds_list_processed))]\n",
        "N = [len(phrase) for phrase in ground_truth_processed]\n",
        "\n",
        "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.893132Z",
          "iopub.status.idle": "2023-06-22T11:53:51.893484Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.893309Z",
          "shell.execute_reply": "2023-06-22T11:53:51.893326Z"
        },
        "trusted": true,
        "id": "_BW7r2hn62Ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7875cd-1e01-4e72-d9cb-e3a5262db7d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.7238421955403087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLiteModel"
      ],
      "metadata": {
        "id": "TGV3XKc962Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " class TFLiteModel(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        super(TFLiteModel, self).__init__()\n",
        "        self.target_start_token_idx = start_token_idx\n",
        "        self.target_end_token_idx = end_token_idx\n",
        "        # Load the feature generation and main models\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n",
        "    def __call__(self, inputs, training=False):\n",
        "        # Preprocess Data\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = x[None]\n",
        "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n",
        "        x = x[0]\n",
        "        x = pre_process(x)\n",
        "        x = x[None]\n",
        "        x = self.model.generate(x, self.target_start_token_idx)\n",
        "        x = x[0]\n",
        "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
        "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
        "        x = x[1:idx]\n",
        "        x = tf.one_hot(x, 59)\n",
        "        return {'outputs': x}\n",
        "\n",
        "tflitemodel_base = TFLiteModel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.894606Z",
          "iopub.status.idle": "2023-06-22T11:53:51.895005Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.894769Z",
          "shell.execute_reply": "2023-06-22T11:53:51.894802Z"
        },
        "trusted": true,
        "id": "R36nDeVf62Ks"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.896159Z",
          "iopub.status.idle": "2023-06-22T11:53:51.896513Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.896337Z",
          "shell.execute_reply": "2023-06-22T11:53:51.896354Z"
        },
        "trusted": true,
        "id": "65NJJTUt62Ks"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
        "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = keras_model_converter.convert()\n",
        "with open('/content/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "infargs = {\"selected_columns\" : SEL_COLS}\n",
        "\n",
        "with open('inference_args.json', \"w\") as json_file:\n",
        "    json.dump(infargs, json_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.898465Z",
          "iopub.status.idle": "2023-06-22T11:53:51.898865Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.898661Z",
          "shell.execute_reply": "2023-06-22T11:53:51.898679Z"
        },
        "trusted": true,
        "id": "tr1IMQGF62Ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98be9b6-b7d9-48f8-e3da-20cc98284e5e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv1d_layer_call_fn, conv1d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_layer_call_fn while saving (showing 5 of 99). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip submission.zip  './model.tflite' './inference_args.json'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.899810Z",
          "iopub.status.idle": "2023-06-22T11:53:51.900210Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.900008Z",
          "shell.execute_reply": "2023-06-22T11:53:51.900026Z"
        },
        "trusted": true,
        "id": "enaNEGcm62LG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d75fde-3787-4b9e-e9cb-35c74d6432f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model.tflite (deflated 20%)\n",
            "  adding: inference_args.json (deflated 85%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "output = prediction_fn(inputs=batch[0][0])\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print(prediction_str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T11:53:51.901623Z",
          "iopub.status.idle": "2023-06-22T11:53:51.901983Z",
          "shell.execute_reply.started": "2023-06-22T11:53:51.901792Z",
          "shell.execute_reply": "2023-06-22T11:53:51.901808Z"
        },
        "trusted": true,
        "id": "VJrRDRcs62LG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef53acaa-fa08-4ed2-ecb7-f44cdaa1689e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8899 comon\n"
          ]
        }
      ]
    }
  ]
}