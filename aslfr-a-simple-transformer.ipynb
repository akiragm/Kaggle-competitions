{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09467e8",
   "metadata": {
    "papermill": {
     "duration": 0.010292,
     "end_time": "2023-07-07T06:00:21.248138",
     "exception": false,
     "start_time": "2023-07-07T06:00:21.237846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "1. I used two transformer layer in the encoder instead of four.\n",
    "2. I used four attention heads instead of two.\n",
    "3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n",
    "2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n",
    "3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n",
    "4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n",
    "5. I added positional embedding to the encoder. This, too, had a significant impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9245d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:21.269928Z",
     "iopub.status.busy": "2023-07-07T06:00:21.269116Z",
     "iopub.status.idle": "2023-07-07T06:00:31.076821Z",
     "shell.execute_reply": "2023-07-07T06:00:31.075867Z"
    },
    "papermill": {
     "duration": 9.821331,
     "end_time": "2023-07-07T06:00:31.079221",
     "exception": false,
     "start_time": "2023-07-07T06:00:21.257890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import Levenshtein as lev\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e466783",
   "metadata": {
    "papermill": {
     "duration": 0.009833,
     "end_time": "2023-07-07T06:00:31.098443",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.088610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af407c",
   "metadata": {
    "papermill": {
     "duration": 0.009251,
     "end_time": "2023-07-07T06:00:31.117452",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.108201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "inpdir = \"/kaggle/input/asl-fingerspelling\"\n",
    "df = pd.read_csv(f'{inpdir}/train.csv')\n",
    "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea4487e",
   "metadata": {
    "papermill": {
     "duration": 0.009263,
     "end_time": "2023-07-07T06:00:31.136239",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.126976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "train_landmarks = pd.read_parquet('/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet')\n",
    "keys = train_landmarks.keys()[1:]\n",
    "train_landmarks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e4908",
   "metadata": {
    "papermill": {
     "duration": 0.009463,
     "end_time": "2023-07-07T06:00:31.154948",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.145485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abda4c5",
   "metadata": {
    "papermill": {
     "duration": 0.009348,
     "end_time": "2023-07-07T06:00:31.173988",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.164640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LPOSE = [13, 15, 17, 19, 21]\n",
    "RPOSE = [14, 16, 18, 20, 22]\n",
    "POSE = LPOSE + RPOSE\n",
    "\n",
    "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
    "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
    "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
    "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
    "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "SEL_COLS = X + Y + Z\n",
    "FRAME_LEN = 128\n",
    "\n",
    "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
    "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
    "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
    "\n",
    "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
    "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
    "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
    "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
    "\n",
    "print('SEL_COLS size:' + str(len(SEL_COLS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef5b08",
   "metadata": {
    "papermill": {
     "duration": 0.009186,
     "end_time": "2023-07-07T06:00:31.192485",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.183299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def load_relevant_data_subset(pq_path):\n",
    "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
    "\n",
    "counter = 0\n",
    "for file_id in tqdm(df.file_id.unique()):\n",
    "    \n",
    "    print(counter)\n",
    "    counter+=1\n",
    "    \n",
    "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
    "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
    "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
    "    seq_refs = df.loc[df.file_id == file_id]\n",
    "    seqs = load_relevant_data_subset(pqfile)\n",
    "    seqs_numpy = seqs.to_numpy()\n",
    "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
    "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
    "            frames = seqs_numpy[seqs.index == seq_id]\n",
    "            \n",
    "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
    "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
    "            no_nan = max(r_nonan, l_nonan)\n",
    "            \n",
    "            if 2*len(phrase)<no_nan:\n",
    "                features = {SEL_COLS[i]: tf.train.Feature(\n",
    "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n",
    "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
    "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
    "                file_writer.write(record_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef3a7a",
   "metadata": {
    "papermill": {
     "duration": 0.009225,
     "end_time": "2023-07-07T06:00:31.211432",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.202207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e17a2",
   "metadata": {
    "papermill": {
     "duration": 0.009629,
     "end_time": "2023-07-07T06:00:31.230507",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.220878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7097dbb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:31.250558Z",
     "iopub.status.busy": "2023-07-07T06:00:31.249888Z",
     "iopub.status.idle": "2023-07-07T06:00:31.255283Z",
     "shell.execute_reply": "2023-07-07T06:00:31.254305Z"
    },
    "papermill": {
     "duration": 0.017474,
     "end_time": "2023-07-07T06:00:31.257226",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.239752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pad_token = 'P'\n",
    "start_token = 'S'\n",
    "end_token = 'E'\n",
    "pad_token_idx = 59\n",
    "start_token_idx = 60\n",
    "end_token_idx = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e05294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:31.277230Z",
     "iopub.status.busy": "2023-07-07T06:00:31.276731Z",
     "iopub.status.idle": "2023-07-07T06:00:31.433060Z",
     "shell.execute_reply": "2023-07-07T06:00:31.432044Z"
    },
    "papermill": {
     "duration": 0.168492,
     "end_time": "2023-07-07T06:00:31.435269",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.266777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 48, 49, 50, 51, 99, 100, 101, 102, 103, 151, 152, 153, 154, 155]\n"
     ]
    }
   ],
   "source": [
    "with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "    char_to_num = json.load(f)\n",
    "\n",
    "\n",
    "char_to_num[pad_token] = pad_token_idx\n",
    "char_to_num[start_token] = start_token_idx\n",
    "char_to_num[end_token] = end_token_idx\n",
    "\n",
    "num_to_char = {j:i for i,j in char_to_num.items()}\n",
    "\n",
    "\n",
    "inpdir = \"/kaggle/input/asl-fingerspelling\"\n",
    "df = pd.read_csv(f'{inpdir}/train.csv')\n",
    "\n",
    "LPOSE = [13, 15, 17, 19, 21]\n",
    "RPOSE = [14, 16, 18, 20, 22]\n",
    "POSE = LPOSE + RPOSE\n",
    "\n",
    "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
    "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
    "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
    "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
    "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "SEL_COLS = X + Y + Z\n",
    "FRAME_LEN = 128\n",
    "\n",
    "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
    "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
    "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
    "\n",
    "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
    "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
    "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
    "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
    "\n",
    "print(RPOSE_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab1272c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:31.457436Z",
     "iopub.status.busy": "2023-07-07T06:00:31.457118Z",
     "iopub.status.idle": "2023-07-07T06:00:31.478476Z",
     "shell.execute_reply": "2023-07-07T06:00:31.477467Z"
    },
    "papermill": {
     "duration": 0.034959,
     "end_time": "2023-07-07T06:00:31.480605",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.445646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_pad(x):\n",
    "    if tf.shape(x)[0] < FRAME_LEN:\n",
    "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
    "        print(x)\n",
    "    else:\n",
    "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
    "    return x\n",
    "\n",
    "def translate_landmarks(landmarks, max_translation):\n",
    "    translation = tf.random.uniform(shape=tf.shape(landmarks), minval=-max_translation, maxval=max_translation)\n",
    "    translated_landmarks = landmarks + translation\n",
    "    return translated_landmarks\n",
    "\n",
    "# def scale_landmarks(landmarks, min_scale, max_scale):\n",
    "#     scale_factor = tf.random.uniform(shape=tf.shape(landmarks), minval=min_scale, maxval=max_scale)\n",
    "#     scaled_landmarks = landmarks * scale_factor\n",
    "#     return scaled_landmarks\n",
    "\n",
    "def pre_process(x):\n",
    "\n",
    "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
    "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
    "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
    "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
    "\n",
    "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
    "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
    "\n",
    "    rnans = tf.math.count_nonzero(rnan_idx)\n",
    "    lnans = tf.math.count_nonzero(lnan_idx)\n",
    "\n",
    "    # For dominant hand\n",
    "    if rnans > lnans:\n",
    "        hand = lhand\n",
    "        pose = lpose\n",
    "\n",
    "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
    "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
    "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
    "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
    "\n",
    "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
    "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
    "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
    "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
    "    else:\n",
    "        hand = rhand\n",
    "        pose = rpose\n",
    "\n",
    "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
    "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
    "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
    "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
    "\n",
    "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
    "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
    "    hand = (hand - mean) / std\n",
    "\n",
    "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
    "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
    "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
    "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
    "\n",
    "    x = tf.concat([hand, pose], axis=1)\n",
    "    x = resize_pad(x)\n",
    "\n",
    "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da9998d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:31.501817Z",
     "iopub.status.busy": "2023-07-07T06:00:31.500393Z",
     "iopub.status.idle": "2023-07-07T06:00:36.353430Z",
     "shell.execute_reply": "2023-07-07T06:00:36.351090Z"
    },
    "papermill": {
     "duration": 4.865726,
     "end_time": "2023-07-07T06:00:36.355703",
     "exception": false,
     "start_time": "2023-07-07T06:00:31.489977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
      "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=list(char_to_num.keys()),\n",
    "        values=list(char_to_num.values()),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"class_weight\"\n",
    ")\n",
    "\n",
    "def preprocess_fn(landmarks, phrase):\n",
    "    phrase = start_token + phrase + end_token\n",
    "    phrase = tf.strings.bytes_split(phrase)\n",
    "    phrase = table.lookup(phrase)\n",
    "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
    "                    constant_values = pad_token_idx)\n",
    "\n",
    "    # landmarksを前処理する\n",
    "    translated_landmarks = translate_landmarks(landmarks, max_translation=10)\n",
    "    #scaled_landmarks = scale_landmarks(landmarks, min_scale=0.8, max_scale=1.2)\n",
    "\n",
    "    # 前処理済みのlandmarksを結合する\n",
    "    #combined_landmarks = tf.concat([landmarks, translated_landmarks, scaled_landmarks], axis=1)\n",
    "    combined_landmarks = tf.concat([landmarks, translated_landmarks], axis=1)\n",
    "    return pre_process(combined_landmarks), phrase\n",
    "\n",
    "def decode_fn(record_bytes):\n",
    "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n",
    "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "    features = tf.io.parse_single_example(record_bytes, schema)\n",
    "    phrase = features[\"phrase\"]\n",
    "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n",
    "    landmarks = tf.transpose(landmarks)\n",
    "\n",
    "    return landmarks, phrase\n",
    "\n",
    "inpdir = \"/kaggle/input/aslfr-parquets-to-tfrecords-cleaned\"\n",
    "tffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n",
    "\n",
    "batch_size = 32\n",
    "val_len = int(0.05 * len(tffiles))\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c96551",
   "metadata": {
    "papermill": {
     "duration": 0.009974,
     "end_time": "2023-07-07T06:00:36.375654",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.365680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9024b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.396398Z",
     "iopub.status.busy": "2023-07-07T06:00:36.396054Z",
     "iopub.status.idle": "2023-07-07T06:00:36.410612Z",
     "shell.execute_reply": "2023-07-07T06:00:36.409424Z"
    },
    "papermill": {
     "duration": 0.027608,
     "end_time": "2023-07-07T06:00:36.412757",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.385149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEL_COLS size:156\n"
     ]
    }
   ],
   "source": [
    "LPOSE = [13, 15, 17, 19, 21]\n",
    "RPOSE = [14, 16, 18, 20, 22]\n",
    "\n",
    "POSE = LPOSE + RPOSE\n",
    "\n",
    "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
    "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
    "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
    "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
    "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "SEL_COLS = X + Y + Z\n",
    "FRAME_LEN = 128\n",
    "\n",
    "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
    "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
    "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
    "\n",
    "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
    "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
    "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
    "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
    "\n",
    "print('SEL_COLS size:' + str(len(SEL_COLS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf7d7e",
   "metadata": {
    "papermill": {
     "duration": 0.009623,
     "end_time": "2023-07-07T06:00:36.431891",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.422268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Here I implemented proper positional embeddings for both the encoder and the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afec7d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.452628Z",
     "iopub.status.busy": "2023-07-07T06:00:36.451966Z",
     "iopub.status.idle": "2023-07-07T06:00:36.463664Z",
     "shell.execute_reply": "2023-07-07T06:00:36.462699Z"
    },
    "papermill": {
     "duration": 0.024198,
     "end_time": "2023-07-07T06:00:36.465675",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.441477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPBlock(layers.Layer):\n",
    "    def __init__(self, num_hid=256, num_layers=5):\n",
    "        super().__init__()\n",
    "        self.mlp = tf.keras.Sequential()\n",
    "        for _ in range(num_layers):\n",
    "            self.mlp.add(tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu))\n",
    "        self.mlp.add(tf.keras.layers.Dense(num_hid))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.mlp(inputs)\n",
    "\n",
    "\n",
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=61, maxlen=50, num_hid=256, mlp_num_layers=5):\n",
    "        super().__init__()\n",
    "        self.num_hid = num_hid\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = self.positional_encoding(maxlen - 1, num_hid)\n",
    "        self.mlp_block = MLPBlock(num_hid, num_layers=mlp_num_layers)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x) * tf.math.sqrt(tf.cast(self.num_hid, tf.float32))\n",
    "        x = x + self.pos_emb[:maxlen, :]\n",
    "        x = self.mlp_block(x)\n",
    "        return x\n",
    "\n",
    "    def positional_encoding(self, maxlen, num_hid):\n",
    "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
    "        depth = num_hid // 2\n",
    "        angles = positions / tf.pow(10000, tf.range(0, depth, 1, dtype=tf.float32) / num_hid)  # depthのインクリメントを修正\n",
    "        pos_encoding = tf.concat([tf.sin(angles), tf.cos(angles)], axis=-1)\n",
    "        return pos_encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356c544",
   "metadata": {
    "papermill": {
     "duration": 0.009591,
     "end_time": "2023-07-07T06:00:36.484812",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.475221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.num_hid = num_hid\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "        '''\n",
    "        self.pos_emb = tf.math.divide(\n",
    "            self.positional_encoding(maxlen-1, num_hid),\n",
    "            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n",
    "        '''\n",
    "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
    "        '''\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "        '''\n",
    "        return x + self.pos_emb[:maxlen, :]\n",
    "    \n",
    "    def positional_encoding(self, maxlen, num_hid):\n",
    "        depth = num_hid/2\n",
    "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
    "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
    "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
    "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
    "        pos_encoding = tf.concat(\n",
    "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
    "          axis=-1)\n",
    "        return pos_encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48acf6af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.514439Z",
     "iopub.status.busy": "2023-07-07T06:00:36.514127Z",
     "iopub.status.idle": "2023-07-07T06:00:36.532805Z",
     "shell.execute_reply": "2023-07-07T06:00:36.531795Z"
    },
    "papermill": {
     "duration": 0.036615,
     "end_time": "2023-07-07T06:00:36.535172",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.498557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarkEmbedding(tf.keras.Model):\n",
    "    def __init__(self, num_hid=256, maxlen=100):\n",
    "        super(LandmarkEmbedding, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu1 = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu2 = tf.keras.layers.LeakyReLU()\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "        self.conv3 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu3 = tf.keras.layers.LeakyReLU()\n",
    "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "        self.conv4 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu4 = tf.keras.layers.LeakyReLU()\n",
    "        self.dropout4 = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
    "        self.maxlen = maxlen\n",
    "        self.num_hid = num_hid\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leaky_relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.leaky_relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.leaky_relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.leaky_relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
    "        x = x + self.pos_emb\n",
    "\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def positional_encoding(self, maxlen, num_hid):\n",
    "        depth = num_hid/2\n",
    "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
    "        depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
    "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
    "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
    "        pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
    "        return pos_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36890302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.557033Z",
     "iopub.status.busy": "2023-07-07T06:00:36.556720Z",
     "iopub.status.idle": "2023-07-07T06:00:36.567836Z",
     "shell.execute_reply": "2023-07-07T06:00:36.566776Z"
    },
    "papermill": {
     "duration": 0.024453,
     "end_time": "2023-07-07T06:00:36.569992",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.545539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "        # 追加した処理\n",
    "        self.dense1 = layers.Dense(embed_dim)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "        self.dense2 = layers.Dense(feed_forward_dim, activation=\"relu\")\n",
    "        self.dense3 = layers.Dense(embed_dim)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "\n",
    "        # 追加した処理\n",
    "        dense1_output = self.dense1(out1)\n",
    "        dense1_output = self.dropout3(dense1_output, training=training)\n",
    "        out2 = self.layernorm3(out1 + dense1_output)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out2 + self.dense3(self.dense2(ffn_output)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987754c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.592479Z",
     "iopub.status.busy": "2023-07-07T06:00:36.591519Z",
     "iopub.status.idle": "2023-07-07T06:00:36.607531Z",
     "shell.execute_reply": "2023-07-07T06:00:36.606167Z"
    },
    "papermill": {
     "duration": 0.029554,
     "end_time": "2023-07-07T06:00:36.609634",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.580080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TFRecordファイルのパス\n",
    "tfrecord_file = \"/kaggle/working/tfds/128822441.tfrecord\"\n",
    "\n",
    "# TFRecordデータセットの作成\n",
    "dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f29e35",
   "metadata": {
    "papermill": {
     "duration": 0.010058,
     "end_time": "2023-07-07T06:00:36.629775",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.619717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Here I added the training flag to the TransformerDecoder's Dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140bd99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.653857Z",
     "iopub.status.busy": "2023-07-07T06:00:36.653537Z",
     "iopub.status.idle": "2023-07-07T06:00:36.666631Z",
     "shell.execute_reply": "2023-07-07T06:00:36.665698Z"
    },
    "papermill": {
     "duration": 0.028856,
     "end_time": "2023-07-07T06:00:36.668726",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.639870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target, training):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
    "        return ffn_out_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd65ff9",
   "metadata": {
    "papermill": {
     "duration": 0.009708,
     "end_time": "2023-07-07T06:00:36.688243",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.678535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Here I made the passing of the training flag explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cdbbf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.715793Z",
     "iopub.status.busy": "2023-07-07T06:00:36.715094Z",
     "iopub.status.idle": "2023-07-07T06:00:36.753219Z",
     "shell.execute_reply": "2023-07-07T06:00:36.751886Z"
    },
    "papermill": {
     "duration": 0.058435,
     "end_time": "2023-07-07T06:00:36.756596",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.698161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=4,\n",
    "        num_layers_dec=1,\n",
    "        num_classes=60,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target, training):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source, training)\n",
    "        y = self.decode(x, target, training)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[0]\n",
    "        target = batch[1]\n",
    "\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        \n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
    "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):        \n",
    "        source = batch[0]\n",
    "        target = batch[1]\n",
    "\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        \n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
    "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source, training = False)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input, training = False)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = logits[:, -1][..., tf.newaxis]\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d1257a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:36.791026Z",
     "iopub.status.busy": "2023-07-07T06:00:36.790689Z",
     "iopub.status.idle": "2023-07-07T06:00:39.397877Z",
     "shell.execute_reply": "2023-07-07T06:00:39.396824Z"
    },
    "papermill": {
     "duration": 2.629681,
     "end_time": "2023-07-07T06:00:39.400672",
     "exception": false,
     "start_time": "2023-07-07T06:00:36.770991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 正解率を計算するためのメトリクスを作成\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# 学習ループ内で正解率を更新するコールバックを定義\n",
    "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_acc = train_accuracy.result()\n",
    "        val_acc = val_accuracy.result()\n",
    "        print(f\"Epoch {epoch+1}: Train Accuracy = {train_acc}, Validation Accuracy = {val_acc}\")\n",
    "        # 正解率をリセット\n",
    "        train_accuracy.reset_states()\n",
    "        val_accuracy.reset_states()\n",
    "# val_lossが3回マイナスになった場合に学習を停止するコールバック\n",
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=7):\n",
    "        super(EarlyStoppingCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.min_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        if val_loss < self.min_val_loss:\n",
    "            self.min_val_loss = val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.model.stop_training = True\n",
    "                print(\"Training stopped due to early stopping.\")\n",
    "\n",
    "batch = next(iter(val_dataset))\n",
    "idx_to_char = list(char_to_num.keys())\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=256,\n",
    "    num_head=4,\n",
    "    num_feed_forward=400,\n",
    "    source_maxlen = FRAME_LEN,\n",
    "    target_maxlen=64,\n",
    "    num_layers_enc=3,\n",
    "    num_layers_dec=2,\n",
    "    num_classes=62,\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "accuracy_callback = AccuracyCallback()\n",
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09825049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:39.423945Z",
     "iopub.status.busy": "2023-07-07T06:00:39.422365Z",
     "iopub.status.idle": "2023-07-07T06:00:39.427879Z",
     "shell.execute_reply": "2023-07-07T06:00:39.427041Z"
    },
    "papermill": {
     "duration": 0.018671,
     "end_time": "2023-07-07T06:00:39.429843",
     "exception": false,
     "start_time": "2023-07-07T06:00:39.411172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#modelアーキテクト\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b71a23a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T06:00:39.452021Z",
     "iopub.status.busy": "2023-07-07T06:00:39.451139Z",
     "iopub.status.idle": "2023-07-07T07:38:46.934409Z",
     "shell.execute_reply": "2023-07-07T07:38:46.930339Z"
    },
    "papermill": {
     "duration": 5887.513949,
     "end_time": "2023-07-07T07:38:46.954047",
     "exception": false,
     "start_time": "2023-07-07T06:00:39.440098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 277s - loss: 0.7820 - val_loss: 0.6214 - 277s/epoch - 182ms/step\n",
      "Epoch 2/100\n",
      "Epoch 2: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 219s - loss: 0.5513 - val_loss: 0.5102 - 219s/epoch - 144ms/step\n",
      "Epoch 3/100\n",
      "Epoch 3: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 221s - loss: 0.4871 - val_loss: 0.4780 - 221s/epoch - 146ms/step\n",
      "Epoch 4/100\n",
      "Epoch 4: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 232s - loss: 0.4581 - val_loss: 0.4577 - 232s/epoch - 152ms/step\n",
      "Epoch 5/100\n",
      "Epoch 5: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 234s - loss: 0.4401 - val_loss: 0.4490 - 234s/epoch - 154ms/step\n",
      "Epoch 6/100\n",
      "Epoch 6: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 237s - loss: 0.4261 - val_loss: 0.4395 - 237s/epoch - 156ms/step\n",
      "Epoch 7/100\n",
      "Epoch 7: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 238s - loss: 0.4160 - val_loss: 0.4346 - 238s/epoch - 157ms/step\n",
      "Epoch 8/100\n",
      "Epoch 8: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 231s - loss: 0.4062 - val_loss: 0.4261 - 231s/epoch - 152ms/step\n",
      "Epoch 9/100\n",
      "Epoch 9: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 235s - loss: 0.3984 - val_loss: 0.4246 - 235s/epoch - 155ms/step\n",
      "Epoch 10/100\n",
      "Epoch 10: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 231s - loss: 0.3914 - val_loss: 0.4201 - 231s/epoch - 152ms/step\n",
      "Epoch 11/100\n",
      "Epoch 11: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 227s - loss: 0.3847 - val_loss: 0.4169 - 227s/epoch - 149ms/step\n",
      "Epoch 12/100\n",
      "Epoch 12: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 231s - loss: 0.3790 - val_loss: 0.4144 - 231s/epoch - 152ms/step\n",
      "Epoch 13/100\n",
      "Epoch 13: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 226s - loss: 0.3732 - val_loss: 0.4128 - 226s/epoch - 149ms/step\n",
      "Epoch 14/100\n",
      "Epoch 14: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 224s - loss: 0.3681 - val_loss: 0.4103 - 224s/epoch - 147ms/step\n",
      "Epoch 15/100\n",
      "Epoch 15: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 226s - loss: 0.3630 - val_loss: 0.4099 - 226s/epoch - 149ms/step\n",
      "Epoch 16/100\n",
      "Epoch 16: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 219s - loss: 0.3584 - val_loss: 0.4104 - 219s/epoch - 144ms/step\n",
      "Epoch 17/100\n",
      "Epoch 17: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 222s - loss: 0.3538 - val_loss: 0.4083 - 222s/epoch - 146ms/step\n",
      "Epoch 18/100\n",
      "Epoch 18: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 223s - loss: 0.3494 - val_loss: 0.4093 - 223s/epoch - 146ms/step\n",
      "Epoch 19/100\n",
      "Epoch 19: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 221s - loss: 0.3452 - val_loss: 0.4110 - 221s/epoch - 145ms/step\n",
      "Epoch 20/100\n",
      "Epoch 20: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 227s - loss: 0.3413 - val_loss: 0.4106 - 227s/epoch - 149ms/step\n",
      "Epoch 21/100\n",
      "Epoch 21: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 232s - loss: 0.3372 - val_loss: 0.4112 - 232s/epoch - 152ms/step\n",
      "Epoch 22/100\n",
      "Epoch 22: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 241s - loss: 0.3333 - val_loss: 0.4106 - 241s/epoch - 158ms/step\n",
      "Epoch 23/100\n",
      "Epoch 23: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "1520/1520 - 241s - loss: 0.3294 - val_loss: 0.4111 - 241s/epoch - 158ms/step\n",
      "Epoch 24/100\n",
      "Epoch 24: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
      "Training stopped due to early stopping.\n",
      "1520/1520 - 242s - loss: 0.3258 - val_loss: 0.4173 - 242s/epoch - 159ms/step\n",
      "CPU times: user 2h 37s, sys: 7min 30s, total: 2h 8min 7s\n",
      "Wall time: 1h 38min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# EarlyStoppingCallbackをコールバックリストに追加して学習を行う\n",
    "history = model.fit(train_dataset, verbose=2, validation_data=val_dataset, epochs=100,\n",
    "                    callbacks=[AccuracyCallback(), EarlyStoppingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9e44d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:46.989108Z",
     "iopub.status.busy": "2023-07-07T07:38:46.988718Z",
     "iopub.status.idle": "2023-07-07T07:38:47.052584Z",
     "shell.execute_reply": "2023-07-07T07:38:47.051356Z"
    },
    "papermill": {
     "duration": 0.085003,
     "end_time": "2023-07-07T07:38:47.055120",
     "exception": false,
     "start_time": "2023-07-07T07:38:46.970117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " landmark_embedding (Landmar  (None, 128, 256)         2387456   \n",
      " kEmbedding)                                                     \n",
      "                                                                 \n",
      " token_embedding (TokenEmbed  multiple                 410624    \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 128, 256)          6977888   \n",
      "                                                                 \n",
      " transformer_decoder (Transf  multiple                 2310800   \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " transformer_decoder_1 (Tran  multiple                 2310800   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " dense_25 (Dense)            multiple                  15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,026,048\n",
      "Trainable params: 12,023,998\n",
      "Non-trainable params: 2,050\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b235066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:47.094254Z",
     "iopub.status.busy": "2023-07-07T07:38:47.093252Z",
     "iopub.status.idle": "2023-07-07T07:38:47.560409Z",
     "shell.execute_reply": "2023-07-07T07:38:47.559413Z"
    },
    "papermill": {
     "duration": 0.489829,
     "end_time": "2023-07-07T07:38:47.562700",
     "exception": false,
     "start_time": "2023-07-07T07:38:47.072871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bdc88453ac0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841397b",
   "metadata": {
    "papermill": {
     "duration": 0.021645,
     "end_time": "2023-07-07T07:38:47.602002",
     "exception": false,
     "start_time": "2023-07-07T07:38:47.580357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "492ba19c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:47.680007Z",
     "iopub.status.busy": "2023-07-07T07:38:47.672323Z",
     "iopub.status.idle": "2023-07-07T07:38:55.968172Z",
     "shell.execute_reply": "2023-07-07T07:38:55.967084Z"
    },
    "papermill": {
     "duration": 8.334785,
     "end_time": "2023-07-07T07:38:55.971202",
     "exception": false,
     "start_time": "2023-07-07T07:38:47.636417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 creekhouseE\n",
      "S33 creek houseE\n",
      "\n",
      "~~~\n",
      "\n",
      "Sscales/kuhaylahE\n",
      "Sscales chuhaylaE\n",
      "\n",
      "~~~\n",
      "\n",
      "S1383 william lanierE\n",
      "S1385 william lanierE\n",
      "\n",
      "~~~\n",
      "\n",
      "S988 franklin laneE\n",
      "S988 funklin plakeE\n",
      "\n",
      "~~~\n",
      "\n",
      "S6920 northeast 661st roadE\n",
      "S6920 northeast 66th stroadE\n",
      "\n",
      "~~~\n",
      "\n",
      "Swww.freem.ne.jpE\n",
      "Swww.freem.me.jpE\n",
      "\n",
      "~~~\n",
      "\n",
      "Shttps://jsi.is/hukuokaE\n",
      "Shttps://jsi.is/hkuokaE\n",
      "\n",
      "~~~\n",
      "\n",
      "S239613 stolze streetE\n",
      "S296102 stold east roadE\n",
      "\n",
      "~~~\n",
      "\n",
      "S271097 bayshore boulevardE\n",
      "S271097 bay gore boulevardE\n",
      "\n",
      "~~~\n",
      "\n",
      "Sfederico pearsonE\n",
      "Sfederico pearonE\n",
      "\n",
      "~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batches = [batch for batch in val_dataset]\n",
    "\n",
    "preds_list = []\n",
    "ground_truth_list = []\n",
    "\n",
    "for batch in batches[:1]:\n",
    "    source = batch[0]\n",
    "    target = batch[1].numpy()\n",
    "    bs = tf.shape(source)[0]\n",
    "    preds = model.generate(source, start_token_idx)\n",
    "    preds = preds.numpy()\n",
    "\n",
    "    for i in range(bs):\n",
    "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
    "        ground_truth_list.append(target_text.replace('P', ''))\n",
    "        prediction = \"\"\n",
    "        for idx in preds[i, :]:\n",
    "            prediction += idx_to_char[idx]\n",
    "            if idx == end_token_idx:\n",
    "                break\n",
    "        preds_list.append(prediction)\n",
    "\n",
    "for i in range(10):\n",
    "    print(ground_truth_list[i])\n",
    "    print(preds_list[i])\n",
    "    print('\\n~~~\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d008b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:56.009475Z",
     "iopub.status.busy": "2023-07-07T07:38:56.009139Z",
     "iopub.status.idle": "2023-07-07T07:38:56.024850Z",
     "shell.execute_reply": "2023-07-07T07:38:56.023830Z"
    },
    "papermill": {
     "duration": 0.036584,
     "end_time": "2023-07-07T07:38:56.026935",
     "exception": false,
     "start_time": "2023-07-07T07:38:55.990351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.7838765008576329\n"
     ]
    }
   ],
   "source": [
    "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
    "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
    "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n",
    "            for i in range(len(preds_list_processed))]\n",
    "N = [len(phrase) for phrase in ground_truth_processed]\n",
    "\n",
    "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f5917",
   "metadata": {
    "papermill": {
     "duration": 0.016974,
     "end_time": "2023-07-07T07:38:56.061232",
     "exception": false,
     "start_time": "2023-07-07T07:38:56.044258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Levenstein Distance Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214481b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:56.187641Z",
     "iopub.status.busy": "2023-07-07T07:38:56.186628Z",
     "iopub.status.idle": "2023-07-07T07:38:56.194963Z",
     "shell.execute_reply": "2023-07-07T07:38:56.193962Z"
    },
    "papermill": {
     "duration": 0.118419,
     "end_time": "2023-07-07T07:38:56.197168",
     "exception": false,
     "start_time": "2023-07-07T07:38:56.078749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute Levenstein Distances\n",
    "def get_ld_train():\n",
    "    N = 100 if IS_INTERACTIVE else 1000\n",
    "    LD_TRAIN = []\n",
    "    for idx, (frames, phrase_true) in enumerate(zip(tqdm(X_train, total=N), y_train)):\n",
    "        # Predict Phrase and Convert to String\n",
    "        phrase_pred = predict_phrase(frames).numpy()\n",
    "        phrase_pred = outputs2phrase(phrase_pred)\n",
    "        # True Phrase Ordinal to String\n",
    "        phrase_true = outputs2phrase(phrase_true)\n",
    "        # Add Levenstein Distance\n",
    "        LD_TRAIN.append({\n",
    "            'phrase_true': phrase_true,\n",
    "            'phrase_pred': phrase_pred,\n",
    "            'levenshtein_distance': levenshtein(phrase_pred, phrase_true),\n",
    "        })\n",
    "        # Take subset in interactive mode\n",
    "        if idx == N:\n",
    "            break\n",
    "            \n",
    "    # Convert to DataFrame\n",
    "    LD_TRAIN_DF = pd.DataFrame(LD_TRAIN)\n",
    "    \n",
    "    return LD_TRAIN_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8447ce40",
   "metadata": {
    "papermill": {
     "duration": 0.017434,
     "end_time": "2023-07-07T07:38:56.232495",
     "exception": false,
     "start_time": "2023-07-07T07:38:56.215061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TFLiteModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1c84941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:56.270143Z",
     "iopub.status.busy": "2023-07-07T07:38:56.269218Z",
     "iopub.status.idle": "2023-07-07T07:38:56.281173Z",
     "shell.execute_reply": "2023-07-07T07:38:56.280208Z"
    },
    "papermill": {
     "duration": 0.033217,
     "end_time": "2023-07-07T07:38:56.283447",
     "exception": false,
     "start_time": "2023-07-07T07:38:56.250230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " class TFLiteModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "        self.target_start_token_idx = start_token_idx\n",
    "        self.target_end_token_idx = end_token_idx\n",
    "        # Load the feature generation and main models\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs, training=False):\n",
    "        # Preprocess Data\n",
    "        x = tf.cast(inputs, tf.float32)\n",
    "        x = x[None]\n",
    "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n",
    "        x = x[0]\n",
    "        x = pre_process(x)\n",
    "        x = x[None]\n",
    "        x = self.model.generate(x, self.target_start_token_idx)\n",
    "        x = x[0]\n",
    "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
    "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
    "        x = x[1:idx]\n",
    "        x = tf.one_hot(x, 59)\n",
    "        return {'outputs': x}\n",
    "\n",
    "tflitemodel_base = TFLiteModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa170193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:56.320546Z",
     "iopub.status.busy": "2023-07-07T07:38:56.320193Z",
     "iopub.status.idle": "2023-07-07T07:38:56.630624Z",
     "shell.execute_reply": "2023-07-07T07:38:56.629528Z"
    },
    "papermill": {
     "duration": 0.33267,
     "end_time": "2023-07-07T07:38:56.633476",
     "exception": false,
     "start_time": "2023-07-07T07:38:56.300806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "797b490b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:38:56.677155Z",
     "iopub.status.busy": "2023-07-07T07:38:56.675105Z",
     "iopub.status.idle": "2023-07-07T07:41:21.275315Z",
     "shell.execute_reply": "2023-07-07T07:41:21.274203Z"
    },
    "papermill": {
     "duration": 144.626633,
     "end_time": "2023-07-07T07:41:21.279554",
     "exception": false,
     "start_time": "2023-07-07T07:38:56.652921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cond_2/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
    "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = keras_model_converter.convert()\n",
    "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "infargs = {\"selected_columns\" : SEL_COLS}\n",
    "\n",
    "with open('inference_args.json', \"w\") as json_file:\n",
    "    json.dump(infargs, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "572d663f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:41:21.319465Z",
     "iopub.status.busy": "2023-07-07T07:41:21.319110Z",
     "iopub.status.idle": "2023-07-07T07:41:26.216995Z",
     "shell.execute_reply": "2023-07-07T07:41:26.215690Z"
    },
    "papermill": {
     "duration": 4.921208,
     "end_time": "2023-07-07T07:41:26.219953",
     "exception": false,
     "start_time": "2023-07-07T07:41:21.298745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.tflite (deflated 14%)\r\n",
      "  adding: inference_args.json (deflated 85%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip  './model.tflite' './inference_args.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce2e305f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T07:41:26.260261Z",
     "iopub.status.busy": "2023-07-07T07:41:26.259570Z",
     "iopub.status.idle": "2023-07-07T07:41:27.554695Z",
     "shell.execute_reply": "2023-07-07T07:41:27.552240Z"
    },
    "papermill": {
     "duration": 1.317984,
     "end_time": "2023-07-07T07:41:27.557331",
     "exception": false,
     "start_time": "2023-07-07T07:41:26.239347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288-212-2222\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
    "\n",
    "REQUIRED_SIGNATURE = \"serving_default\"\n",
    "REQUIRED_OUTPUT = \"outputs\"\n",
    "\n",
    "with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "    character_map = json.load(f)\n",
    "rev_character_map = {j:i for i,j in character_map.items()}\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "\n",
    "if REQUIRED_SIGNATURE not in found_signatures:\n",
    "    raise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "output = prediction_fn(inputs=batch[0][0])\n",
    "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
    "print(prediction_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6081.930817,
   "end_time": "2023-07-07T07:41:31.616775",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-07T06:00:09.685958",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
