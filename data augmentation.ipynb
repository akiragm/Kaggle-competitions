{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ColabPreprocess  --START\n",
        "置換<br>\n",
        "\n",
        "/kaggle/input/            <br>\n",
        "/content/"
      ],
      "metadata": {
        "id": "uIY3gyjVDW16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "9D2OX6U0CaH6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! apt update\n",
        "! apt install gcsfuse"
      ],
      "metadata": {
        "outputId": "0bc629dd-a9ae-4972-b936-cb1344c44447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qpeTkECaH7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0  98481      0 --:--:-- --:--:-- --:--:-- 98481\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,004 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:7 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [2,286 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,360 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,299 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Fetched 5,054 kB in 2s (2,598 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "13 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 14.0 MB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 0.42.5 [14.0 MB]\n",
            "Fetched 14.0 MB in 0s (29.8 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.42.5_amd64.deb ...\n",
            "Unpacking gcsfuse (0.42.5) ...\n",
            "Setting up gcsfuse (0.42.5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5f_lFB9TCaH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kaggle get_gcspath\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "print(KaggleDatasets().get_gcs_path())"
      ],
      "metadata": {
        "id": "1GmDR8Lh1fku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3Q0v8LEtnE",
        "outputId": "0fb50718-10ba-46dd-b84d-5bff00d45da5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p asl-fingerspelling\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-060e8f96f45da8817e298f5151de7d204c3aa2ebfe6436b68e8d87e2 asl-fingerspelling"
      ],
      "metadata": {
        "id": "olczO1_pC2TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53014849-0c12-4676-c646-5bafe5d39c1c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0626 08:07:59.975134 2023/06/26 08:07:59.975108 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /content/asl-fingerspelling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p aslfr-parquets-to-tfrecords-cleaned\n",
        "! gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 kds-1865224784ea3c877e01e6064beb4b6fd74d08462427498e98ddc3df aslfr-parquets-to-tfrecords-cleaned"
      ],
      "metadata": {
        "outputId": "eabf1b25-826d-4a69-c6eb-8e7e19bcfd60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2KWdEtVCaH9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0626 08:08:03.001855 2023/06/26 08:08:03.001810 Start gcsfuse/0.42.5 (Go version go1.20.3) for app \"\" using mount point: /content/aslfr-parquets-to-tfrecords-cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esy-KMuR8ivw",
        "outputId": "b508b504-8b6e-4fb1-e8d4-2f046dbc6947"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8L77lmNJEQYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --END  ColabPreprocess"
      ],
      "metadata": {
        "id": "ZDYAPQiVEATw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. I used two transformer layer in the encoder instead of four.\n",
        "2. I used four attention heads instead of two.\n",
        "3. I used new tokens for SOS, EOS, and padding (very minor since Rohith used rare tokens for these purposes, but still- more 'correct').\n",
        "2. I fixed a bug (probably?) in the decoder's dropout layers, which did not have the training flag, resulting in dropout during inference. This change gave a nice bump in the score.\n",
        "3. I made the passing of the training flag explicit. I know it can be implicit since it is a kwarg, but explicit passing makes the whole thing more straightforward and maybe fix another one or two training-flag-related bugs along the way.\n",
        "4. I changed the positional encoding in the decoder from tf.keras.layers.Embedding to proper positional embeddings (i.e., the usual sines and cosines usually used for this purpose). This had a significant impact.\n",
        "5. I added positional embedding to the encoder. This, too, had a significant impact.\n"
      ],
      "metadata": {
        "id": "ls6jZUmODp5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import Levenshtein as lev\n",
        "import os\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:39.647352Z",
          "iopub.execute_input": "2023-06-26T03:43:39.647946Z",
          "iopub.status.idle": "2023-06-26T03:43:39.654535Z",
          "shell.execute_reply.started": "2023-06-26T03:43:39.647910Z",
          "shell.execute_reply": "2023-06-26T03:43:39.653364Z"
        },
        "trusted": true,
        "id": "hJnLDjLzDp53"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "B3hcEfbDDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
        "display(df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:34.921833Z",
          "iopub.execute_input": "2023-06-21T12:27:34.922562Z",
          "iopub.status.idle": "2023-06-21T12:27:35.134638Z",
          "shell.execute_reply.started": "2023-06-21T12:27:34.922525Z",
          "shell.execute_reply": "2023-06-21T12:27:35.133695Z"
        },
        "id": "0Ni7noahDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_landmarks = pd.read_parquet('/content/asl-fingerspelling/train_landmarks/1019715464.parquet')\n",
        "keys = train_landmarks.keys()[1:]\n",
        "train_landmarks.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:35.136172Z",
          "iopub.execute_input": "2023-06-21T12:27:35.136526Z",
          "iopub.status.idle": "2023-06-21T12:27:52.128059Z",
          "shell.execute_reply.started": "2023-06-21T12:27:35.136494Z",
          "shell.execute_reply": "2023-06-21T12:27:52.122672Z"
        },
        "id": "F1hbBsMFDp55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFRecord"
      ],
      "metadata": {
        "id": "t_Zq2IIvDp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.129279Z",
          "iopub.status.idle": "2023-06-21T12:27:52.130399Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.130158Z",
          "shell.execute_reply": "2023-06-21T12:27:52.13018Z"
        },
        "id": "jycbHpy_Dp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
        "\n",
        "counter = 0\n",
        "for file_id in tqdm(df.file_id.unique()):\n",
        "    \n",
        "    print(counter)\n",
        "    counter+=1\n",
        "    \n",
        "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
        "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
        "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
        "    seq_refs = df.loc[df.file_id == file_id]\n",
        "    seqs = load_relevant_data_subset(pqfile)\n",
        "    seqs_numpy = seqs.to_numpy()\n",
        "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
        "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
        "            frames = seqs_numpy[seqs.index == seq_id]\n",
        "            \n",
        "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n",
        "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n",
        "            no_nan = max(r_nonan, l_nonan)\n",
        "            \n",
        "            if 2*len(phrase)<no_nan:\n",
        "                features = {SEL_COLS[i]: tf.train.Feature(\n",
        "                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(SEL_COLS))}\n",
        "                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
        "                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
        "                file_writer.write(record_bytes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-21T12:27:52.131662Z",
          "iopub.status.idle": "2023-06-21T12:27:52.132528Z",
          "shell.execute_reply.started": "2023-06-21T12:27:52.132225Z",
          "shell.execute_reply": "2023-06-21T12:27:52.132253Z"
        },
        "id": "Hmzq1uMZDp56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "anVm5CKGDp57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I use new tokens for padding, start and end of sentences. (Capitals are good since the original phrases have only lower case letters, besides numbers and various signs)."
      ],
      "metadata": {
        "id": "NaASHGkwDp57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = 'P'\n",
        "start_token = 'S'\n",
        "end_token = 'E'\n",
        "pad_token_idx = 59\n",
        "start_token_idx = 60\n",
        "end_token_idx = 61"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:50.038588Z",
          "iopub.execute_input": "2023-06-26T03:43:50.039294Z",
          "iopub.status.idle": "2023-06-26T03:43:50.043979Z",
          "shell.execute_reply.started": "2023-06-26T03:43:50.039260Z",
          "shell.execute_reply": "2023-06-26T03:43:50.043067Z"
        },
        "trusted": true,
        "id": "zGEhbPRUDp58"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    char_to_num = json.load(f)\n",
        "\n",
        "\n",
        "char_to_num[pad_token] = pad_token_idx\n",
        "char_to_num[start_token] = start_token_idx\n",
        "char_to_num[end_token] = end_token_idx\n",
        "\n",
        "num_to_char = {j:i for i,j in char_to_num.items()}\n",
        "\n",
        "\n",
        "inpdir = \"/content/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "\n",
        "LPOSE = [13, 15, 17, 19, 21]\n",
        "RPOSE = [14, 16, 18, 20, 22]\n",
        "POSE = LPOSE + RPOSE\n",
        "\n",
        "RHAND_LBLS = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
        "LHAND_LBLS = [ f'x_left_hand_{i}' for i in range(21)] + [ f'y_left_hand_{i}' for i in range(21)] + [ f'z_left_hand_{i}' for i in range(21)]\n",
        "POSE_LBLS = [f'x_pose_{i}' for i in POSE] + [f'y_pose_{i}' for i in POSE] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
        "Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
        "\n",
        "SEL_COLS = X + Y + Z\n",
        "FRAME_LEN = 128\n",
        "\n",
        "X_IDX = [i for i, col in enumerate(SEL_COLS)  if \"x_\" in col]\n",
        "Y_IDX = [i for i, col in enumerate(SEL_COLS)  if \"y_\" in col]\n",
        "Z_IDX = [i for i, col in enumerate(SEL_COLS)  if \"z_\" in col]\n",
        "\n",
        "RHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col]\n",
        "LHAND_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col]\n",
        "RPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n",
        "LPOSE_IDX = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]\n",
        "\n",
        "print(RPOSE_IDX)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:51.279454Z",
          "iopub.execute_input": "2023-06-26T03:43:51.279841Z",
          "iopub.status.idle": "2023-06-26T03:43:51.388163Z",
          "shell.execute_reply.started": "2023-06-26T03:43:51.279809Z",
          "shell.execute_reply": "2023-06-26T03:43:51.387128Z"
        },
        "trusted": true,
        "id": "SdTNf47NDp58",
        "outputId": "041a8945-120a-4485-9884-8673eac68ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 48, 49, 50, 51, 99, 100, 101, 102, 103, 151, 152, 153, 154, 155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{0: ' ', 1: '!', 2: '#', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: '+', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '=', 28: '?', 29: '@', 30: '[', 31: '_', 32: 'a', 33: 'b', 34: 'c', 35: 'd', 36: 'e', 37: 'f', 38: 'g', 39: 'h', 40: 'i', 41: 'j', 42: 'k', 43: 'l', 44: 'm', 45: 'n', 46: 'o', 47: 'p', 48: 'q', 49: 'r', 50: 's', 51: 't', 52: 'u', 53: 'v', 54: 'w', 55: 'x', 56: 'y', 57: 'z', 58: '~', 59: 'P', 60: 'S', 61: 'E'}\n",
        "add Codeadd Markdown"
      ],
      "metadata": {
        "id": "7l2otrH4Dp59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_pad(x):\n",
        "    if tf.shape(x)[0] < FRAME_LEN:\n",
        "        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n",
        "        print(x)\n",
        "    else:\n",
        "        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n",
        "    return x\n",
        "\n",
        "def translate_landmarks(landmarks, max_translation):\n",
        "    translation = tf.random.uniform(shape=tf.shape(landmarks), minval=-max_translation, maxval=max_translation)\n",
        "    translated_landmarks = landmarks + translation\n",
        "    return translated_landmarks\n",
        "\n",
        "def scale_landmarks(landmarks, min_scale, max_scale):\n",
        "    scale_factor = tf.random.uniform(shape=tf.shape(landmarks), minval=min_scale, maxval=max_scale)\n",
        "    scaled_landmarks = landmarks * scale_factor\n",
        "    return scaled_landmarks\n",
        "\n",
        "def pre_process(x):\n",
        "\n",
        "    rhand = tf.gather(x, RHAND_IDX, axis=1)\n",
        "    lhand = tf.gather(x, LHAND_IDX, axis=1)\n",
        "    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n",
        "    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n",
        "\n",
        "    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n",
        "    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n",
        "\n",
        "    rnans = tf.math.count_nonzero(rnan_idx)\n",
        "    lnans = tf.math.count_nonzero(lnan_idx)\n",
        "\n",
        "    # For dominant hand\n",
        "    if rnans > lnans:\n",
        "        hand = lhand\n",
        "        pose = lpose\n",
        "\n",
        "        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n",
        "\n",
        "        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n",
        "    else:\n",
        "        hand = rhand\n",
        "        pose = rpose\n",
        "\n",
        "    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n",
        "    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n",
        "    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n",
        "    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n",
        "    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n",
        "    hand = (hand - mean) / std\n",
        "\n",
        "    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n",
        "    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n",
        "    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n",
        "    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1)\n",
        "\n",
        "    x = tf.concat([hand, pose], axis=1)\n",
        "    x = resize_pad(x)\n",
        "\n",
        "    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX)))\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:56.251215Z",
          "iopub.execute_input": "2023-06-26T03:43:56.251603Z",
          "iopub.status.idle": "2023-06-26T03:43:56.275318Z",
          "shell.execute_reply.started": "2023-06-26T03:43:56.251574Z",
          "shell.execute_reply": "2023-06-26T03:43:56.274277Z"
        },
        "trusted": true,
        "id": "Qk5pTdDzDp5-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=list(char_to_num.keys()),\n",
        "        values=list(char_to_num.values()),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name=\"class_weight\"\n",
        ")\n",
        "\n",
        "def preprocess_fn(landmarks, phrase):\n",
        "    phrase = start_token + phrase + end_token\n",
        "    phrase = tf.strings.bytes_split(phrase)\n",
        "    phrase = table.lookup(phrase)\n",
        "    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]], mode = 'CONSTANT',\n",
        "                    constant_values = pad_token_idx)\n",
        "\n",
        "    # landmarksを前処理する\n",
        "    translated_landmarks = translate_landmarks(landmarks, max_translation=10)\n",
        "    scaled_landmarks = scale_landmarks(landmarks, min_scale=0.8, max_scale=1.2)\n",
        "\n",
        "    # 前処理済みのlandmarksを結合する\n",
        "    combined_landmarks = tf.concat([landmarks, translated_landmarks, scaled_landmarks], axis=1)\n",
        "\n",
        "    return pre_process(combined_landmarks), phrase\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in SEL_COLS}\n",
        "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "    phrase = features[\"phrase\"]\n",
        "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in SEL_COLS])\n",
        "    landmarks = tf.transpose(landmarks)\n",
        "\n",
        "    return landmarks, phrase\n",
        "\n",
        "inpdir = \"/content/aslfr-parquets-to-tfrecords-cleaned\"\n",
        "tffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()\n",
        "\n",
        "batch_size = 32\n",
        "val_len = int(0.05 * len(tffiles))\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).map(preprocess_fn).shuffle(30000, reshuffle_each_iteration=True).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).map(preprocess_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:43:57.838702Z",
          "iopub.execute_input": "2023-06-26T03:43:57.839078Z",
          "iopub.status.idle": "2023-06-26T03:43:59.156543Z",
          "shell.execute_reply.started": "2023-06-26T03:43:57.839049Z",
          "shell.execute_reply": "2023-06-26T03:43:59.155472Z"
        },
        "trusted": true,
        "id": "GK-wOj8CDp5_",
        "outputId": "f8bd0a32-c690-4cfd-c844-ca18ebae26bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n",
            "Tensor(\"cond_1/Pad:0\", shape=(None, 26, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The model"
      ],
      "metadata": {
        "id": "PufJODDjDp5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:e865f0c6-0e14-4387-9779-537f8b3d065d.png)\n",
        "![image.png](attachment:39ec8854-9e5f-4617-aa6a-69098b605134.png)\n",
        "![image.png](attachment:8b28cc87-2b4a-467f-a818-44b7e1f8dc8f.png)\n",
        "![image.png](attachment:243f34f9-3f88-4452-aac7-ee1ec0a3d065.png)"
      ],
      "metadata": {
        "id": "35kTT5MRDp5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I implemented proper positional embeddings for both the encoder and the decoder."
      ],
      "metadata": {
        "id": "su-6MWcSDp6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(layers.Layer):\n",
        "    def __init__(self, num_hid=64, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.mlp = tf.keras.Sequential()\n",
        "        for _ in range(num_layers):\n",
        "            self.mlp.add(tf.keras.layers.Dense(num_hid, activation=tf.nn.gelu))\n",
        "        self.mlp.add(tf.keras.layers.Dense(num_hid))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.mlp(inputs)\n",
        "\n",
        "\n",
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64, mlp_num_layers=2):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = self.positional_encoding(maxlen - 1, num_hid)\n",
        "        self.mlp_block = MLPBlock(num_hid, num_layers=mlp_num_layers)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x) * tf.math.sqrt(tf.cast(self.num_hid, tf.float32))\n",
        "        x = x + self.pos_emb[:maxlen, :]\n",
        "        x = self.mlp_block(x)\n",
        "        return x\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depth = num_hid // 2\n",
        "        angles = positions / tf.pow(10000, tf.range(0, depth, 1, dtype=tf.float32) / num_hid)  # depthのインクリメントを修正\n",
        "        pos_encoding = tf.concat([tf.sin(angles), tf.cos(angles)], axis=-1)\n",
        "        return pos_encoding\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:00.656849Z",
          "iopub.execute_input": "2023-06-26T03:44:00.659000Z",
          "iopub.status.idle": "2023-06-26T03:44:00.672227Z",
          "shell.execute_reply.started": "2023-06-26T03:44:00.658953Z",
          "shell.execute_reply": "2023-06-26T03:44:00.671099Z"
        },
        "trusted": true,
        "id": "9QJUkdQeDp6A"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.num_hid = num_hid\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "        '''\n",
        "        self.pos_emb = tf.math.divide(\n",
        "            self.positional_encoding(maxlen-1, num_hid),\n",
        "            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n",
        "        '''\n",
        "        self.pos_emb = self.positional_encoding(maxlen-1, num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        '''\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "        '''\n",
        "        return x + self.pos_emb[:maxlen, :]\n",
        "    \n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T01:27:59.514789Z",
          "iopub.execute_input": "2023-06-22T01:27:59.517058Z",
          "iopub.status.idle": "2023-06-22T01:27:59.530952Z",
          "shell.execute_reply.started": "2023-06-22T01:27:59.517017Z",
          "shell.execute_reply": "2023-06-22T01:27:59.529987Z"
        },
        "id": "0K45t4ttDp6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super(LandmarkEmbedding, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu1 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu2 = tf.keras.layers.ReLU()\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu3 = tf.keras.layers.ReLU()\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = tf.keras.layers.Conv1D(num_hid, 11, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu4 = tf.keras.layers.ReLU()\n",
        "        self.dropout4 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
        "        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n",
        "        self.maxlen = maxlen\n",
        "        self.num_hid = num_hid\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n",
        "        x = x + self.pos_emb\n",
        "\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "    def positional_encoding(self, maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype=tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
        "        return pos_encoding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:02.337798Z",
          "iopub.execute_input": "2023-06-26T03:44:02.338456Z",
          "iopub.status.idle": "2023-06-26T03:44:02.358498Z",
          "shell.execute_reply.started": "2023-06-26T03:44:02.338424Z",
          "shell.execute_reply": "2023-06-26T03:44:02.357547Z"
        },
        "trusted": true,
        "id": "yhso_UunDp6A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:04.520721Z",
          "iopub.execute_input": "2023-06-26T03:44:04.521113Z",
          "iopub.status.idle": "2023-06-26T03:44:04.530882Z",
          "shell.execute_reply.started": "2023-06-26T03:44:04.521080Z",
          "shell.execute_reply": "2023-06-26T03:44:04.529251Z"
        },
        "trusted": true,
        "id": "N8Lugl97Dp6B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# TFRecordファイルのパス\n",
        "tfrecord_file = \"/kaggle/working/tfds/128822441.tfrecord\"\n",
        "\n",
        "# TFRecordデータセットの作成\n",
        "dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
        "print(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:07.559213Z",
          "iopub.execute_input": "2023-06-26T03:44:07.560180Z",
          "iopub.status.idle": "2023-06-26T03:44:07.577877Z",
          "shell.execute_reply.started": "2023-06-26T03:44:07.560136Z",
          "shell.execute_reply": "2023-06-26T03:44:07.576727Z"
        },
        "trusted": true,
        "id": "PryRJHouDp6B",
        "outputId": "af95ed8d-c99b-4ef4-a63a-c1ff71205dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I added the training flag to the TransformerDecoder's Dropout layers."
      ],
      "metadata": {
        "id": "6Ul8pZtNDp6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target, training):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:08.748287Z",
          "iopub.execute_input": "2023-06-26T03:44:08.748649Z",
          "iopub.status.idle": "2023-06-26T03:44:08.764270Z",
          "shell.execute_reply.started": "2023-06-26T03:44:08.748619Z",
          "shell.execute_reply": "2023-06-26T03:44:08.762681Z"
        },
        "trusted": true,
        "id": "lbmu0lqMDp6C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here I made the passing of the training flag explicit."
      ],
      "metadata": {
        "id": "IxjuUK90Dp6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target, training):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y, training)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source, training)\n",
        "        y = self.decode(x, target, training)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[0]\n",
        "        target = batch[1]\n",
        "\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, pad_token_idx))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source, training = False)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input, training = False)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = logits[:, -1][..., tf.newaxis]\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:44:11.821637Z",
          "iopub.execute_input": "2023-06-26T03:44:11.822020Z",
          "iopub.status.idle": "2023-06-26T03:44:11.845701Z",
          "shell.execute_reply.started": "2023-06-26T03:44:11.821989Z",
          "shell.execute_reply": "2023-06-26T03:44:11.844544Z"
        },
        "trusted": true,
        "id": "FMzXwlaNDp6D"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解率を計算するためのメトリクスを作成\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# 学習ループ内で正解率を更新するコールバックを定義\n",
        "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_acc = train_accuracy.result()\n",
        "        val_acc = val_accuracy.result()\n",
        "        print(f\"Epoch {epoch+1}: Train Accuracy = {train_acc}, Validation Accuracy = {val_acc}\")\n",
        "        # 正解率をリセット\n",
        "        train_accuracy.reset_states()\n",
        "        val_accuracy.reset_states()\n",
        "# val_lossが連続3回マイナスになった場合に学習を停止するコールバック\n",
        "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=3):\n",
        "        super(EarlyStoppingCallback, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.min_val_loss = float('inf')\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        if val_loss < self.min_val_loss:\n",
        "            self.min_val_loss = val_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stopped due to early stopping.\")\n",
        "\n",
        "batch = next(iter(val_dataset))\n",
        "idx_to_char = list(char_to_num.keys())\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=4,\n",
        "    num_feed_forward=400,\n",
        "    source_maxlen = FRAME_LEN,\n",
        "    target_maxlen=64,\n",
        "    num_layers_enc=2,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=62,\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "accuracy_callback = AccuracyCallback()\n",
        "optimizer = keras.optimizers.Adam(0.0001)\n",
        "\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_accuracy])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:45:35.856212Z",
          "iopub.execute_input": "2023-06-26T03:45:35.856580Z",
          "iopub.status.idle": "2023-06-26T03:45:36.221753Z",
          "shell.execute_reply.started": "2023-06-26T03:45:35.856550Z",
          "shell.execute_reply": "2023-06-26T03:45:36.220648Z"
        },
        "trusted": true,
        "id": "qZRLTg89Dp6D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# EarlyStoppingCallbackをコールバックリストに追加して学習を行う\n",
        "history = model.fit(train_dataset, verbose=2, validation_data=val_dataset, epochs=100,\n",
        "                    callbacks=[AccuracyCallback(), EarlyStoppingCallback()])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T03:45:40.633802Z",
          "iopub.execute_input": "2023-06-26T03:45:40.634201Z",
          "iopub.status.idle": "2023-06-26T04:23:16.771818Z",
          "shell.execute_reply.started": "2023-06-26T03:45:40.634167Z",
          "shell.execute_reply": "2023-06-26T04:23:16.769586Z"
        },
        "trusted": true,
        "id": "rLPhxPFzDp6E",
        "outputId": "fb5ebc47-8250-4e25-c7f2-9ff4377932e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 231s - loss: 0.8578 - val_loss: 0.8185 - 231s/epoch - 152ms/step\n",
            "Epoch 2/100\n",
            "Epoch 2: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.8054 - val_loss: 0.7968 - 89s/epoch - 59ms/step\n",
            "Epoch 3/100\n",
            "Epoch 3: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 91s - loss: 0.7898 - val_loss: 0.7859 - 91s/epoch - 60ms/step\n",
            "Epoch 4/100\n",
            "Epoch 4: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 91s - loss: 0.7808 - val_loss: 0.7802 - 91s/epoch - 60ms/step\n",
            "Epoch 5/100\n",
            "Epoch 5: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7746 - val_loss: 0.7749 - 89s/epoch - 59ms/step\n",
            "Epoch 6/100\n",
            "Epoch 6: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7697 - val_loss: 0.7699 - 89s/epoch - 59ms/step\n",
            "Epoch 7/100\n",
            "Epoch 7: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7657 - val_loss: 0.7668 - 89s/epoch - 59ms/step\n",
            "Epoch 8/100\n",
            "Epoch 8: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7621 - val_loss: 0.7643 - 90s/epoch - 59ms/step\n",
            "Epoch 9/100\n",
            "Epoch 9: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7592 - val_loss: 0.7619 - 89s/epoch - 59ms/step\n",
            "Epoch 10/100\n",
            "Epoch 10: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7564 - val_loss: 0.7607 - 90s/epoch - 59ms/step\n",
            "Epoch 11/100\n",
            "Epoch 11: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7539 - val_loss: 0.7589 - 90s/epoch - 59ms/step\n",
            "Epoch 12/100\n",
            "Epoch 12: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7518 - val_loss: 0.7564 - 90s/epoch - 59ms/step\n",
            "Epoch 13/100\n",
            "Epoch 13: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7495 - val_loss: 0.7554 - 90s/epoch - 59ms/step\n",
            "Epoch 14/100\n",
            "Epoch 14: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7475 - val_loss: 0.7534 - 90s/epoch - 59ms/step\n",
            "Epoch 15/100\n",
            "Epoch 15: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7457 - val_loss: 0.7523 - 89s/epoch - 59ms/step\n",
            "Epoch 16/100\n",
            "Epoch 16: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7438 - val_loss: 0.7509 - 90s/epoch - 59ms/step\n",
            "Epoch 17/100\n",
            "Epoch 17: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7419 - val_loss: 0.7503 - 89s/epoch - 59ms/step\n",
            "Epoch 18/100\n",
            "Epoch 18: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7399 - val_loss: 0.7489 - 90s/epoch - 59ms/step\n",
            "Epoch 19/100\n",
            "Epoch 19: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7382 - val_loss: 0.7471 - 89s/epoch - 59ms/step\n",
            "Epoch 20/100\n",
            "Epoch 20: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7365 - val_loss: 0.7462 - 89s/epoch - 59ms/step\n",
            "Epoch 21/100\n",
            "Epoch 21: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7353 - val_loss: 0.7458 - 89s/epoch - 59ms/step\n",
            "Epoch 22/100\n",
            "Epoch 22: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7338 - val_loss: 0.7444 - 89s/epoch - 59ms/step\n",
            "Epoch 23/100\n",
            "Epoch 23: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7325 - val_loss: 0.7445 - 89s/epoch - 59ms/step\n",
            "Epoch 24/100\n",
            "Epoch 24: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7311 - val_loss: 0.7435 - 89s/epoch - 59ms/step\n",
            "Epoch 25/100\n",
            "Epoch 25: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7300 - val_loss: 0.7426 - 89s/epoch - 59ms/step\n",
            "Epoch 26/100\n",
            "Epoch 26: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7288 - val_loss: 0.7423 - 88s/epoch - 58ms/step\n",
            "Epoch 27/100\n",
            "Epoch 27: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7276 - val_loss: 0.7411 - 90s/epoch - 59ms/step\n",
            "Epoch 28/100\n",
            "Epoch 28: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7266 - val_loss: 0.7413 - 88s/epoch - 58ms/step\n",
            "Epoch 29/100\n",
            "Epoch 29: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7256 - val_loss: 0.7403 - 88s/epoch - 58ms/step\n",
            "Epoch 30/100\n",
            "Epoch 30: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7243 - val_loss: 0.7406 - 88s/epoch - 58ms/step\n",
            "Epoch 31/100\n",
            "Epoch 31: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7234 - val_loss: 0.7395 - 89s/epoch - 58ms/step\n",
            "Epoch 32/100\n",
            "Epoch 32: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7224 - val_loss: 0.7390 - 89s/epoch - 59ms/step\n",
            "Epoch 33/100\n",
            "Epoch 33: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7214 - val_loss: 0.7396 - 89s/epoch - 59ms/step\n",
            "Epoch 34/100\n",
            "Epoch 34: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7205 - val_loss: 0.7385 - 89s/epoch - 58ms/step\n",
            "Epoch 35/100\n",
            "Epoch 35: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7194 - val_loss: 0.7376 - 90s/epoch - 59ms/step\n",
            "Epoch 36/100\n",
            "Epoch 36: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 90s - loss: 0.7186 - val_loss: 0.7384 - 90s/epoch - 59ms/step\n",
            "Epoch 37/100\n",
            "Epoch 37: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7176 - val_loss: 0.7378 - 89s/epoch - 59ms/step\n",
            "Epoch 38/100\n",
            "Epoch 38: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7167 - val_loss: 0.7372 - 89s/epoch - 58ms/step\n",
            "Epoch 39/100\n",
            "Epoch 39: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7158 - val_loss: 0.7369 - 89s/epoch - 59ms/step\n",
            "Epoch 40/100\n",
            "Epoch 40: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7149 - val_loss: 0.7362 - 89s/epoch - 59ms/step\n",
            "Epoch 41/100\n",
            "Epoch 41: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7140 - val_loss: 0.7363 - 88s/epoch - 58ms/step\n",
            "Epoch 42/100\n",
            "Epoch 42: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 89s - loss: 0.7132 - val_loss: 0.7359 - 89s/epoch - 58ms/step\n",
            "Epoch 43/100\n",
            "Epoch 43: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 92s - loss: 0.7123 - val_loss: 0.7354 - 92s/epoch - 60ms/step\n",
            "Epoch 44/100\n",
            "Epoch 44: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7116 - val_loss: 0.7354 - 88s/epoch - 58ms/step\n",
            "Epoch 45/100\n",
            "Epoch 45: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7107 - val_loss: 0.7347 - 88s/epoch - 58ms/step\n",
            "Epoch 46/100\n",
            "Epoch 46: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7099 - val_loss: 0.7359 - 88s/epoch - 58ms/step\n",
            "Epoch 47/100\n",
            "Epoch 47: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "1520/1520 - 88s - loss: 0.7091 - val_loss: 0.7358 - 88s/epoch - 58ms/step\n",
            "Epoch 48/100\n",
            "Epoch 48: Train Accuracy = 0.0, Validation Accuracy = 0.0\n",
            "Training stopped due to early stopping.\n",
            "1520/1520 - 88s - loss: 0.7083 - val_loss: 0.7356 - 88s/epoch - 58ms/step\n",
            "CPU times: user 2h 59min 49s, sys: 18min 21s, total: 3h 18min 11s\n",
            "Wall time: 1h 13min 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:22.467839Z",
          "iopub.execute_input": "2023-06-26T04:23:22.468542Z",
          "iopub.status.idle": "2023-06-26T04:23:22.523050Z",
          "shell.execute_reply.started": "2023-06-26T04:23:22.468503Z",
          "shell.execute_reply": "2023-06-26T04:23:22.522121Z"
        },
        "trusted": true,
        "id": "m0PK7-zbDp6E",
        "outputId": "051b2b18-2b50-4c4b-f002-a0b3355d384c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " landmark_embedding_1 (Landm  (None, 128, 200)         1495600   \n",
            " arkEmbedding)                                                   \n",
            "                                                                 \n",
            " token_embedding_1 (TokenEmb  multiple                 133000    \n",
            " edding)                                                         \n",
            "                                                                 \n",
            " sequential_8 (Sequential)   (None, 128, 200)          3103600   \n",
            "                                                                 \n",
            " transformer_decoder_1 (Tran  multiple                 1447000   \n",
            " sformerDecoder)                                                 \n",
            "                                                                 \n",
            " dense_19 (Dense)            multiple                  12462     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,696,064\n",
            "Trainable params: 4,694,462\n",
            "Non-trainable params: 1,602\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:25.874327Z",
          "iopub.execute_input": "2023-06-26T04:23:25.874717Z",
          "iopub.status.idle": "2023-06-26T04:23:26.232494Z",
          "shell.execute_reply.started": "2023-06-26T04:23:25.874667Z",
          "shell.execute_reply": "2023-06-26T04:23:26.231586Z"
        },
        "trusted": true,
        "id": "BHA4qBuLDp6E",
        "outputId": "0b26db22-df60-4cf6-b79b-d049af8af494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7375f19c90>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "SywRcwtGDp6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [batch for batch in val_dataset]\n",
        "\n",
        "preds_list = []\n",
        "ground_truth_list = []\n",
        "\n",
        "for batch in batches[:1]:\n",
        "    source = batch[0]\n",
        "    target = batch[1].numpy()\n",
        "    bs = tf.shape(source)[0]\n",
        "    preds = model.generate(source, start_token_idx)\n",
        "    preds = preds.numpy()\n",
        "\n",
        "    for i in range(bs):\n",
        "        target_text = \"\".join([idx_to_char[_] for _ in target[i, :]])\n",
        "        ground_truth_list.append(target_text.replace('P', ''))\n",
        "        prediction = \"\"\n",
        "        for idx in preds[i, :]:\n",
        "            prediction += idx_to_char[idx]\n",
        "            if idx == end_token_idx:\n",
        "                break\n",
        "        preds_list.append(prediction)\n",
        "\n",
        "for i in range(10):\n",
        "    print(ground_truth_list[i])\n",
        "    print(preds_list[i])\n",
        "    print('\\n~~~\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:33.831503Z",
          "iopub.execute_input": "2023-06-26T04:23:33.832760Z",
          "iopub.status.idle": "2023-06-26T04:23:40.926369Z",
          "shell.execute_reply.started": "2023-06-26T04:23:33.832713Z",
          "shell.execute_reply": "2023-06-26T04:23:40.925390Z"
        },
        "trusted": true,
        "id": "CTn5dZ8ADp6F",
        "outputId": "90751fb5-2200-4208-c191-613b05b449ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 creekhouseE\n",
            "S+92-31-10-03E\n",
            "\n",
            "~~~\n",
            "\n",
            "Sscales/kuhaylahE\n",
            "S+39-60-23-03-00-00-33E\n",
            "\n",
            "~~~\n",
            "\n",
            "S1383 william lanierE\n",
            "S+39-60-23-03-00-00-33E\n",
            "\n",
            "~~~\n",
            "\n",
            "S988 franklin laneE\n",
            "S199-399-3102E\n",
            "\n",
            "~~~\n",
            "\n",
            "S6920 northeast 661st roadE\n",
            "S+39-60-23-03-00-00-33E\n",
            "\n",
            "~~~\n",
            "\n",
            "Swww.freem.ne.jpE\n",
            "S+92-30-23-03E\n",
            "\n",
            "~~~\n",
            "\n",
            "Shttps://jsi.is/hukuokaE\n",
            "S+39-60-23-03-00-00-33E\n",
            "\n",
            "~~~\n",
            "\n",
            "S239613 stolze streetE\n",
            "S+39-60-20-03-00E\n",
            "\n",
            "~~~\n",
            "\n",
            "S271097 bayshore boulevardE\n",
            "S+39-60-23-03-00-00-33E\n",
            "\n",
            "~~~\n",
            "\n",
            "Sfederico pearsonE\n",
            "S911-347-3109E\n",
            "\n",
            "~~~\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_processed = [ground_truth_list[i][1:-1] for i in range(len(ground_truth_list))]\n",
        "preds_list_processed = [preds_list[i][1:-1] for i in range(len(preds_list))]\n",
        "lev_dist = [lev.distance(ground_truth_processed[i], preds_list_processed[i])\n",
        "            for i in range(len(preds_list_processed))]\n",
        "N = [len(phrase) for phrase in ground_truth_processed]\n",
        "\n",
        "print('Validation score: '+str((np.sum(N) - np.sum(lev_dist))/np.sum(N)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:45.163446Z",
          "iopub.execute_input": "2023-06-26T04:23:45.163846Z",
          "iopub.status.idle": "2023-06-26T04:23:45.171850Z",
          "shell.execute_reply.started": "2023-06-26T04:23:45.163812Z",
          "shell.execute_reply": "2023-06-26T04:23:45.170820Z"
        },
        "trusted": true,
        "id": "naN88UcIDp6F",
        "outputId": "5d15a5ca-fec3-40d4-e39a-3e8126666508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.036020583190394515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLiteModel"
      ],
      "metadata": {
        "id": "ucgKzMf4Dp6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " class TFLiteModel(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        super(TFLiteModel, self).__init__()\n",
        "        self.target_start_token_idx = start_token_idx\n",
        "        self.target_end_token_idx = end_token_idx\n",
        "        # Load the feature generation and main models\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n",
        "    def __call__(self, inputs, training=False):\n",
        "        # Preprocess Data\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = x[None]\n",
        "        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n",
        "        x = x[0]\n",
        "        x = pre_process(x)\n",
        "        x = x[None]\n",
        "        x = self.model.generate(x, self.target_start_token_idx)\n",
        "        x = x[0]\n",
        "        idx = tf.argmax(tf.cast(tf.equal(x, self.target_end_token_idx), tf.int32))\n",
        "        idx = tf.where(tf.math.less(idx, 1), tf.constant(2, dtype=tf.int64), idx)\n",
        "        x = x[1:idx]\n",
        "        x = tf.one_hot(x, 59)\n",
        "        return {'outputs': x}\n",
        "\n",
        "tflitemodel_base = TFLiteModel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:47.474886Z",
          "iopub.execute_input": "2023-06-26T04:23:47.476016Z",
          "iopub.status.idle": "2023-06-26T04:23:47.488141Z",
          "shell.execute_reply.started": "2023-06-26T04:23:47.475971Z",
          "shell.execute_reply": "2023-06-26T04:23:47.487131Z"
        },
        "trusted": true,
        "id": "tEcGTaJ2Dp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:50.183480Z",
          "iopub.execute_input": "2023-06-26T04:23:50.184185Z",
          "iopub.status.idle": "2023-06-26T04:23:50.376400Z",
          "shell.execute_reply.started": "2023-06-26T04:23:50.184149Z",
          "shell.execute_reply": "2023-06-26T04:23:50.375374Z"
        },
        "trusted": true,
        "id": "yC-8CLlHDp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
        "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = keras_model_converter.convert()\n",
        "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "infargs = {\"selected_columns\" : SEL_COLS}\n",
        "\n",
        "with open('inference_args.json', \"w\") as json_file:\n",
        "    json.dump(infargs, json_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:23:53.080752Z",
          "iopub.execute_input": "2023-06-26T04:23:53.081962Z",
          "iopub.status.idle": "2023-06-26T04:25:04.842986Z",
          "shell.execute_reply.started": "2023-06-26T04:23:53.081917Z",
          "shell.execute_reply": "2023-06-26T04:25:04.841993Z"
        },
        "trusted": true,
        "id": "0PxmgsFQDp6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip submission.zip  './model.tflite' './inference_args.json'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:25:07.995108Z",
          "iopub.execute_input": "2023-06-26T04:25:07.995950Z",
          "iopub.status.idle": "2023-06-26T04:25:10.415570Z",
          "shell.execute_reply.started": "2023-06-26T04:25:07.995914Z",
          "shell.execute_reply": "2023-06-26T04:25:10.414236Z"
        },
        "trusted": true,
        "id": "S4U791C_Dp6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "output = prediction_fn(inputs=batch[0][0])\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print(prediction_str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T04:25:14.037030Z",
          "iopub.execute_input": "2023-06-26T04:25:14.037455Z",
          "iopub.status.idle": "2023-06-26T04:25:14.458201Z",
          "shell.execute_reply.started": "2023-06-26T04:25:14.037420Z",
          "shell.execute_reply": "2023-06-26T04:25:14.457173Z"
        },
        "trusted": true,
        "id": "YpI1MlRqDp6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KxaL1qFDp6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}